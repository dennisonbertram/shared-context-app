This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)

Additional Info:
----------------

================================================================
Directory Structure
================================================================
architecture/
  architecture-global-context-network-2025-01-16.md
  architecture-hooks-event-capture-2025-01-16.md
  architecture-subagent-system-2025-01-16.md
  architecture-testing-harness-2025-01-16.md
  INDEX.md
decisions/
  decision-async-processing-model-2025-01-16.md
  decision-claude-testing-harness-2025-01-16.md
  decision-sanitize-before-storage-2025-01-16.md
  decision-subagent-driven-development-2025-01-16.md
  decision-use-claude-hooks-2025-01-16.md
  decision-use-sqlite-2025-01-16.md
  INDEX.md
guides/
  guide-claude-agent-sdk-integration-2025-01-16.md
  guide-phase-0-foundation-setup-2025-01-16.md
  guide-phase-1-hook-development-2025-01-16.md
  guide-tdd-workflow-2025-01-16.md
  guide-testing-harness-usage-2025-01-16.md
  guide-using-subagents-2025-01-16.md
  INDEX.md
plans/
  INDEX.md
  plan-global-context-network-mvp-2025-01-16.md
  plan-implementation-roadmap-2025-01-16.md
  plan-original-user-vision-2025-01-16.md
  plan-phase-0-tasks-2025-01-16.md
  plan-phase-1-tasks-2025-01-16.md
  plan-phase-2-tasks-2025-01-16.md
  plan-phase-3-tasks-2025-01-16.md
  plan-phase-4-tasks-2025-01-16.md
  plan-phase-5-tasks-2025-01-16.md
  plan-phase-6-tasks-2025-01-16.md
  plan-phase-7-tasks-2025-01-16.md
  plan-subagent-workflow-2025-01-16.md
reference/
  INDEX.md
  reference-claude-agent-sdk-api-2025-01-16.md
  reference-database-schema-2025-01-16.md
  reference-subagent-types-2025-01-16.md
  reference-testing-strategy-2025-01-16.md
INDEX.md

================================================================
Files
================================================================

================
File: architecture/architecture-global-context-network-2025-01-16.md
================
# Global Context Network - System Architecture

> Complete system architecture for the Global Context Network MVP

---
title: Global Context Network System Architecture
category: architecture
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [architecture, system-design, blockchain, privacy, subagents]
---

## Overview

The Global Context Network is a decentralized system for capturing, sanitizing, storing, and sharing AI agent learnings globally. It enables agents to learn from each other's experiences while maintaining strict privacy guarantees through PII sanitization before storage.

### Core Innovation

**"Mining through Learning"**: Instead of computational mining, users contribute valuable learnings to the network and receive token rewards based on quality and validation.

## System Architecture

```
┌─────────────────────────────────────────────────────────────────────────┐
│                         Claude Code (User Agent)                         │
└────────────┬─────────────────────────────────────┬──────────────────────┘
             │                                      │
             ▼ UserPromptSubmit                    ▼ Stop
    ┌────────────────┐                    ┌───────────────┐
    │  Hook Handler  │                    │  Hook Handler │
    └────────┬───────┘                    └───────┬───────┘
             │                                      │
             └──────────────┬──────────────────────┘
                            ▼
                 ┌──────────────────────┐
                 │  Event Collector     │
                 │  (Captures events)   │
                 └──────────┬───────────┘
                            │
                            ▼
                 ┌──────────────────────┐
                 │   Event Queue        │
                 │   (Persistent)       │
                 └──────────┬───────────┘
                            │
                            ▼
                 ┌──────────────────────┐
                 │  Sanitization Queue  │
                 │  (Async Worker)      │
                 └──────────┬───────────┘
                            │
                            ▼
              ┌─────────────────────────────┐
              │   Sanitization Pipeline     │
              │  ┌────────────────────────┐ │
              │  │ Rule-Based Detector    │ │
              │  │ (Regex, Fast)          │ │
              │  └──────────┬─────────────┘ │
              │             ▼                │
              │  ┌────────────────────────┐ │
              │  │ AI-Powered Sanitizer   │ │
              │  │ (Context-Aware)        │ │
              │  └──────────┬─────────────┘ │
              │             ▼                │
              │  ┌────────────────────────┐ │
              │  │ Hybrid Validator       │ │
              │  │ (Combine Results)      │ │
              │  └──────────┬─────────────┘ │
              └─────────────┼───────────────┘
                            │
                            ▼ SANITIZED DATA ONLY
                 ┌──────────────────────┐
                 │   SQLite Database    │
                 │  ┌────────────────┐  │
                 │  │ Conversations  │  │
                 │  │ Messages       │  │
                 │  │ Learnings      │  │
                 │  │ Job Queue      │  │
                 │  │ Uploads        │  │
                 │  └────────────────┘  │
                 └──────────┬───────────┘
                            │
                            ▼
                 ┌──────────────────────┐
                 │ Learning Extractor   │
                 │ (Async Worker)       │
                 └──────────┬───────────┘
                            │
                            ▼
                 ┌──────────────────────┐
                 │  Quality Filter      │
                 │  (Score & Validate)  │
                 └──────────┬───────────┘
                            │
                            ├──────────────────┐
                            │                  │
                            ▼                  ▼
                 ┌──────────────────┐  ┌──────────────────┐
                 │   MCP Server     │  │  Mining Queue    │
                 │  (Query Access)  │  │  (Upload)        │
                 └──────────────────┘  └────────┬─────────┘
                            │                    │
                            │                    ▼
                            │         ┌──────────────────┐
                            │         │  IPFS Upload     │
                            │         └────────┬─────────┘
                            │                  │
                            │                  ▼
                            │         ┌──────────────────┐
                            │         │ Blockchain Tx    │
                            │         │ (Token Rewards)  │
                            │         └──────────────────┘
                            │
                            ▼
                 ┌──────────────────────┐
                 │   Agent Clients      │
                 │ (Query via MCP)      │
                 └──────────────────────┘
```

## Core Components

### 1. Event Capture Layer

**Purpose**: Capture Claude Code conversations without blocking the user

**Components**:
- **UserPromptSubmit Hook**: Captures user input
- **Stop Hook**: Captures agent responses
- **Event Collector**: Aggregates events into conversations
- **Event Queue**: Persists events (SQLite-based)

**Key Requirements**:
- Hook execution < 100ms
- Never block user interaction
- Fail silently with logging
- Persist events across restarts

### 2. Sanitization Pipeline

**Purpose**: Remove ALL PII before database storage

**Components**:
- **Rule-Based Detector**: Fast regex-based PII detection
- **AI Sanitizer**: Context-aware detection using LLM
- **Hybrid Validator**: Combines both approaches
- **Audit Logger**: Tracks what was redacted

**PII Categories**:
1. API Keys & Secrets
2. File Paths (absolute with usernames)
3. Email Addresses
4. IP Addresses
5. Names (person names, not variables)
6. Phone Numbers
7. URLs with tokens

**Critical Guarantee**: NEVER store raw data. Sanitization happens BEFORE database insert.

### 3. Storage Layer

**Purpose**: Persist sanitized conversations and learnings

**Database**: SQLite with migrations

**Tables**:
- `conversations`: Sanitized conversation metadata
- `messages`: Individual sanitized messages
- `learnings`: Extracted insights and patterns
- `job_queue`: Async job tracking
- `uploads`: Network upload status
- `sanitization_log`: Audit trail

**Design Principles**:
- ACID compliance
- Indexed for performance (queries < 100ms)
- Versioned migrations
- Transaction-based updates

### 4. Async Processing Layer

**Purpose**: Process jobs without blocking

**Components**:
- **Job Queue**: Persistent, priority-based queue
- **Workers**: Independent job processors
- **Retry Logic**: Exponential backoff
- **Error Handling**: Quarantine failed jobs

**Job Types**:
1. `sanitize_conversation`: Run sanitization pipeline
2. `extract_learning`: Generate learnings
3. `mine_upload`: Upload to network

### 5. Learning Extraction Layer

**Purpose**: Extract valuable, reusable learnings

**Components**:
- **Conversation Analyzer**: Determines if conversation has value
- **Category Extractors**: Specialized by learning type
- **Quality Scorer**: Assigns confidence scores
- **Deduplication**: Prevents duplicate learnings

**Learning Categories**:
- `pattern`: Code patterns and architectures
- `best_practice`: Recommended approaches
- `anti_pattern`: Things to avoid
- `bug_fix`: Problem-solving strategies
- `optimization`: Performance improvements
- `tool_usage`: How to use tools/libraries
- `workflow`: Development workflows
- `decision`: Architecture decisions

**Quality Requirements**:
- Confidence score ≥ 0.6
- Content length ≥ 100 characters
- Well-categorized with tags
- Not trivial or generic

### 6. Query Interface (MCP Server)

**Purpose**: Enable agents to query learnings

**Protocol**: Model Context Protocol (MCP)

**Tools**:
- `search_learnings`: Query by text, category, tags
- `get_learning_by_id`: Retrieve specific learning
- `get_learning_context`: Full conversation for learning

**Resources**:
- `context://learnings/recent`: Latest learnings
- `context://learnings/top-rated`: Highest confidence
- `context://stats`: Network statistics

**Performance**: All queries < 200ms

### 7. Network Layer

**Purpose**: Share learnings globally with rewards

**Components**:
- **IPFS Client**: Decentralized storage
- **Blockchain Integration**: Transaction handling
- **Token System**: Reward calculation
- **Validator Network**: Quality validation (future)

**Upload Process**:
1. Learning queued for upload
2. Content uploaded to IPFS → CID generated
3. Blockchain transaction with CID
4. Token reward calculated
5. Status tracked in uploads table

## Data Flow

### Happy Path: Conversation → Global Network

```
1. User interacts with Claude Code
   ↓
2. Hooks capture UserPromptSubmit + Stop events
   ↓
3. Events queued (< 100ms, non-blocking)
   ↓
4. Async worker picks up sanitization job
   ↓
5. Sanitization pipeline removes ALL PII
   ↓
6. Sanitized data stored in SQLite
   ↓
7. Learning extraction job queued
   ↓
8. Async worker extracts learnings
   ↓
9. Quality filter scores and filters learnings
   ↓
10. High-quality learnings queued for upload
   ↓
11. Mining worker uploads to IPFS
   ↓
12. Blockchain transaction records upload
   ↓
13. Token reward distributed
   ↓
14. Other agents query via MCP server
```

## Privacy Guarantees

### Zero-Trust PII Handling

**Rule 1**: Never store unsanitized data
**Rule 2**: Sanitize before database insertion
**Rule 3**: Audit all redactions
**Rule 4**: User control over uploads

### Sanitization Validation

**Rule-Based Layer** (Fast, Deterministic):
- Regex patterns for known PII formats
- < 1% false positive rate
- Processing time < 10ms

**AI Layer** (Accurate, Context-Aware):
- LLM-based context analysis
- Distinguishes names from variables
- Handles company-specific terminology
- < 5% false negative rate

**Hybrid Validation**:
- Rules catch obvious cases quickly
- AI validates and enhances
- Combined result sanitized
- Audit log tracks all detections

## Performance Requirements

| Component | Requirement | Rationale |
|-----------|-------------|-----------|
| Hook Execution | < 100ms | Never block user |
| Event Queueing | < 50ms | Fast persistence |
| Sanitization | < 2s per conversation | Acceptable async delay |
| Database Queries | < 100ms | Responsive queries |
| MCP Queries | < 200ms | Agent experience |
| Learning Extraction | < 5s per conversation | Background processing |

## Scalability Considerations

### Current (MVP)
- Single SQLite database
- Local processing
- File-based queue

### Future Scaling
- PostgreSQL for multi-user
- Distributed job queue (Redis)
- Horizontal worker scaling
- CDN for IPFS content
- Sharded blockchain integration

## Security Model

### Threat Model

**Threats Addressed**:
1. PII Leakage → Sanitization before storage
2. Unauthorized Access → Local-first architecture
3. Data Corruption → ACID transactions
4. Injection Attacks → Parameterized queries
5. Secret Exposure → Hook-level filtering

**Future Threats**:
1. Network Byzantine actors → Validator consensus
2. Spam/Junk learnings → Quality scoring + validation
3. Sybil attacks → Identity verification
4. Reward manipulation → Multi-validator consensus

### Access Control

**MVP**: Local-only access (single user)

**Future**:
- Multi-user authentication
- Role-based access control
- API key management for MCP
- Encrypted storage option

## Technology Stack

| Layer | Technology | Rationale |
|-------|-----------|-----------|
| Runtime | Node.js + TypeScript | Type safety, async-first |
| Database | SQLite | Simple, embedded, ACID |
| Testing | Vitest | Fast, modern, TypeScript-first |
| Sanitization | Regex + Claude API | Hybrid approach |
| MCP Server | @modelcontextprotocol/sdk | Standard protocol |
| Blockchain | TBD (Ethereum/Celestia) | EVM compatibility |
| Storage | IPFS | Decentralized, content-addressed |
| Queue | SQLite-based | Simple, persistent |

## Error Handling

### Graceful Degradation

**Hooks Fail**: Log error, don't block user
**Sanitization Fails**: Quarantine conversation, alert
**Learning Extraction Fails**: Mark for manual review
**Upload Fails**: Retry with exponential backoff
**MCP Query Fails**: Return empty with error message

### Recovery Strategies

1. **Job Retries**: Max 3 attempts with backoff
2. **Dead Letter Queue**: Failed jobs for analysis
3. **Manual Review**: Quarantine for complex cases
4. **Rollback**: Database migrations reversible
5. **Audit Trail**: Full logging for debugging

## Testing Strategy

### Test Pyramid

- **70% Unit Tests**: Isolated component testing
- **20% Integration Tests**: Component interactions
- **10% E2E Tests**: Full system workflows

### Critical Test Coverage

1. **Sanitization**: Zero PII leaks in 1000+ test cases
2. **Hooks**: Non-blocking, error handling
3. **Queue**: No job loss, proper ordering
4. **Database**: ACID compliance, concurrency
5. **MCP**: Protocol compliance, performance

### Claude-Powered Testing Harness

Uses Claude Agent SDK to:
- Generate comprehensive test suites
- Validate test quality
- Verify implementations
- Enforce quality gates

## Deployment Architecture

### MVP (Local Development)
```
User Machine:
  - Claude Code with hooks
  - SQLite database
  - Background workers
  - MCP server (local)
```

### Production (Future)
```
User Machines:
  - Claude Code with hooks
  - Local SQLite cache
  - MCP client

Cloud Infrastructure:
  - PostgreSQL cluster
  - Worker pool (auto-scaling)
  - MCP server (HA)
  - IPFS node/gateway
  - Blockchain node
```

## Integration Points

### Claude Code Hooks
- Configuration via `hooks.json`
- Scripts in `.claude/hooks/`
- Environment variables for paths

### MCP Protocol
- Standard MCP server implementation
- Claude Code auto-discovery
- Tool and resource definitions

### Blockchain
- Smart contract for rewards
- Event listening for confirmations
- Wallet integration for payouts

### IPFS
- Content upload via API
- CID generation and tracking
- Gateway for content retrieval

## Monitoring & Observability

### Key Metrics

**Performance**:
- Hook execution time
- Sanitization duration
- Query response time
- Job processing rate

**Quality**:
- PII detection rate
- Learning confidence scores
- Test coverage percentage
- Quality gate pass rate

**Business**:
- Conversations captured
- Learnings extracted
- Network uploads
- Token rewards distributed

### Logging Strategy

1. **Structured Logging**: JSON format
2. **Log Levels**: DEBUG, INFO, WARN, ERROR
3. **Correlation IDs**: Track conversation flow
4. **Audit Trail**: All PII redactions
5. **Performance Metrics**: Timing for all operations

## Related Documents

### Architecture
- [Subagent System](./architecture-subagent-system-2025-01-16.md)
- [Testing Harness](./architecture-testing-harness-2025-01-16.md)
- [Sanitization Pipeline](./architecture-sanitization-pipeline-2025-01-16.md)
- [Database Schema](./architecture-database-schema-2025-01-16.md)

### Decisions
- [ADR: Use Claude Hooks](../decisions/decision-use-claude-hooks-2025-01-16.md)
- [ADR: Sanitize Before Storage](../decisions/decision-sanitize-before-storage-2025-01-16.md)
- [ADR: Subagent-Driven Development](../decisions/decision-subagent-driven-development-2025-01-16.md)

### Plans
- [Implementation Roadmap](../plans/plan-implementation-roadmap-2025-01-16.md)
- [Original User Vision](../plans/plan-original-user-vision-2025-01-16.md)

### Reference
- [Database Schema Reference](../reference/reference-database-schema-2025-01-16.md)
- [Testing Strategy](../reference/reference-testing-strategy-2025-01-16.md)

================
File: architecture/architecture-hooks-event-capture-2025-01-16.md
================
# Hooks and Event Capture Architecture

> Low-latency event capture system using Claude Code hooks without blocking user interactions

---
title: Hooks and Event Capture Architecture
category: architecture
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [hooks, event-capture, performance, async, non-blocking]
---

## Overview

The Hooks and Event Capture system captures every Claude Code interaction (user prompts and agent responses) without impacting user experience. It achieves sub-100ms performance through fire-and-forget async design, persistent queuing, and graceful error handling.

**Core Principle**: Never block the user. Capture everything, fail silently with logging.

## Goals

- Capture 100% of user-agent interactions
- Hook execution < 100ms (p95)
- Non-blocking design (fire-and-forget)
- Crash-safe event persistence
- Zero user-visible errors
- Idempotent event processing

## Non-Goals

- Real-time processing (use async queue)
- Perfect ordering across crashes (eventual consistency OK)
- Capturing internal LLM chain-of-thought (not accessible)
- Network-based event streaming (local-first)

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                     Claude Code                              │
│                 (User Interaction Layer)                     │
└───────────┬─────────────────────────────┬───────────────────┘
            │                              │
            ▼ UserPromptSubmit             ▼ Stop
   ┌────────────────┐            ┌────────────────┐
   │  Hook Handler  │            │  Hook Handler  │
   │  (< 50ms)      │            │  (< 50ms)      │
   └────────┬───────┘            └───────┬────────┘
            │                             │
            ├─────────────────────────────┘
            │
            ▼ serialize + enqueue (fire-and-forget)
   ┌────────────────────────────────────────────┐
   │         Event Collector                     │
   │  ┌──────────────────────────────────────┐  │
   │  │  - Assign conversation_id            │  │
   │  │  - Assign message_id                 │  │
   │  │  - Add sequence number               │  │
   │  │  - Add timestamps                    │  │
   │  │  - Add idempotency_key               │  │
   │  └──────────────────────────────────────┘  │
   └────────────┬───────────────────────────────┘
                │
                ▼ persist (WAL mode)
   ┌────────────────────────────────────────────┐
   │      SQLite Event Queue                     │
   │  ┌──────────────────────────────────────┐  │
   │  │  events table                        │  │
   │  │  - id, conversation_id, message_id   │  │
   │  │  - type, role, content, sequence     │  │
   │  │  - idempotency_key, timestamps       │  │
   │  │  - status (pending/processing/done)  │  │
   │  └──────────────────────────────────────┘  │
   └────────────┬───────────────────────────────┘
                │
                ▼ async worker picks up
   ┌────────────────────────────────────────────┐
   │    Sanitization Job Queue                   │
   │    (downstream processing)                  │
   └────────────────────────────────────────────┘
```

## Event Schema

### Event Structure

```typescript
interface CapturedEvent {
  // Identity
  id: string;                    // UUID v4
  conversation_id: string;       // Stable conversation identifier
  message_id: string;            // Unique message identifier
  idempotency_key: string;       // For deduplication

  // Content
  type: 'user_prompt' | 'agent_response';
  role: 'user' | 'assistant';
  content: string;               // Raw content (NOT sanitized yet)
  tool_calls?: ToolCall[];       // Tool invocations
  attachments?: Attachment[];    // File attachments

  // Metadata
  sequence: number;              // Order within conversation
  session_id: string;            // Claude Code session ID
  project_id?: string;           // Project identifier
  created_at: number;            // Unix timestamp (ms)
  hook_name: string;             // 'UserPromptSubmit' | 'Stop'

  // Versioning
  client_version: string;        // Claude Code version
  policy_version: string;        // Sanitization policy version

  // Processing
  status: 'pending' | 'processing' | 'completed' | 'failed';
  processed_at?: number;
  error?: string;
}

interface ToolCall {
  tool: string;
  input: any;
  output?: any;
}

interface Attachment {
  name: string;
  path: string;
  mime_type: string;
  size: number;
}
```

## Hook Implementation

### UserPromptSubmit Hook

**File**: `.claude/hooks/user-prompt-submit.ts`

```typescript
#!/usr/bin/env node
import { captureEvent } from './lib/event-collector';

/**
 * UserPromptSubmit hook
 * Executes BEFORE Claude processes the user's prompt
 * Performance budget: < 50ms
 */
async function main() {
  const startTime = performance.now();

  try {
    // Read hook payload from stdin
    const payload = await readStdin();
    const hookData = JSON.parse(payload);

    // Fire-and-forget event capture
    captureEvent({
      type: 'user_prompt',
      role: 'user',
      content: hookData.prompt,
      tool_calls: hookData.toolCalls,
      attachments: hookData.attachments,
      session_id: hookData.sessionId,
      project_id: hookData.projectId
    }).catch(error => {
      // Log error but don't throw (never block user)
      console.error('[Hook Error]', error);
    });

    // Always succeed quickly
    const duration = performance.now() - startTime;
    if (duration > 50) {
      console.warn(`[Hook Warning] Execution took ${duration}ms (budget: 50ms)`);
    }

  } catch (error) {
    // Silent failure - log only
    console.error('[Hook Critical Error]', error);
  }

  // Exit successfully (never block)
  process.exit(0);
}

main();
```

### Stop Hook

**File**: `.claude/hooks/stop.ts`

```typescript
#!/usr/bin/env node
import { captureEvent } from './lib/event-collector';

/**
 * Stop hook
 * Executes AFTER Claude completes its response
 * Performance budget: < 50ms
 */
async function main() {
  const startTime = performance.now();

  try {
    const payload = await readStdin();
    const hookData = JSON.parse(payload);

    // Fire-and-forget event capture
    captureEvent({
      type: 'agent_response',
      role: 'assistant',
      content: hookData.response,
      tool_calls: hookData.toolCalls,
      session_id: hookData.sessionId,
      project_id: hookData.projectId
    }).catch(error => {
      console.error('[Hook Error]', error);
    });

    const duration = performance.now() - startTime;
    if (duration > 50) {
      console.warn(`[Hook Warning] Execution took ${duration}ms (budget: 50ms)`);
    }

  } catch (error) {
    console.error('[Hook Critical Error]', error);
  }

  process.exit(0);
}

main();
```

### Hook Configuration

**File**: `.claude/hooks.json`

```json
{
  "hooks": {
    "UserPromptSubmit": {
      "script": ".claude/hooks/user-prompt-submit.ts",
      "enabled": true,
      "timeout": 100
    },
    "Stop": {
      "script": ".claude/hooks/stop.ts",
      "enabled": true,
      "timeout": 100
    }
  },
  "config": {
    "eventQueuePath": "${PROJECT_ROOT}/.data/events.db",
    "maxBufferSize": 1000,
    "fallbackToSampling": true,
    "samplingRate": 0.1
  }
}
```

## Event Collector

### Non-Blocking Design

```typescript
// lib/event-collector.ts
import { EventEmitter } from 'events';
import { v4 as uuid } from 'uuid';

/**
 * Fire-and-forget event capture
 * Returns immediately, processes async
 */
export async function captureEvent(event: Partial<CapturedEvent>): Promise<void> {
  // Immediate return - don't await
  setImmediate(() => {
    processEvent(event).catch(error => {
      logger.error('Event processing failed', { error, event });
    });
  });

  // Return immediately (< 1ms)
  return;
}

/**
 * Async event processing
 * Runs in background, never blocks caller
 */
async function processEvent(event: Partial<CapturedEvent>): Promise<void> {
  try {
    // Enrich event with metadata
    const enrichedEvent: CapturedEvent = {
      id: uuid(),
      conversation_id: getOrCreateConversationId(event),
      message_id: uuid(),
      idempotency_key: generateIdempotencyKey(event),
      sequence: getNextSequence(event.conversation_id!),
      session_id: event.session_id || getSessionId(),
      created_at: Date.now(),
      hook_name: event.type === 'user_prompt' ? 'UserPromptSubmit' : 'Stop',
      client_version: getClientVersion(),
      policy_version: getPolicyVersion(),
      status: 'pending',
      ...event
    } as CapturedEvent;

    // Persist to queue (< 10ms with WAL)
    await eventQueue.enqueue(enrichedEvent);

    logger.info('Event captured', {
      conversation_id: enrichedEvent.conversation_id,
      message_id: enrichedEvent.message_id,
      type: enrichedEvent.type
    });

  } catch (error) {
    logger.error('Event enrichment failed', { error, event });
    throw error;
  }
}
```

### Conversation Management

```typescript
// lib/conversation-tracker.ts
const conversationCache = new Map<string, string>();

/**
 * Get or create stable conversation ID
 * Uses session_id + heuristics to group messages
 */
function getOrCreateConversationId(event: Partial<CapturedEvent>): string {
  const sessionId = event.session_id || getSessionId();

  // Check cache
  if (conversationCache.has(sessionId)) {
    return conversationCache.get(sessionId)!;
  }

  // Create new conversation ID
  const conversationId = uuid();
  conversationCache.set(sessionId, conversationId);

  return conversationId;
}

/**
 * Get next sequence number for conversation
 * Ensures ordering within conversation
 */
function getNextSequence(conversationId: string): number {
  // Query database for max sequence
  const result = db.prepare(`
    SELECT COALESCE(MAX(sequence), 0) as max_seq
    FROM events
    WHERE conversation_id = ?
  `).get(conversationId);

  return (result?.max_seq || 0) + 1;
}
```

## Event Queue Persistence

### SQLite Configuration

```typescript
// lib/event-queue.ts
import Database from 'better-sqlite3';

class EventQueue {
  private db: Database.Database;

  constructor(dbPath: string) {
    this.db = new Database(dbPath);

    // Performance optimizations
    this.db.pragma('journal_mode = WAL');        // Write-ahead logging
    this.db.pragma('synchronous = NORMAL');      // Balanced safety/speed
    this.db.pragma('foreign_keys = ON');
    this.db.pragma('busy_timeout = 5000');

    this.initializeSchema();
  }

  private initializeSchema(): void {
    this.db.exec(`
      CREATE TABLE IF NOT EXISTS events (
        id TEXT PRIMARY KEY,
        conversation_id TEXT NOT NULL,
        message_id TEXT NOT NULL,
        idempotency_key TEXT NOT NULL UNIQUE,

        type TEXT NOT NULL,
        role TEXT NOT NULL,
        content TEXT NOT NULL,
        tool_calls TEXT,
        attachments TEXT,

        sequence INTEGER NOT NULL,
        session_id TEXT NOT NULL,
        project_id TEXT,
        created_at INTEGER NOT NULL,
        hook_name TEXT NOT NULL,

        client_version TEXT NOT NULL,
        policy_version TEXT NOT NULL,

        status TEXT NOT NULL DEFAULT 'pending',
        processed_at INTEGER,
        error TEXT,

        CHECK(type IN ('user_prompt', 'agent_response')),
        CHECK(role IN ('user', 'assistant')),
        CHECK(status IN ('pending', 'processing', 'completed', 'failed'))
      );

      CREATE INDEX IF NOT EXISTS idx_events_conversation
        ON events(conversation_id, sequence);

      CREATE INDEX IF NOT EXISTS idx_events_status
        ON events(status, created_at);

      CREATE INDEX IF NOT EXISTS idx_events_session
        ON events(session_id, created_at);
    `);
  }

  /**
   * Enqueue event (< 10ms with WAL)
   * Idempotent via idempotency_key
   */
  async enqueue(event: CapturedEvent): Promise<void> {
    const insert = this.db.prepare(`
      INSERT OR IGNORE INTO events (
        id, conversation_id, message_id, idempotency_key,
        type, role, content, tool_calls, attachments,
        sequence, session_id, project_id, created_at, hook_name,
        client_version, policy_version, status
      ) VALUES (
        ?, ?, ?, ?,
        ?, ?, ?, ?, ?,
        ?, ?, ?, ?, ?,
        ?, ?, ?
      )
    `);

    insert.run(
      event.id,
      event.conversation_id,
      event.message_id,
      event.idempotency_key,
      event.type,
      event.role,
      event.content,
      JSON.stringify(event.tool_calls || []),
      JSON.stringify(event.attachments || []),
      event.sequence,
      event.session_id,
      event.project_id,
      event.created_at,
      event.hook_name,
      event.client_version,
      event.policy_version,
      event.status
    );
  }

  /**
   * Dequeue pending events for processing
   */
  async dequeue(limit: number = 10): Promise<CapturedEvent[]> {
    const events = this.db.prepare(`
      SELECT * FROM events
      WHERE status = 'pending'
      ORDER BY created_at ASC
      LIMIT ?
    `).all(limit);

    return events.map(row => ({
      ...row,
      tool_calls: JSON.parse(row.tool_calls || '[]'),
      attachments: JSON.parse(row.attachments || '[]')
    }));
  }
}
```

### Idempotency

```typescript
/**
 * Generate idempotency key for deduplication
 * Ensures retry-safe operations
 */
function generateIdempotencyKey(event: Partial<CapturedEvent>): string {
  const components = [
    event.session_id,
    event.type,
    event.content?.slice(0, 100), // First 100 chars
    event.created_at
  ];

  return createHash('sha256')
    .update(components.join('|'))
    .digest('hex');
}
```

## Performance Optimizations

### Backpressure Handling

```typescript
// lib/backpressure.ts
class BackpressureManager {
  private bufferSize: number = 0;
  private maxBufferSize: number = 1000;
  private samplingRate: number = 1.0;

  async handleEvent(event: Partial<CapturedEvent>): Promise<boolean> {
    // Check buffer size
    this.bufferSize = await this.getQueueSize();

    if (this.bufferSize > this.maxBufferSize) {
      // Apply sampling
      if (Math.random() > this.samplingRate) {
        logger.warn('Event dropped due to backpressure', {
          bufferSize: this.bufferSize,
          samplingRate: this.samplingRate
        });
        return false;
      }
    }

    // Process event
    await captureEvent(event);
    return true;
  }

  private async getQueueSize(): Promise<number> {
    const result = db.prepare(`
      SELECT COUNT(*) as count
      FROM events
      WHERE status = 'pending'
    `).get();

    return result?.count || 0;
  }
}
```

### Streaming Handling

```typescript
// lib/streaming-handler.ts
class StreamingHandler {
  private partialBuffers = new Map<string, string>();

  handlePartial(sessionId: string, chunk: string): void {
    // Buffer partial chunks
    const existing = this.partialBuffers.get(sessionId) || '';
    this.partialBuffers.set(sessionId, existing + chunk);
  }

  async handleComplete(sessionId: string, final?: string): Promise<void> {
    // Get buffered content
    const buffered = this.partialBuffers.get(sessionId) || '';
    const content = final || buffered;

    // Capture complete event
    await captureEvent({
      session_id: sessionId,
      type: 'agent_response',
      role: 'assistant',
      content
    });

    // Clear buffer
    this.partialBuffers.delete(sessionId);
  }

  // Cleanup stale buffers
  cleanup(): void {
    const now = Date.now();
    for (const [sessionId, _] of this.partialBuffers) {
      const lastUpdate = this.getLastUpdate(sessionId);
      if (now - lastUpdate > 60000) { // 1 minute timeout
        this.partialBuffers.delete(sessionId);
      }
    }
  }
}
```

## Error Handling

### Graceful Degradation

```typescript
// lib/error-handler.ts
class HookErrorHandler {
  async safeExecute<T>(
    operation: () => Promise<T>,
    fallback: T
  ): Promise<T> {
    try {
      return await operation();
    } catch (error) {
      logger.error('Hook operation failed', { error });

      // Emit metric
      metrics.increment('hook.error', {
        operation: operation.name
      });

      // Return fallback (never throw to caller)
      return fallback;
    }
  }

  handleCriticalError(error: Error): void {
    // Log to file (don't rely on network)
    appendFileSync(
      '.data/hook-errors.log',
      JSON.stringify({ timestamp: Date.now(), error: error.message }) + '\n'
    );

    // Attempt to emit metric
    metrics.increment('hook.critical_error').catch(() => {});
  }
}
```

### Recovery Strategies

```typescript
// lib/recovery.ts
class RecoveryManager {
  /**
   * Recover from crashed queue
   * Reset stuck events to pending
   */
  async recoverQueue(): Promise<void> {
    const updated = db.prepare(`
      UPDATE events
      SET status = 'pending', error = 'Recovered from crash'
      WHERE status = 'processing'
        AND created_at < ?
    `).run(Date.now() - 300000); // 5 minutes ago

    logger.info('Queue recovery completed', {
      recovered: updated.changes
    });
  }

  /**
   * Cleanup old completed events
   */
  async cleanup(retentionDays: number = 7): Promise<void> {
    const cutoff = Date.now() - (retentionDays * 24 * 60 * 60 * 1000);

    const deleted = db.prepare(`
      DELETE FROM events
      WHERE status = 'completed'
        AND processed_at < ?
    `).run(cutoff);

    logger.info('Event cleanup completed', {
      deleted: deleted.changes
    });
  }
}
```

## Security Considerations

### Hook Sandboxing

```typescript
// Deny network egress in hooks
process.env.NODE_ENV = 'hook';
process.env.NO_PROXY = '*';

// Restrict file system access
const allowedPaths = [
  path.join(PROJECT_ROOT, '.data'),
  path.join(PROJECT_ROOT, '.claude')
];

function validatePath(filePath: string): boolean {
  const resolved = path.resolve(filePath);
  return allowedPaths.some(allowed => resolved.startsWith(allowed));
}
```

### Log Sanitization

```typescript
// Never log sensitive data in hooks
function sanitizeLogData(data: any): any {
  const sanitized = { ...data };

  // Remove potential PII fields
  delete sanitized.content;
  delete sanitized.tool_calls;
  delete sanitized.attachments;

  return sanitized;
}

logger.info('Event captured', sanitizeLogData(event));
```

## Monitoring

### Key Metrics

```typescript
// Metrics to track
metrics.timing('hook.execution_time', duration);
metrics.increment('hook.success');
metrics.increment('hook.error');
metrics.gauge('event_queue.size', queueSize);
metrics.timing('event_queue.enqueue_time', enqueueDuration);
```

### Health Checks

```typescript
// Health check endpoint
async function healthCheck(): Promise<HealthStatus> {
  return {
    queue: {
      size: await getQueueSize(),
      oldestEvent: await getOldestEventAge()
    },
    hooks: {
      enabled: areHooksEnabled(),
      lastExecution: getLastExecutionTime()
    }
  };
}
```

## Related Documents

### Architecture
- [Global Context Network](./architecture-global-context-network-2025-01-16.md)
- [Sanitization Pipeline](./architecture-sanitization-pipeline-2025-01-16.md)
- [Database Schema](./architecture-database-schema-2025-01-16.md)

### Reference
- [Event Schema Reference](../reference/reference-event-schema-2025-01-16.md)
- [Hook Configuration](../reference/reference-hook-configuration-2025-01-16.md)

================
File: architecture/architecture-subagent-system-2025-01-16.md
================
# Subagent System Architecture

> Architecture for subagent-driven development using Claude Agent SDK

---
title: Subagent System Architecture
category: architecture
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [subagents, claude-agent-sdk, development-workflow, parallelization]
---

## Overview

The Global Context Network uses a **subagent-driven development model** where ALL implementation and testing is delegated to specialized Claude agents. This ensures focused expertise, parallel execution, and built-in quality validation.

**Core Principle**: Never implement directly - always delegate to specialized subagents.

## Architecture

```
┌──────────────────────────────────────────────────────────────────┐
│                    Main Orchestrator Agent                        │
│                  (Claude Code Main Session)                       │
└────────────┬───────────────────────────────┬─────────────────────┘
             │                                │
             ▼ Delegation                    ▼ Delegation
┌────────────────────────┐      ┌────────────────────────┐
│ Implementation Subagent│      │    Test Subagent       │
│  - Reads requirements  │      │  - Generates tests     │
│  - Writes code         │      │  - Validates quality   │
│  - Runs locally        │      │  - Checks coverage     │
└────────────┬───────────┘      └────────────┬───────────┘
             │                                │
             │                                │
             ▼                                ▼
┌────────────────────────┐      ┌────────────────────────┐
│  Quality Gate Subagent │◄─────┤ Integration Subagent   │
│  - Lint + Type Check   │      │  - Component testing   │
│  - Security scan       │      │  - E2E validation      │
│  - Performance review  │      │  - Regression check    │
└────────────────────────┘      └────────────────────────┘
```

## Subagent Types

### 1. Implementation Subagents

**Purpose**: Build features and components

**Specialized By Phase**:

| Phase | Subagent | Responsibility | Tools |
|-------|----------|----------------|-------|
| 0 | `foundation-setup-agent` | TypeScript + Vitest setup | Write, Bash, Read |
| 0 | `database-schema-agent` | Schema + migrations | Write, Bash |
| 0 | `test-infrastructure-agent` | Test utilities | Write, Read |
| 1 | `hook-developer-agent` | Hook scripts | Write, Bash, Read |
| 1 | `event-collector-agent` | Event aggregation | Write, Read |
| 1 | `queue-system-agent` | Persistent queue | Write, Bash |
| 2 | `rule-sanitizer-agent` | Regex PII detection | Write, Read |
| 2 | `ai-sanitizer-agent` | LLM sanitization | Write, Read |
| 2 | `sanitization-pipeline-agent` | Pipeline orchestration | Write, Read |
| 3 | `repository-agent` | Repository pattern | Write, Read |
| 3 | `query-optimization-agent` | Indexes + queries | Write, Bash |
| 4 | `job-queue-agent` | Queue implementation | Write, Read |
| 4 | `worker-agent` | Worker processes | Write, Bash |
| 5 | `learning-extractor-agent` | Extraction pipeline | Write, Read |
| 5 | `quality-filter-agent` | Scoring + filtering | Write, Read |
| 6 | `mcp-protocol-agent` | MCP implementation | Write, Read |
| 6 | `query-optimization-agent` | Search + filtering | Write, Bash |
| 7 | `ipfs-integration-agent` | IPFS uploads | Write, Bash |
| 7 | `blockchain-agent` | Blockchain transactions | Write, Bash |

**Configuration Example**:
```typescript
{
  "hook-developer-agent": {
    description: "Implements Claude Code hooks for event capture",
    prompt: `You are a Claude Code hooks expert. Implement:
    - UserPromptSubmit hook (< 100ms)
    - Stop hook (< 100ms)
    - Event serialization
    - Error handling (never block user)
    Follow TDD: write tests first.`,
    tools: ["Write", "Read", "Bash", "mcp__test-runner__run_unit_tests"],
    model: "sonnet"
  }
}
```

### 2. Test Generation Subagents

**Purpose**: Create comprehensive test suites

**Types**:

**Unit Test Generator**:
```typescript
{
  "unit-test-generator": {
    description: "Generates unit tests with 100% coverage target",
    prompt: `Generate unit tests following TDD:
    - Test each function in isolation
    - Cover edge cases and boundaries
    - Test error conditions
    - Use proper arrange-act-assert
    - Mock external dependencies
    Target: > 85% coverage`,
    tools: ["Write", "Read", "mcp__test-runner__validate_test_quality"],
    model: "sonnet"
  }
}
```

**Integration Test Generator**:
```typescript
{
  "integration-test-generator": {
    description: "Creates integration tests for component interactions",
    prompt: `Generate integration tests:
    - Test component interactions
    - Use real dependencies where safe
    - Test database transactions
    - Verify async behavior
    - Check error propagation`,
    tools: ["Write", "Read", "Bash", "mcp__test-runner__run_integration_tests"],
    model: "sonnet"
  }
}
```

**E2E Test Generator**:
```typescript
{
  "e2e-test-generator": {
    description: "Creates end-to-end workflow tests",
    prompt: `Generate E2E tests:
    - Test complete user workflows
    - Hook → Database → MCP flow
    - Sanitization → Learning → Upload flow
    - Verify system behavior
    - Test failure scenarios`,
    tools: ["Write", "Read", "Bash", "mcp__test-runner__run_e2e_tests"],
    model: "sonnet"
  }
}
```

### 3. Test Validation Subagents

**Purpose**: Validate test quality and implementation

**Test Quality Validator**:
```typescript
{
  "test-quality-validator": {
    description: "Reviews test code quality and completeness",
    prompt: `Validate tests for:
    - Proper structure (describe, it, expect)
    - Clear test names
    - Complete edge case coverage
    - Proper assertions (not just truthy)
    - No flaky tests
    - Maintainability
    Score each test 0-1. Require > 0.8 to pass.`,
    tools: ["Read", "Grep", "mcp__test-runner__validate_test_quality"],
    model: "sonnet"
  }
}
```

**Coverage Validator**:
```typescript
{
  "coverage-validator": {
    description: "Ensures adequate test coverage",
    prompt: `Analyze coverage:
    - Lines, statements, functions, branches
    - Identify uncovered code paths
    - Flag critical missing tests
    - Require > 85% coverage
    - No untested error handlers`,
    tools: ["Read", "Bash", "mcp__test-runner__get_coverage_report"],
    model: "haiku"
  }
}
```

**Implementation Validator**:
```typescript
{
  "implementation-validator": {
    description: "Validates implementation against tests",
    prompt: `Verify implementation:
    - All tests pass
    - Handles all edge cases from tests
    - Proper error handling
    - No security vulnerabilities
    - Follows coding standards
    - Performance acceptable`,
    tools: ["Read", "Grep", "Bash", "mcp__test-runner__run_unit_tests"],
    model: "sonnet"
  }
}
```

### 4. Quality Gate Subagents

**Purpose**: Enforce standards before merge

**Code Quality Validator**:
```typescript
{
  "code-quality-validator": {
    description: "Reviews code quality and standards",
    prompt: `Review code for:
    - TypeScript strict mode compliance
    - ESLint rule adherence
    - Prettier formatting
    - Proper type annotations
    - Clear naming conventions
    - DRY principles
    - SOLID principles
    All checks must pass.`,
    tools: ["Read", "Bash", "Grep"],
    model: "sonnet"
  }
}
```

**Security Validator**:
```typescript
{
  "security-validator": {
    description: "Scans for security vulnerabilities",
    prompt: `Security audit:
    - SQL injection vulnerabilities
    - Command injection risks
    - Path traversal attempts
    - Hardcoded secrets
    - Insecure dependencies
    - XSS vectors
    Block if any critical issues found.`,
    tools: ["Read", "Bash", "Grep"],
    model: "sonnet"
  }
}
```

**Performance Validator**:
```typescript
{
  "performance-validator": {
    description: "Analyzes performance characteristics",
    prompt: `Analyze performance:
    - Algorithm complexity
    - Database query efficiency
    - Memory usage patterns
    - Blocking operations
    - Resource leaks
    Flag performance regressions.`,
    tools: ["Read", "Bash", "Grep"],
    model: "sonnet"
  }
}
```

## Subagent Workflow

### TDD Cycle with Subagents

```
1. 🔴 RED Phase (Test Generator Subagent)
   ├─► Generate failing test
   ├─► Validate test quality (Test Quality Validator)
   └─► Ensure test properly fails

2. 🟢 GREEN Phase (Implementation Subagent)
   ├─► Write minimal code to pass test
   ├─► Run tests continuously
   └─► Validate implementation (Implementation Validator)

3. 🔵 REFACTOR Phase (Refactor Subagent)
   ├─► Improve code quality
   ├─► Maintain passing tests
   └─► Re-validate quality (Code Quality Validator)

4. ✅ QUALITY GATE (Quality Gate Subagents)
   ├─► Run all validators in parallel
   ├─► Coverage > 85%
   ├─► Security scan passes
   ├─► Performance acceptable
   └─► All gates MUST pass
```

### Parallel Execution

Subagents can run in parallel when independent:

```typescript
// Phase 0 example: Parallel execution
const response = query({
  prompt: "Implement Phase 0 Foundation",
  options: {
    agents: {
      "foundation-setup": { ... },
      "database-schema": { ... },
      "test-infrastructure": { ... }
    }
  }
});

// All three agents work simultaneously
// Main agent coordinates and integrates results
```

### Sequential Dependencies

Some subagents must wait for others:

```
foundation-setup ─► database-schema ─► test-infrastructure
                    (needs project)    (needs database)
```

## Subagent Communication

### Via Main Agent

Subagents communicate through the main orchestrator:

```typescript
// Main agent delegates
const testGenResult = await runSubagent("unit-test-generator", {...});

// Main agent passes results to next subagent
const implResult = await runSubagent("implementation-agent", {
  tests: testGenResult.tests
});

// Main agent validates
const validationResult = await runSubagent("implementation-validator", {
  implementation: implResult.code,
  tests: testGenResult.tests
});
```

### Via Shared Context

Subagents can access shared resources:
- File system (read/write)
- Database (queries)
- Test results (via MCP tools)
- Coverage reports (via MCP tools)

## Benefits of Subagent Architecture

### 1. Specialization
Each subagent is expert in its domain:
- Hook developer knows hook best practices
- Test generator knows testing patterns
- Security validator knows OWASP top 10

### 2. Parallelization
Independent tasks run concurrently:
- Multiple components implemented simultaneously
- Tests generated while implementation proceeds
- Validators run in parallel for quality gates

### 3. Quality Assurance
Built-in validation at every step:
- Test quality validated before implementation
- Implementation validated against tests
- Quality gates enforce standards

### 4. Maintainability
Clear separation of concerns:
- Each subagent has focused responsibility
- Easy to update individual agents
- Consistent patterns across codebase

### 5. Auditability
Complete trace of decisions:
- Each subagent produces artifacts
- Validation results documented
- Quality scores tracked

## Configuration Management

### Subagent Definitions

Stored in configuration files:

```typescript
// subagents/implementation-agents.ts
export const implementationAgents = {
  "hook-developer-agent": { ... },
  "event-collector-agent": { ... },
  // ... more agents
};

// subagents/test-agents.ts
export const testAgents = {
  "unit-test-generator": { ... },
  "integration-test-generator": { ... },
  // ... more agents
};

// subagents/validation-agents.ts
export const validationAgents = {
  "test-quality-validator": { ... },
  "coverage-validator": { ... },
  // ... more agents
};
```

### Agent Orchestration

```typescript
import { query } from "@anthropic-ai/claude-agent-sdk";
import { implementationAgents, testAgents, validationAgents } from './subagents';

export async function implementPhase(phaseNumber: number) {
  const response = query({
    prompt: `Implement Phase ${phaseNumber} following TDD`,
    options: {
      model: "claude-sonnet-4-5",
      agents: {
        ...implementationAgents,
        ...testAgents,
        ...validationAgents
      },
      mcpServers: {
        "test-runner": testRunnerServer
      }
    }
  });

  for await (const message of response) {
    // Process subagent communications
    if (message.type === 'system' && message.subtype === 'subagent_start') {
      console.log(`Starting: ${message.agent_name}`);
    }
    if (message.type === 'system' && message.subtype === 'subagent_end') {
      console.log(`Completed: ${message.agent_name}`);
    }
  }
}
```

## Error Handling

### Subagent Failures

**Retry Logic**:
```typescript
async function runWithRetry(subagentName: string, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await runSubagent(subagentName);
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await sleep(2 ** i * 1000); // Exponential backoff
    }
  }
}
```

**Fallback Strategies**:
- If test generator fails → Manual test creation prompt
- If implementation fails → Simplify requirements
- If validator fails → Manual review required

### Quality Gate Failures

**Block and Report**:
```typescript
if (validationResult.coverageScore < 0.85) {
  throw new Error(`Coverage ${validationResult.coverageScore} < 0.85 required`);
}

if (validationResult.securityIssues.length > 0) {
  throw new Error(`Security issues: ${validationResult.securityIssues.join(', ')}`);
}
```

## Performance Optimization

### Selective Subagent Invocation

Don't invoke all subagents for every task:

```typescript
// Simple task: minimal validation
if (task.complexity === 'simple') {
  agents = ['implementation-agent', 'unit-test-generator'];
}

// Complex task: full validation
if (task.complexity === 'complex') {
  agents = [
    'implementation-agent',
    'unit-test-generator',
    'integration-test-generator',
    'test-quality-validator',
    'code-quality-validator',
    'security-validator'
  ];
}
```

### Caching Results

Cache subagent results to avoid re-runs:

```typescript
const cache = new Map<string, SubagentResult>();

async function getCachedSubagentResult(name: string, input: any) {
  const key = `${name}:${JSON.stringify(input)}`;
  if (cache.has(key)) {
    return cache.get(key);
  }
  const result = await runSubagent(name, input);
  cache.set(key, result);
  return result;
}
```

## Monitoring & Metrics

### Subagent Performance

Track subagent execution:
- Invocation count
- Success rate
- Average duration
- Error types

### Quality Metrics

Track validation results:
- Test coverage trends
- Quality gate pass rate
- Security issue count
- Performance regression count

## Related Documents

### Architecture
- [Global Context Network](./architecture-global-context-network-2025-01-16.md)
- [Testing Harness](./architecture-testing-harness-2025-01-16.md)

### Decisions
- [ADR: Subagent-Driven Development](../decisions/decision-subagent-driven-development-2025-01-16.md)

### Guides
- [Using Subagents](../guides/guide-using-subagents-2025-01-16.md)
- [TDD Workflow](../guides/guide-tdd-workflow-2025-01-16.md)

### Reference
- [Subagent Types](../reference/reference-subagent-types-2025-01-16.md)
- [Claude Agent SDK API](../reference/reference-claude-agent-sdk-api-2025-01-16.md)

================
File: architecture/architecture-testing-harness-2025-01-16.md
================
# Testing Harness Architecture

> Claude-powered testing infrastructure with TDD enforcement and quality gates

---
title: Testing Harness Architecture
category: architecture
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [testing, claude-agent-sdk, tdd, quality-gates, subagents]
---

## Overview

The Testing Harness is a Claude-powered infrastructure that ensures code quality through Test-Driven Development (TDD), automated test generation, continuous validation, and quality gate enforcement. It leverages the Claude Agent SDK to create specialized subagents for different testing concerns.

**Core Principle**: Every feature is test-first, every test is validated, every implementation is verified.

## Goals

- Enforce TDD workflow (Red-Green-Refactor)
- Generate comprehensive test suites automatically
- Validate test quality and coverage
- Ensure zero regressions through continuous testing
- Provide fast feedback loops (< 30s for unit tests)
- Support deterministic testing for LLM-powered components

## Non-Goals

- Manual test writing (delegated to subagents)
- UI-based test runners (CLI-only for MVP)
- Cross-browser testing (not needed for Node.js backend)
- Performance testing (covered separately)

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                   Claude Agent SDK                           │
│                  (Main Orchestrator)                         │
└──────────┬──────────────────────────────────────────────────┘
           │
           ├──────────────────────────────────────┐
           │                                       │
           ▼ Delegation                           ▼ Delegation
┌──────────────────────────┐          ┌──────────────────────────┐
│  Test Generator Subagent │          │ Test Validator Subagent  │
│  ┌────────────────────┐  │          │  ┌────────────────────┐  │
│  │ Unit Test Gen      │  │          │  │ Quality Validator  │  │
│  │ Integration Gen    │  │          │  │ Coverage Validator │  │
│  │ E2E Test Gen       │  │          │  │ Impl Validator     │  │
│  └────────────────────┘  │          │  └────────────────────┘  │
└──────────┬───────────────┘          └───────────┬──────────────┘
           │                                       │
           │                                       │
           ▼                                       ▼
┌──────────────────────────┐          ┌──────────────────────────┐
│   Implementation Agent   │          │  Quality Gate Subagent   │
│  - Writes minimal code   │          │  ┌────────────────────┐  │
│  - Passes tests          │◄─────────┤  │ Lint Validator     │  │
│  - Refactors             │          │  │ Type Validator     │  │
└──────────────────────────┘          │  │ Security Validator │  │
                                       │  │ Performance Check  │  │
                                       │  └────────────────────┘  │
                                       └──────────────────────────┘
           │                                       │
           └───────────────┬───────────────────────┘
                           ▼
                  ┌─────────────────┐
                  │  MCP Test Tool  │
                  │  ┌───────────┐  │
                  │  │ Run Tests │  │
                  │  │ Coverage  │  │
                  │  │ Validate  │  │
                  │  └───────────┘  │
                  └─────────┬───────┘
                            │
                            ▼
                  ┌─────────────────┐
                  │   Vitest        │
                  │   (Test Runner) │
                  └─────────────────┘
```

## Components

### 1. Test Generator Subagents

**Purpose**: Automatically generate comprehensive test suites

#### Unit Test Generator

```typescript
{
  "unit-test-generator": {
    description: "Generates unit tests following TDD principles",
    prompt: `Generate unit tests with these requirements:
    - Test each function in complete isolation
    - Cover all edge cases and boundary conditions
    - Test error conditions thoroughly
    - Use arrange-act-assert pattern
    - Mock all external dependencies
    - Target coverage: > 85% lines, > 80% branches

    Use deterministic fixtures for LLM-powered components.
    Include property-based tests for complex logic.`,
    tools: ["Write", "Read", "mcp__test-runner__run_unit_tests"],
    model: "sonnet-4-5"
  }
}
```

**Key Features**:
- Deterministic testing for LLM steps (fixture-based outputs)
- Property-based testing using fast-check
- Adversarial test cases for PII detection
- Cost controls (local mocks for CI, cloud models for validation)

#### Integration Test Generator

```typescript
{
  "integration-test-generator": {
    description: "Creates integration tests for component interactions",
    prompt: `Generate integration tests:
    - Test real component interactions
    - Use actual database (SQLite in-memory for tests)
    - Verify async behavior and timing
    - Test transaction boundaries
    - Check error propagation paths
    - Validate job queue semantics`,
    tools: ["Write", "Read", "Bash", "mcp__test-runner__run_integration_tests"],
    model: "sonnet-4-5"
  }
}
```

**Key Features**:
- Real database interactions (in-memory SQLite)
- Async behavior verification
- Transaction testing
- Queue semantics validation

#### E2E Test Generator

```typescript
{
  "e2e-test-generator": {
    description: "Creates end-to-end workflow tests",
    prompt: `Generate E2E tests for complete workflows:
    - Hook → Event Queue → Sanitization → Database
    - Learning Extraction → Quality Filter → MCP Query
    - Mining Upload → IPFS → Blockchain
    - Test failure scenarios and recovery
    - Verify data integrity end-to-end`,
    tools: ["Write", "Read", "Bash", "mcp__test-runner__run_e2e_tests"],
    model: "sonnet-4-5"
  }
}
```

**Key Features**:
- Complete system workflows
- Failure scenario testing
- Data integrity verification
- Recovery path validation

### 2. Test Validation Subagents

**Purpose**: Ensure test quality and completeness

#### Test Quality Validator

```typescript
{
  "test-quality-validator": {
    description: "Reviews test code quality",
    prompt: `Validate tests against quality criteria:
    - Proper structure (describe, it, expect with clear names)
    - Complete edge case coverage
    - Strong assertions (not just truthy checks)
    - No flaky tests (deterministic execution)
    - Maintainable code (clear intent, minimal duplication)
    - Performance tests have clear thresholds

    Score each test 0-1. Require score > 0.8 to pass.
    Flag any non-deterministic behavior.`,
    tools: ["Read", "Grep", "mcp__test-runner__validate_test_quality"],
    model: "sonnet-4-5"
  }
}
```

**Quality Criteria**:
- Clear test names describing behavior
- Proper arrange-act-assert structure
- Strong, specific assertions
- Deterministic execution
- No shared mutable state
- Timing-independent

#### Coverage Validator

```typescript
{
  "coverage-validator": {
    description: "Ensures adequate test coverage",
    prompt: `Analyze test coverage:
    - Lines, statements, functions, branches
    - Critical paths MUST be covered
    - Sanitization code > 95% coverage
    - Queue error paths > 90% coverage
    - Hook handlers > 90% coverage
    - Overall target: > 85%

    Flag uncovered critical code.
    Fail if any critical path lacks coverage.`,
    tools: ["Read", "Bash", "mcp__test-runner__get_coverage_report"],
    model: "haiku"
  }
}
```

**Coverage Gates**:
- Sanitization: > 95% lines/branches
- Hooks: > 90% coverage
- Queue: > 90% error paths
- Overall: > 85% coverage
- No untested critical paths

#### Implementation Validator

```typescript
{
  "implementation-validator": {
    description: "Validates implementation against tests",
    prompt: `Verify implementation quality:
    - All tests pass
    - Handles all edge cases from tests
    - Proper error handling (no silent failures)
    - No security vulnerabilities (SQL injection, path traversal)
    - Follows TypeScript strict mode
    - Performance acceptable (within budgets)
    - No LLM over-trust (validate all outputs)`,
    tools: ["Read", "Grep", "Bash", "mcp__test-runner__run_unit_tests"],
    model: "sonnet-4-5"
  }
}
```

**Validation Checks**:
- All tests passing
- Error handling comprehensive
- Security vulnerabilities absent
- Performance within budgets
- Type safety enforced

### 3. Quality Gate Subagents

**Purpose**: Enforce standards before code integration

#### Code Quality Validator

```typescript
{
  "code-quality-validator": {
    description: "Reviews code quality standards",
    prompt: `Review code for quality:
    - TypeScript strict mode compliance
    - ESLint rules adhered to
    - Prettier formatting applied
    - Proper type annotations (no 'any')
    - Clear naming conventions
    - DRY principles followed
    - SOLID principles applied

    All checks MUST pass.`,
    tools: ["Read", "Bash", "Grep"],
    model: "sonnet-4-5"
  }
}
```

**Quality Checks**:
- Lint: ESLint passing
- Types: Strict TypeScript
- Format: Prettier applied
- Style: Naming conventions
- Architecture: SOLID principles

#### Security Validator

```typescript
{
  "security-validator": {
    description: "Scans for security vulnerabilities",
    prompt: `Security audit:
    - SQL injection (use parameterized queries only)
    - Command injection (sanitize shell inputs)
    - Path traversal (validate file paths)
    - Hardcoded secrets (reject commits with secrets)
    - Prompt injection resistance (LLM as stateless classifier)
    - Deserialization risks (validate JSON schemas)
    - Supply chain (check npm dependencies with Socket)

    Block if ANY critical issues found.`,
    tools: ["Read", "Bash", "Grep", "mcp__socket__depscore"],
    model: "sonnet-4-5"
  }
}
```

**Security Checks**:
- SQL injection prevention
- Command injection blocking
- Path traversal validation
- Secrets scanning
- Dependency security (Socket)
- Prompt injection resistance

#### Performance Validator

```typescript
{
  "performance-validator": {
    description: "Analyzes performance characteristics",
    prompt: `Analyze performance:
    - Algorithm complexity (avoid O(n²) in hot paths)
    - Database query efficiency (use EXPLAIN)
    - Memory usage patterns (no leaks)
    - Blocking operations (async where needed)
    - Resource leaks (proper cleanup)

    Performance budgets:
    - Hook execution: < 100ms
    - Event queueing: < 50ms
    - DB queries: < 100ms
    - MCP queries: < 200ms

    Fail if budgets exceeded.`,
    tools: ["Read", "Bash", "Grep"],
    model: "sonnet-4-5"
  }
}
```

**Performance Budgets**:
- Hook execution: < 100ms
- Event queueing: < 50ms
- Database queries: < 100ms
- MCP queries: < 200ms
- Sanitization: < 2s per conversation

### 4. MCP Test Runner Server

**Purpose**: Provide testing tools to subagents

#### Tool Schemas

**run_unit_tests**:
```typescript
{
  name: "run_unit_tests",
  description: "Execute unit tests with coverage",
  inputSchema: {
    type: "object",
    properties: {
      pattern: { type: "string", description: "Test file pattern (e.g., '*.test.ts')" },
      timeout: { type: "number", default: 30000, description: "Timeout in ms" },
      coverage: { type: "boolean", default: true, description: "Collect coverage" }
    }
  },
  outputSchema: {
    type: "object",
    properties: {
      passed: { type: "number" },
      failed: { type: "number" },
      skipped: { type: "number" },
      coverage: {
        type: "object",
        properties: {
          lines: { type: "number" },
          statements: { type: "number" },
          functions: { type: "number" },
          branches: { type: "number" }
        }
      },
      duration: { type: "number" },
      errors: { type: "array", items: { type: "string" } }
    }
  }
}
```

**validate_test_quality**:
```typescript
{
  name: "validate_test_quality",
  description: "Validate test code quality",
  inputSchema: {
    type: "object",
    properties: {
      testFile: { type: "string", description: "Path to test file" }
    },
    required: ["testFile"]
  },
  outputSchema: {
    type: "object",
    properties: {
      score: { type: "number", minimum: 0, maximum: 1 },
      issues: { type: "array", items: { type: "string" } },
      recommendations: { type: "array", items: { type: "string" } }
    }
  }
}
```

**get_coverage_report**:
```typescript
{
  name: "get_coverage_report",
  description: "Get detailed coverage report",
  inputSchema: {
    type: "object",
    properties: {
      format: { type: "string", enum: ["json", "html", "lcov"], default: "json" }
    }
  },
  outputSchema: {
    type: "object",
    properties: {
      summary: {
        type: "object",
        properties: {
          lines: { type: "object" },
          statements: { type: "object" },
          functions: { type: "object" },
          branches: { type: "object" }
        }
      },
      files: { type: "array" },
      uncovered: { type: "array", description: "Critical uncovered paths" }
    }
  }
}
```

## TDD Workflow

### Red-Green-Refactor Cycle

```
1. 🔴 RED Phase
   ├─► Test Generator creates failing test
   ├─► Test Quality Validator reviews test
   ├─► Run test → confirm it fails correctly
   └─► Score test quality (must be > 0.8)

2. 🟢 GREEN Phase
   ├─► Implementation Agent writes minimal code
   ├─► Run tests continuously
   ├─► Implementation Validator checks quality
   └─► All tests passing

3. 🔵 REFACTOR Phase
   ├─► Improve code quality
   ├─► Code Quality Validator reviews
   ├─► Run tests (must still pass)
   └─► Performance Validator checks budgets

4. ✅ QUALITY GATE
   ├─► Lint passing (ESLint)
   ├─► Types passing (TypeScript strict)
   ├─► Coverage > 85%
   ├─► Security scan clean
   ├─► Performance budgets met
   └─► ALL gates MUST pass
```

### Deterministic Testing for LLM Components

**Challenge**: LLM outputs are non-deterministic

**Solution**: Fixture-based testing

```typescript
// tests/fixtures/sanitization-outputs.ts
export const sanitizationFixtures = {
  "test-case-1": {
    input: "My email is john@example.com",
    expected: "My email is <EMAIL_1>",
    piiDetected: [
      { type: "email", value: "john@example.com", replacement: "<EMAIL_1>" }
    ]
  },
  "test-case-2": {
    input: "API key: sk-1234567890abcdef",
    expected: "API key: <API_KEY_1>",
    piiDetected: [
      { type: "api_key", value: "sk-1234567890abcdef", replacement: "<API_KEY_1>" }
    ]
  }
};

// tests/sanitization.test.ts
describe("Sanitization", () => {
  it("should sanitize using fixtures", () => {
    const fixture = sanitizationFixtures["test-case-1"];
    const result = sanitize(fixture.input, { useMock: true });
    expect(result.sanitized).toBe(fixture.expected);
    expect(result.piiDetected).toEqual(fixture.piiDetected);
  });
});
```

**Cost Controls**:
- CI uses local mocks (fixtures)
- Validation uses real LLM (rate-limited)
- Budget caps per day
- Graceful degradation to rules-only

### Property-Based Testing

For complex logic (especially PII detection):

```typescript
import { fc } from "fast-check";

describe("PII Detection Properties", () => {
  it("should detect all email formats", () => {
    fc.assert(
      fc.property(fc.emailAddress(), (email) => {
        const result = detectPII(email);
        return result.some(pii => pii.type === "email");
      })
    );
  });

  it("should be idempotent", () => {
    fc.assert(
      fc.property(fc.string(), (input) => {
        const first = sanitize(input);
        const second = sanitize(first.sanitized);
        return first.sanitized === second.sanitized;
      })
    );
  });
});
```

### Fuzz Testing for PII

```typescript
import { generatePIITestCases } from "./fuzz-generators";

describe("PII Fuzz Tests", () => {
  it("should detect adversarial PII patterns", () => {
    const testCases = generatePIITestCases(1000);

    for (const testCase of testCases) {
      const result = detectPII(testCase.input);
      expect(result.length).toBeGreaterThan(0);
      expect(result.some(pii => pii.type === testCase.expectedType)).toBe(true);
    }
  });
});
```

## Performance Testing

### Performance Test Structure

```typescript
describe("Performance Tests", () => {
  it("hook execution should be < 100ms", async () => {
    const start = performance.now();
    await hookHandler({ type: "UserPromptSubmit", data: sampleData });
    const duration = performance.now() - start;

    expect(duration).toBeLessThan(100);
  });

  it("should handle 100 concurrent events", async () => {
    const events = Array(100).fill(null).map(() => createEvent());
    const start = performance.now();

    await Promise.all(events.map(e => processEvent(e)));

    const duration = performance.now() - start;
    expect(duration).toBeLessThan(5000); // 50ms per event avg
  });
});
```

### Load Testing

```typescript
// tests/load/sanitization-load.test.ts
describe("Sanitization Load Tests", () => {
  it("should maintain performance at 10k conversations", async () => {
    const conversations = generateConversations(10000);

    const start = performance.now();
    for (const conv of conversations) {
      await sanitizeConversation(conv);
    }
    const duration = performance.now() - start;

    const avgDuration = duration / conversations.length;
    expect(avgDuration).toBeLessThan(2000); // < 2s per conversation
  });
});
```

## Error Handling

### Test Execution Errors

**Flaky Tests**:
```typescript
// Detect flaky tests
const results = [];
for (let i = 0; i < 10; i++) {
  results.push(await runTest());
}

const allPassed = results.every(r => r.passed);
const allFailed = results.every(r => !r.passed);

if (!allPassed && !allFailed) {
  throw new Error("Flaky test detected!");
}
```

**Timeout Handling**:
```typescript
// tests/utils/timeout.ts
export async function withTimeout<T>(
  promise: Promise<T>,
  timeoutMs: number
): Promise<T> {
  const timeout = new Promise<never>((_, reject) =>
    setTimeout(() => reject(new Error("Test timeout")), timeoutMs)
  );
  return Promise.race([promise, timeout]);
}
```

### Subagent Failures

**Retry Logic**:
```typescript
async function runSubagentWithRetry(
  subagentName: string,
  maxRetries = 3
): Promise<SubagentResult> {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await runSubagent(subagentName);
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await sleep(2 ** i * 1000); // Exponential backoff
    }
  }
  throw new Error("Max retries exceeded");
}
```

**Fallback Strategies**:
- Test generator fails → Manual test creation prompt
- Implementation fails → Simplify requirements
- Validator fails → Manual review required

## Integration with Claude Agent SDK

### Agent Configuration

```typescript
import { query } from "@anthropic-ai/claude-agent-sdk";

export async function implementFeatureWithTDD(feature: string) {
  const response = query({
    prompt: `Implement ${feature} following strict TDD`,
    options: {
      model: "claude-sonnet-4-5",
      agents: {
        "unit-test-generator": unitTestGeneratorConfig,
        "implementation-agent": implementationAgentConfig,
        "test-quality-validator": testQualityValidatorConfig,
        "coverage-validator": coverageValidatorConfig,
        "code-quality-validator": codeQualityValidatorConfig
      },
      mcpServers: {
        "test-runner": testRunnerServer
      }
    }
  });

  for await (const message of response) {
    if (message.type === 'system' && message.subtype === 'subagent_start') {
      console.log(`Starting: ${message.agent_name}`);
    }
    if (message.type === 'system' && message.subtype === 'subagent_end') {
      console.log(`Completed: ${message.agent_name}`);
    }
  }
}
```

### Local Sandboxing

**Security**: Subagents run in restricted environment

```typescript
// Disable shell access unless explicitly allowed
const subagentConfig = {
  tools: ["Write", "Read"], // NO Bash by default
  allowedPaths: ["/project/src", "/project/tests"], // Restrict file access
  networkAccess: false, // No network by default
  maxExecutionTime: 300000 // 5 minute timeout
};
```

## Monitoring and Metrics

### Key Metrics

**Test Performance**:
- Test execution time (target: < 30s for unit tests)
- Coverage percentage (target: > 85%)
- Flaky test count (target: 0)
- Test quality score (target: > 0.8)

**Quality Gates**:
- Gate pass rate (target: 100%)
- Blocker issues (target: 0)
- Security vulnerabilities (target: 0)
- Performance budget violations (target: 0)

**Subagent Performance**:
- Invocation count per type
- Success rate per subagent
- Average duration per subagent
- Retry rate

### Logging

```typescript
// Structured logging for test runs
logger.info("test_run_started", {
  testType: "unit",
  pattern: "*.test.ts",
  coverage: true,
  timestamp: Date.now()
});

logger.info("test_run_completed", {
  passed: 42,
  failed: 0,
  duration: 15234,
  coverage: { lines: 87.5, branches: 82.3 },
  timestamp: Date.now()
});
```

## Related Documents

### Architecture
- [Global Context Network](./architecture-global-context-network-2025-01-16.md)
- [Subagent System](./architecture-subagent-system-2025-01-16.md)

### Guides
- [TDD Workflow](../guides/guide-tdd-workflow-2025-01-16.md)
- [Testing Harness Usage](../guides/guide-testing-harness-usage-2025-01-16.md)

### Reference
- [Testing Strategy](../reference/reference-testing-strategy-2025-01-16.md)
- [Claude Agent SDK API](../reference/reference-claude-agent-sdk-api-2025-01-16.md)

================
File: architecture/INDEX.md
================
# Architecture Documentation

> Last updated: 2025-01-16

## Overview

This directory contains system design documents, component architectures, and technical specifications for the Global Context Network MVP.

## Documents

### Active Documents

| Date | Document | Status | Description |
|------|----------|--------|-------------|
| 2025-01-16 | [architecture-global-context-network-2025-01-16.md](./architecture-global-context-network-2025-01-16.md) | Active | Complete system architecture overview |
| 2025-01-16 | [architecture-subagent-system-2025-01-16.md](./architecture-subagent-system-2025-01-16.md) | Active | Subagent-driven development architecture |
| 2025-01-16 | [architecture-testing-harness-2025-01-16.md](./architecture-testing-harness-2025-01-16.md) | Active | Claude-powered testing infrastructure |
| 2025-01-16 | [architecture-hooks-event-capture-2025-01-16.md](./architecture-hooks-event-capture-2025-01-16.md) | Active | Hook implementation and event capture system |
| 2025-01-16 | [architecture-sanitization-pipeline-2025-01-16.md](./architecture-sanitization-pipeline-2025-01-16.md) | Active | PII detection and sanitization architecture |
| 2025-01-16 | [architecture-learning-extraction-2025-01-16.md](./architecture-learning-extraction-2025-01-16.md) | Active | Learning extraction and quality scoring |
| 2025-01-16 | [architecture-mcp-server-2025-01-16.md](./architecture-mcp-server-2025-01-16.md) | Active | MCP server implementation for agent queries |
| 2025-01-16 | [architecture-database-schema-2025-01-16.md](./architecture-database-schema-2025-01-16.md) | Active | Database schema design and migrations |

## Key Architectural Patterns

### Privacy-First Design
ALL data is sanitized BEFORE storage. The system guarantees zero PII leaks through:
- Rule-based PII detection (fast, deterministic)
- AI-powered context-aware sanitization
- Hybrid validation pipeline
- Audit logging for continuous improvement

### Subagent-Driven Development
Every component is implemented by specialized subagents:
- Implementation subagents build features
- Test subagents generate and validate tests
- Quality gate subagents enforce standards
- Integration subagents verify component interactions

### Async-First Architecture
Non-blocking design with persistent queues:
- Event capture never blocks user
- Sanitization runs asynchronously
- Learning extraction happens in background
- Mining/upload processes independently

## System Components

1. **Event Capture Layer** (Hooks + Queue)
2. **Sanitization Pipeline** (Rules + AI)
3. **Storage Layer** (SQLite + Migrations)
4. **Async Processing** (Job Queue + Workers)
5. **Learning Extraction** (Analysis + Scoring)
6. **Query Interface** (MCP Server)
7. **Network Layer** (IPFS + Blockchain)

## Related Categories

- [Decisions](../decisions/INDEX.md) - ADRs explaining architectural choices
- [Plans](../plans/INDEX.md) - Implementation roadmaps
- [Reference](../reference/INDEX.md) - Technical specifications

## Quick Tips

- Start with the global architecture document for overview
- Review component-specific docs for deep dives
- Check ADRs for rationale behind decisions
- Use diagrams for understanding data flow

================
File: decisions/decision-async-processing-model-2025-01-16.md
================
---
title: ADR-006: Async Processing Model with Job Queue
category: decision
date: 2025-01-16
status: accepted
deciders: Claude + Dennison
tags: [async, job-queue, performance, reliability]
---

# ADR-006: Async Processing Model with Job Queue

## Status

Accepted

Date: 2025-01-16

## Context

The Global Context Network has several processing stages that must not block user interaction:

1. **Event capture** - Hooks must complete < 100ms
2. **Sanitization** - PII detection takes 1-2s per conversation
3. **Learning extraction** - AI analysis takes 5-10s
4. **Upload to network** - IPFS/blockchain can take 10-30s
5. **Quality validation** - Multi-stage validation takes time

**Requirements**:
- **Never block user** - Claude Code must remain responsive
- **Persist across restarts** - Jobs survive crashes/shutdowns
- **Retry failed jobs** - Network issues, temporary failures
- **Ordered processing** - Respect dependencies (sanitize before extract)
- **Idempotency** - Safe to retry jobs
- **Offline tolerance** - Queue locally, sync when online
- **Observable** - Monitor queue depth, latency, errors

**Why Async is Critical**:
- User experience constraint: < 100ms p95 for hooks
- Processing is inherently slow: sanitization, learning extraction, uploads
- Network operations are unpredictable: IPFS, blockchain
- Offline capability: must work without constant connectivity
- Predictable local operation before global publishing

## Decision

Use SQLite-based persistent job queue with async workers.

**Architecture**:
```
Hook (< 100ms) → Event Queue → Async Workers → Results
                       ↓
                   (Persisted)
```

**Job Types**:
1. `sanitize_conversation` - Run PII sanitization pipeline
2. `extract_learning` - Generate learnings from conversation
3. `mine_upload` - Upload to IPFS/blockchain

**Queue Properties**:
- Persistent (survives restarts)
- Priority-based (critical jobs first)
- Retry with exponential backoff
- Dead letter queue for failed jobs
- Atomic enqueue (outbox pattern)

**Worker Design**:
- Independent processes
- Poll queue for jobs
- Lease-based execution
- Idempotent job handlers
- Graceful shutdown

## Consequences

### Positive

- **Never blocks user** - Hooks return immediately (< 50ms)
- **Persists across restarts** - Jobs survive crashes
- **Retry with backoff** - Handles transient failures
- **No external dependencies** - SQLite-based, local-first
- **Offline tolerance** - Queue locally, flush when online
- **Predictable local operation** - No network required for queueing
- **Observable** - Full visibility into queue state
- **Ordered processing** - Dependency management built-in

### Negative

- **Single-process limitation** - One worker at a time (MVP acceptable)
- **No distributed processing** - Can't scale horizontally (fine for MVP)
- **Polling overhead** - Workers poll queue continuously
- **At-least-once semantics** - Exactly-once impossible (need idempotency)
- **Delayed feedback** - Users don't see immediate results

### Neutral

- **Job states** - Need to track queued, in-progress, completed, failed
- **Lease expiry** - Jobs can be retried if worker crashes
- **Metrics tracking** - Monitor queue depth, age, success rate
- **Backpressure handling** - May need to sample or drop if overwhelmed

## Alternatives Considered

### Alternative 1: Synchronous Processing

**Description**: Process everything in the hook itself.

**Pros**:
- Simpler code
- Immediate feedback
- No queue complexity
- Easier debugging

**Cons**:
- **Blocks user** - Unacceptable UX (2-10s delays)
- **Hook timeout** - Claude Code enforces timeout
- **Poor offline support** - Fails if network down
- **No retry** - Transient failures permanent

**Why not chosen**: Violates UX constraint (< 100ms hooks). Blocking user is unacceptable.

### Alternative 2: Redis/RabbitMQ/SQS

**Description**: Use external queue service.

**Pros**:
- Production-ready
- Distributed by design
- Excellent tooling
- Battle-tested

**Cons**:
- **External dependency** - Violates local-first principle
- **Setup overhead** - Install, configure, manage
- **Network dependency** - Offline mode broken
- **Operational complexity** - Monitor, backup, upgrade
- **Overkill for MVP** - Single user doesn't need distributed queue

**Why not chosen**: Too much operational overhead for single-user MVP. SQLite meets all requirements.

### Alternative 3: OS Job Schedulers (cron, systemd timers, launchd)

**Description**: Use OS-level job scheduling.

**Pros**:
- No custom queue needed
- OS handles execution
- Standard tooling

**Cons**:
- **No dynamic queueing** - Can't enqueue at runtime
- **Poor job management** - Hard to track state
- **No retries** - Must implement separately
- **Platform-specific** - Different on macOS/Linux/Windows

**Why not chosen**: Not suitable for dynamic event-driven queueing.

### Alternative 4: Simple setTimeout/setInterval

**Description**: Use JavaScript timers for delayed execution.

**Pros**:
- Very simple
- No dependencies
- Easy to understand

**Cons**:
- **No persistence** - Lost on restart
- **No retry** - Failures disappear
- **No ordering** - Race conditions
- **No observability** - Can't inspect pending jobs

**Why not chosen**: Violates "never lose data" requirement. Jobs must persist across restarts.

### Alternative 5: Temporal/Prefect/Dagster

**Description**: Use workflow orchestration framework.

**Pros**:
- Excellent DAG orchestration
- Built-in retry and error handling
- Great observability
- Scales to production
- Durable execution

**Cons**:
- **Heavy** - Requires server infrastructure
- **Overkill** - Too complex for MVP
- **Operational overhead** - Deploy, manage orchestrator
- **Not local-first** - Network dependency

**Why not chosen**: Great for future scaling but too heavy for MVP. Can migrate post-MVP.

### Alternative 6: Embedded Job Queue Libraries

**Description**: Use existing SQLite-based queue libraries.

**Pros**:
- Proven implementation
- Less code to write
- Community support

**Cons**:
- External dependency
- May not fit exact needs
- Learning curve for team
- Less control

**Why not chosen**: Considered but decided custom implementation is simple enough and gives more control. Can re-evaluate if complexity grows.

## Implementation

### Job Queue Schema

```typescript
CREATE TABLE job_queue (
  id TEXT PRIMARY KEY,
  type TEXT NOT NULL, -- 'sanitize_conversation', 'extract_learning', 'mine_upload'
  status TEXT NOT NULL, -- 'queued', 'in_progress', 'completed', 'failed', 'dead_letter'
  priority INTEGER NOT NULL DEFAULT 5, -- 1 (highest) to 10 (lowest)
  payload TEXT NOT NULL, -- JSON
  idempotency_key TEXT UNIQUE, -- For deduplication
  created_at INTEGER NOT NULL,
  scheduled_at INTEGER NOT NULL, -- When to execute (for delays)
  started_at INTEGER, -- When worker picked up
  completed_at INTEGER,
  lease_expires_at INTEGER, -- Worker lease expiry
  retry_count INTEGER DEFAULT 0,
  max_retries INTEGER DEFAULT 3,
  error TEXT, -- Last error message
  result TEXT -- JSON result
);

CREATE INDEX idx_jobs_status_priority ON job_queue(status, priority, created_at);
CREATE INDEX idx_jobs_scheduled ON job_queue(scheduled_at) WHERE status = 'queued';
CREATE INDEX idx_jobs_lease_expiry ON job_queue(lease_expires_at) WHERE status = 'in_progress';
CREATE INDEX idx_jobs_idempotency ON job_queue(idempotency_key);
```

### Outbox Pattern (Atomic Enqueue)

```typescript
// Enqueue job atomically with conversation insert
async function captureAndEnqueue(conversation: Conversation) {
  db.transaction(() => {
    // 1. Insert conversation
    db.prepare(`
      INSERT INTO conversations (id, created_at, status)
      VALUES (?, ?, ?)
    `).run(conversation.id, Date.now(), "pending_sanitization");

    // 2. Enqueue sanitization job (same transaction)
    db.prepare(`
      INSERT INTO job_queue (id, type, status, priority, payload, idempotency_key, created_at, scheduled_at)
      VALUES (?, ?, ?, ?, ?, ?, ?, ?)
    `).run(
      generateId(),
      "sanitize_conversation",
      "queued",
      1, // High priority
      JSON.stringify({ conversationId: conversation.id }),
      `sanitize-${conversation.id}`, // Idempotency key
      Date.now(),
      Date.now() // Execute immediately
    );
  })();
}
```

### Job States and Transitions

```typescript
enum JobStatus {
  QUEUED = "queued",           // Waiting to execute
  IN_PROGRESS = "in_progress", // Worker processing
  COMPLETED = "completed",     // Successfully finished
  FAILED = "failed",           // Failed but can retry
  DEAD_LETTER = "dead_letter"  // Failed max retries
}

// State transitions
const validTransitions = {
  [JobStatus.QUEUED]: [JobStatus.IN_PROGRESS],
  [JobStatus.IN_PROGRESS]: [JobStatus.COMPLETED, JobStatus.FAILED, JobStatus.QUEUED], // Queued = lease expired
  [JobStatus.FAILED]: [JobStatus.QUEUED, JobStatus.DEAD_LETTER],
  [JobStatus.COMPLETED]: [], // Terminal
  [JobStatus.DEAD_LETTER]: [] // Terminal
};
```

### Worker Implementation

```typescript
class JobWorker {
  private running = false;
  private pollInterval = 1000; // 1s
  private leaseDuration = 60000; // 60s

  async start() {
    this.running = true;
    console.log("Worker started");

    while (this.running) {
      try {
        const job = await this.claimJob();

        if (job) {
          await this.executeJob(job);
        } else {
          // No jobs, wait before polling again
          await sleep(this.pollInterval);
        }
      } catch (error) {
        console.error("Worker error:", error);
        await sleep(this.pollInterval);
      }
    }

    console.log("Worker stopped");
  }

  async stop() {
    this.running = false;
    // Graceful shutdown: finish current job
  }

  private async claimJob(): Promise<Job | null> {
    const now = Date.now();

    return db.transaction(() => {
      // Find next job to process
      const job = db.prepare(`
        SELECT * FROM job_queue
        WHERE status = 'queued'
          AND scheduled_at <= ?
        ORDER BY priority ASC, created_at ASC
        LIMIT 1
      `).get(now);

      if (!job) {
        // Also check for expired leases
        const expiredJob = db.prepare(`
          SELECT * FROM job_queue
          WHERE status = 'in_progress'
            AND lease_expires_at < ?
          ORDER BY priority ASC, created_at ASC
          LIMIT 1
        `).get(now);

        if (expiredJob) {
          // Reset to queued for retry
          db.prepare(`
            UPDATE job_queue
            SET status = 'queued',
                lease_expires_at = NULL,
                started_at = NULL
            WHERE id = ?
          `).run(expiredJob.id);

          return expiredJob;
        }

        return null;
      }

      // Claim job with lease
      db.prepare(`
        UPDATE job_queue
        SET status = 'in_progress',
            started_at = ?,
            lease_expires_at = ?
        WHERE id = ?
      `).run(now, now + this.leaseDuration, job.id);

      return job;
    })();
  }

  private async executeJob(job: Job) {
    try {
      console.log(`Executing job ${job.id} (${job.type})`);

      // Get handler for job type
      const handler = this.getHandler(job.type);

      // Execute with idempotency
      const result = await handler(JSON.parse(job.payload));

      // Mark completed
      db.prepare(`
        UPDATE job_queue
        SET status = 'completed',
            completed_at = ?,
            result = ?
        WHERE id = ?
      `).run(Date.now(), JSON.stringify(result), job.id);

      console.log(`✓ Job ${job.id} completed`);
    } catch (error) {
      console.error(`✗ Job ${job.id} failed:`, error);

      // Retry logic
      await this.handleFailure(job, error);
    }
  }

  private async handleFailure(job: Job, error: Error) {
    const retryCount = job.retry_count + 1;

    if (retryCount >= job.max_retries) {
      // Move to dead letter queue
      db.prepare(`
        UPDATE job_queue
        SET status = 'dead_letter',
            retry_count = ?,
            error = ?
        WHERE id = ?
      `).run(retryCount, error.message, job.id);

      // Alert
      await alert({
        severity: "ERROR",
        message: `Job ${job.id} moved to dead letter queue`,
        error: error.message
      });
    } else {
      // Retry with exponential backoff
      const backoff = this.calculateBackoff(retryCount);

      db.prepare(`
        UPDATE job_queue
        SET status = 'queued',
            retry_count = ?,
            scheduled_at = ?,
            error = ?,
            lease_expires_at = NULL,
            started_at = NULL
        WHERE id = ?
      `).run(retryCount, Date.now() + backoff, error.message, job.id);

      console.log(`Retrying job ${job.id} in ${backoff}ms (attempt ${retryCount})`);
    }
  }

  private calculateBackoff(retryCount: number): number {
    // Exponential backoff with jitter
    const baseDelay = 1000; // 1s
    const maxDelay = 60000; // 60s
    const exponential = Math.min(baseDelay * Math.pow(2, retryCount), maxDelay);
    const jitter = Math.random() * 1000; // 0-1s jitter

    return exponential + jitter;
  }

  private getHandler(jobType: string): JobHandler {
    const handlers = {
      sanitize_conversation: sanitizeConversationHandler,
      extract_learning: extractLearningHandler,
      mine_upload: mineUploadHandler
    };

    return handlers[jobType] || (() => {
      throw new Error(`Unknown job type: ${jobType}`);
    });
  }
}
```

### Idempotency

```typescript
// Every job handler must be idempotent
async function sanitizeConversationHandler(payload: { conversationId: string }) {
  const { conversationId } = payload;

  // Check if already sanitized
  const conversation = db.prepare(
    "SELECT * FROM conversations WHERE id = ?"
  ).get(conversationId);

  if (conversation.status === "sanitized") {
    console.log(`Conversation ${conversationId} already sanitized`);
    return { skipped: true, reason: "already-sanitized" };
  }

  // Perform sanitization...
  const sanitized = await sanitize(conversation.content);

  // Update atomically
  db.transaction(() => {
    db.prepare(`
      UPDATE conversations
      SET sanitized_content = ?,
          status = 'sanitized',
          updated_at = ?
      WHERE id = ?
    `).run(sanitized, Date.now(), conversationId);
  })();

  return { success: true };
}
```

### Graceful Shutdown

```typescript
process.on("SIGTERM", async () => {
  console.log("SIGTERM received, shutting down gracefully");

  // Stop accepting new jobs
  worker.stop();

  // Wait for current job to finish (with timeout)
  await Promise.race([
    worker.waitForCompletion(),
    sleep(30000) // 30s max wait
  ]);

  // Close database
  db.close();

  process.exit(0);
});
```

### Metrics and Monitoring

```typescript
interface QueueMetrics {
  queueDepth: number; // Jobs waiting
  queueAge: number; // Oldest queued job age (ms)
  inProgressCount: number;
  p95Latency: number; // 95th percentile job duration
  successRate: number; // Completed / Total
  deadLetterCount: number;
}

async function getQueueMetrics(): Promise<QueueMetrics> {
  const stats = db.prepare(`
    SELECT
      status,
      COUNT(*) as count,
      MIN(created_at) as oldest,
      AVG(completed_at - started_at) as avg_duration,
      MAX(completed_at - started_at) as max_duration
    FROM job_queue
    WHERE created_at > ? -- Last 24 hours
    GROUP BY status
  `).all(Date.now() - 86400000);

  // Calculate metrics...
  return metrics;
}

// Expose metrics for monitoring
setInterval(async () => {
  const metrics = await getQueueMetrics();

  if (metrics.queueDepth > 100) {
    await alert({
      severity: "WARNING",
      message: `Queue depth high: ${metrics.queueDepth}`
    });
  }

  if (metrics.queueAge > 3600000) { // 1 hour
    await alert({
      severity: "WARNING",
      message: `Old jobs in queue: ${metrics.queueAge}ms`
    });
  }
}, 60000); // Check every minute
```

### Backpressure Handling

```typescript
async function enqueueWithBackpressure(job: Job) {
  const queueDepth = db.prepare(
    "SELECT COUNT(*) as count FROM job_queue WHERE status = 'queued'"
  ).get().count;

  const maxQueueSize = 10000;

  if (queueDepth >= maxQueueSize) {
    // Queue full - implement backpressure
    if (job.priority > 5) {
      // Drop low-priority jobs
      console.warn(`Queue full, dropping low-priority job ${job.type}`);
      return { dropped: true };
    } else {
      // Block and wait for high-priority jobs
      await waitForQueueSpace(maxQueueSize);
    }
  }

  // Enqueue job
  db.prepare(`
    INSERT INTO job_queue (...)
    VALUES (...)
  `).run(...);

  return { enqueued: true };
}
```

## Risks and Mitigations

### Risk: Jobs Lost on Crash

**Impact**: Medium - Work needs to be redone

**Mitigation**:
- Persistent queue (survives crashes)
- Lease-based execution (requeue if worker dies)
- Idempotent handlers (safe to retry)
- Monitor dead letter queue

### Risk: Queue Buildup

**Impact**: Medium - Delayed processing

**Mitigation**:
- Monitor queue depth
- Alert on high queue age
- Backpressure mechanism
- Can add more workers post-MVP

### Risk: Duplicate Processing

**Impact**: Low - Wasted resources

**Mitigation**:
- Idempotency keys prevent duplicates
- Idempotent job handlers
- Check state before processing

## Related Documents

### Architecture
- [Global Context Network Architecture](../architecture/architecture-global-context-network-2025-01-16.md)
- [Async Processing Layer](../architecture/architecture-async-processing-2025-01-16.md)

### Decisions
- [ADR-001: Use Claude Hooks](./decision-use-claude-hooks-2025-01-16.md)
- [ADR-004: Sanitize Before Storage](./decision-sanitize-before-storage-2025-01-16.md)
- [ADR-005: Use SQLite](./decision-use-sqlite-2025-01-16.md)

### Plans
- [Phase 4: Async Processing](../plans/plan-phase-4-async-processing-2025-01-16.md)

### Reference
- [Job Types Reference](../reference/reference-job-types-2025-01-16.md)

================
File: decisions/decision-claude-testing-harness-2025-01-16.md
================
---
title: ADR-003: Claude-Powered Testing Harness
category: decision
date: 2025-01-16
status: accepted
deciders: Claude + Dennison
tags: [testing, quality, claude-agent-sdk, tdd]
---

# ADR-003: Claude-Powered Testing Harness

## Status

Accepted

Date: 2025-01-16

## Context

The Global Context Network has critical quality requirements:

1. **Zero PII leaks** - Privacy is non-negotiable, must be proven
2. **Correctness of learnings** - Extracted insights must be accurate
3. **Reliability** - Async processing must be robust with retries
4. **Performance** - Hooks < 100ms, queries < 200ms
5. **Security** - No injection vulnerabilities or exposed secrets

Standard unit tests underrepresent these risks because:
- **Edge cases** - Hard to manually enumerate all PII patterns
- **Context-aware** - Need to test sanitization in realistic scenarios
- **End-to-end validation** - Component tests miss integration issues
- **Quality variance** - Manual test quality varies across developers
- **Coverage gaps** - Easy to miss critical paths

We need validation beyond code coverage - we need **risk coverage** including:
- Privacy violations (PII leakage)
- Security vulnerabilities
- Performance regressions
- Correctness of learned facts
- Async failure scenarios

## Decision

Use Claude Agent SDK for test generation, validation, and quality gates.

**Components**:
1. **Test Generator Subagents** - Generate comprehensive test suites
2. **Test Quality Validator** - Score test quality and completeness
3. **Coverage Analyzer** - Ensure > 85% code coverage
4. **Privacy Red Team** - Generate adversarial PII test cases
5. **Implementation Validator** - Verify code matches tests

**TDD Workflow**:
```
RED: Test generator creates failing test
  ↓
VALIDATE: Test quality validator scores test
  ↓
GREEN: Implementation subagent passes test
  ↓
VERIFY: Implementation validator checks correctness
  ↓
REFACTOR: Code quality validator ensures standards
```

**Quality Gates** (all must pass):
- Test coverage > 85%
- All tests pass
- PII leakage score = 0
- Security scan clean
- Performance SLOs met

## Consequences

### Positive

- **Comprehensive coverage** - AI finds edge cases humans miss
- **Privacy assurance** - Red team generates PII test cases
- **Automated quality scoring** - Objective test quality metrics
- **Edge case discovery** - AI explores boundary conditions
- **Self-validating system** - Tests validate themselves
- **Consistent quality** - Same standards across all components
- **Fast iteration** - Automated test generation accelerates TDD

### Negative

- **API costs** - Claude API usage for test generation
- **Non-determinism** - Generated tests may vary between runs
- **Prompt dependency** - Test quality depends on prompt engineering
- **Maintenance** - Must maintain test generator prompts
- **Learning curve** - Team must understand AI-powered testing
- **Debugging** - Harder to debug generated test failures

### Neutral

- **Requires Claude API** - Adds external dependency
- **Token budget needed** - Must allocate costs for CI
- **Test data governance** - Ensure generated tests don't contain PII
- **Flaky test handling** - Need quarantine for non-deterministic tests

## Alternatives Considered

### Alternative 1: Manual Test Writing Only

**Description**: Developers write all tests manually following TDD.

**Pros**:
- Full control over test logic
- Deterministic results
- No API dependency
- Standard industry practice
- Easier debugging

**Cons**:
- Slow (bottleneck on human creativity)
- Inconsistent quality across developers
- Misses edge cases
- No automated quality validation
- High maintenance burden

**Why not chosen**: Too slow for aggressive MVP timeline, lacks comprehensive edge case coverage.

### Alternative 2: Property-Based Testing (Hypothesis/FastCheck)

**Description**: Use property-based testing frameworks for structured components.

**Pros**:
- Excellent for finding edge cases
- Deterministic with seeds
- No API costs
- Good for pure functions
- Shrinking finds minimal failing examples

**Cons**:
- Requires defining properties (still manual)
- Not suitable for all components
- Doesn't validate test quality
- No privacy-specific red team
- Learning curve for team

**Why not chosen**: Complementary approach, should be used alongside Claude harness. Will incorporate for structured components.

### Alternative 3: Mutation Testing (Stryker, PIT)

**Description**: Measure test suite sensitivity by mutating code.

**Pros**:
- Validates test effectiveness
- Finds weak tests
- Deterministic results
- No external dependency

**Cons**:
- Slow (must re-run tests for each mutation)
- Doesn't generate tests
- Doesn't understand domain (privacy, security)
- High computational cost

**Why not chosen**: Useful for validation but doesn't generate tests. Can add as quality check later.

### Alternative 4: Golden File / Record-Replay Testing

**Description**: Record inputs/outputs, replay for regression testing.

**Pros**:
- Deterministic
- Catches regressions
- Fast execution
- Easy to maintain

**Cons**:
- Doesn't generate new tests
- Brittle to intentional changes
- No edge case discovery
- Not suitable for privacy testing

**Why not chosen**: Useful for integration tests but doesn't solve test generation problem.

### Alternative 5: Static Analysis and Linters Only

**Description**: Rely on ESLint, TypeScript, security scanners.

**Pros**:
- Fast feedback
- Deterministic
- No API costs
- Catches common issues
- Standard tooling

**Cons**:
- No runtime behavior testing
- Can't verify correctness
- Misses logic bugs
- No PII detection testing
- Limited to structural issues

**Why not chosen**: Necessary but insufficient. Will use alongside testing harness.

## Implementation

### Test Generator Configuration

```typescript
interface TestGeneratorConfig {
  component: string;
  testType: "unit" | "integration" | "e2e";
  coverageTarget: number; // 0.0 - 1.0
  edgeCaseFocus: string[]; // ["pii", "performance", "errors"]
  model: "sonnet" | "opus";
  temperature: number;
}

const unitTestGenerator = {
  component: "sanitization-pipeline",
  testType: "unit",
  coverageTarget: 0.95, // Critical component
  edgeCaseFocus: ["pii", "errors", "boundaries"],
  model: "sonnet",
  temperature: 0.3
};
```

### Privacy Red Team Generator

Generate adversarial PII test cases:

```typescript
const piiRedTeamPrompt = `Generate PII edge cases for sanitization testing.

Include:
- Obfuscated emails (user[at]domain[dot]com)
- International phone formats
- API keys with unusual formats
- Names in code (variable names vs person names)
- Paths with usernames in unexpected places
- Combined PII (email + phone in same string)
- Unicode/emoji in PII
- Base64-encoded secrets
- Uncommon PII patterns

Generate 50 unique test cases.
Each must be realistic and challenging.`;
```

### Test Quality Scoring

```typescript
interface TestQualityScore {
  structure: number; // 0-1: proper describe/it/expect
  clarity: number; // 0-1: clear test names
  assertions: number; // 0-1: meaningful assertions
  edgeCases: number; // 0-1: boundary conditions covered
  isolation: number; // 0-1: proper mocking/independence
  maintainability: number; // 0-1: clear and DRY
  overall: number; // weighted average
}

// Require overall > 0.8 to pass
```

### Determinism for CI

```typescript
// For CI runs: low temperature, fixed seed
const ciTestConfig = {
  temperature: 0.1,
  seed: "ci-run-20250116",
  maxRetries: 1, // Don't retry in CI
  timeout: 300000 // 5min max
};

// For exploration: higher temperature
const exploreConfig = {
  temperature: 0.7,
  seed: null, // Random
  maxRetries: 3
};
```

### Cost Budgets

```typescript
interface TestingBudget {
  maxTokensPerComponent: number;
  maxTokensPerCIRun: number;
  smokeTestTokens: number; // Quick validation
  fullTestTokens: number; // Nightly comprehensive
}

const budget = {
  maxTokensPerComponent: 20000,
  maxTokensPerCIRun: 100000, // Cap CI costs
  smokeTestTokens: 10000, // PR validation
  fullTestTokens: 500000 // Nightly deep testing
};
```

### Test Data Governance

Ensure generated tests don't contain real PII:

```typescript
async function validateGeneratedTests(tests: string[]): Promise<boolean> {
  // Scan generated test code for PII
  const detector = new PIIDetector();

  for (const test of tests) {
    const findings = await detector.scan(test);
    if (findings.length > 0) {
      throw new Error(`Generated test contains PII: ${findings}`);
    }
  }

  return true;
}
```

### Smoke vs Exhaustive Suites

```typescript
// Smoke tests: Fast, run on every PR
const smokeTests = {
  coverage: 0.70, // Lower bar
  timeout: 60000, // 1min
  tokenBudget: 10000,
  tests: ["happy-path", "basic-errors"]
};

// Exhaustive tests: Comprehensive, run nightly
const exhaustiveTests = {
  coverage: 0.95, // High bar
  timeout: 600000, // 10min
  tokenBudget: 500000,
  tests: ["all-edge-cases", "red-team", "property-based"]
};
```

### Flaky Test Quarantine

```typescript
interface FlakyTestHandler {
  maxFailureRate: number; // 0.05 = 5%
  minRuns: number; // Need 20 runs to determine flakiness
  quarantineDuration: number; // 7 days

  async handleFlaky(test: Test): Promise<void> {
    // Move to quarantine
    await moveToQuarantine(test);

    // Create issue for investigation
    await createIssue({
      title: `Flaky test: ${test.name}`,
      labels: ["flaky-test", "needs-investigation"]
    });

    // Notify team
    await notify(`Test ${test.name} quarantined due to flakiness`);
  }
}
```

### Integration with Property-Based Testing

```typescript
// Combine Claude generation with property-based testing
const hybridTests = {
  // Claude generates properties to test
  generateProperties: async (component: string) => {
    const properties = await claudeGenerateProperties(component);
    return properties;
  },

  // FastCheck validates properties
  validateWithFastCheck: (properties: Property[]) => {
    for (const prop of properties) {
      fc.assert(fc.property(prop.generators, prop.predicate));
    }
  }
};
```

### Coverage Validation

```typescript
interface CoverageRequirements {
  lines: number; // 0.85
  statements: number; // 0.85
  functions: number; // 0.90
  branches: number; // 0.80

  // Special requirements for critical paths
  criticalPaths: {
    [path: string]: number; // 1.0 for sanitization
  };
}

const requirements = {
  lines: 0.85,
  statements: 0.85,
  functions: 0.90,
  branches: 0.80,
  criticalPaths: {
    "src/sanitization/": 0.95, // High bar for privacy
    "src/hooks/": 0.90 // High bar for performance
  }
};
```

## Risks and Mitigations

### Risk: Non-Determinism Breaks CI

**Impact**: High - Unreliable builds

**Mitigation**:
- Low temperature (0.1) for CI
- Fixed seeds for reproducibility
- Retry same seed on failure
- Quarantine flaky tests
- Smoke tests with deterministic config

### Risk: API Cost Overruns

**Impact**: Medium - Budget concerns

**Mitigation**:
- Hard token limits per component
- Use Haiku for simple tests
- Cache test generation results
- Progressive test generation (smoke → full)
- Alert at 80% of budget

### Risk: Generated Tests Contain PII

**Impact**: High - Privacy violation

**Mitigation**:
- Scan generated tests for PII
- Use synthetic data only
- Review generated tests before commit
- Automated PII detection on test code

### Risk: Test Quality Variance

**Impact**: Medium - Unreliable validation

**Mitigation**:
- Quality scoring (require > 0.8)
- Human review for critical components
- Version and track prompts
- Continuous prompt improvement

## Related Documents

### Architecture
- [Testing Harness Architecture](../architecture/architecture-testing-harness-2025-01-16.md)
- [Subagent System](../architecture/architecture-subagent-system-2025-01-16.md)

### Decisions
- [ADR-002: Subagent-Driven Development](./decision-subagent-driven-development-2025-01-16.md)
- [ADR-004: Sanitize Before Storage](./decision-sanitize-before-storage-2025-01-16.md)

### Guides
- [TDD Workflow Guide](../guides/guide-tdd-workflow-2025-01-16.md)
- [Testing Harness Usage](../guides/guide-testing-harness-usage-2025-01-16.md)

### Reference
- [Testing Strategy Reference](../reference/reference-testing-strategy-2025-01-16.md)

================
File: decisions/decision-sanitize-before-storage-2025-01-16.md
================
---
title: ADR-004: Sanitize Before Storage (Privacy-First Architecture)
category: decision
date: 2025-01-16
status: accepted
deciders: Claude + Dennison
tags: [privacy, security, pii, sanitization, zero-trust]
---

# ADR-004: Sanitize Before Storage (Privacy-First Architecture)

## Status

Accepted

Date: 2025-01-16

## Context

The Global Context Network captures user conversations with AI agents, which inevitably contain:
- **API keys and secrets** - Authentication tokens, passwords
- **Personal information** - Names, emails, phone numbers
- **File paths** - Absolute paths with usernames
- **IP addresses** - Network information
- **Organization-specific data** - Company names, project names
- **URLs with tokens** - Authentication in query params

This data will be:
1. Stored locally in SQLite database
2. Extracted for learning generation
3. Potentially shared globally via IPFS/blockchain
4. Queried by other AI agents via MCP

**The Risk**: If PII is stored unsanitized, it can leak through:
- Database breaches
- Accidental sharing
- Query results
- Learning extractions
- Global network uploads
- Developer debugging
- Log files

**Data Minimization Principle**: The safest PII is PII we never store. Once stored, it can spread through the system unpredictably.

**Zero-Trust Privacy**: We cannot trust that all downstream components will properly handle PII. The only safe approach is to never let PII enter storage.

## Decision

Sanitize ALL data BEFORE database insertion. Never store unsanitized conversation data.

**Architecture**:
```
Event Capture → Sanitization Pipeline → Database
                        ↑
                  (PII never passes this gate)
```

**Sanitization happens**:
- BEFORE any database write
- In the event queue processing worker
- Using hybrid detection (rules + AI)
- With audit trail of all redactions

**Sanitization methods**:
1. **Rule-based detector** - Fast regex for known patterns
2. **AI-powered detector** - Context-aware LLM analysis
3. **Hybrid validator** - Combines both approaches
4. **Audit logger** - Tracks what was redacted

**Redaction format**:
- Irreversible redaction by default
- Placeholder tokens: `<EMAIL_1>`, `<API_KEY_1>`, `<PERSON_1>`
- Optional per-session pseudonymization for within-session linking
- Separate encrypted mapping (if pseudonymization enabled)

## Consequences

### Positive

- **Zero-trust PII handling** - Database inherently safe
- **Safe default sharing** - No risk of accidental PII in learnings
- **Breach impact minimized** - No PII to steal
- **Compliance friendly** - Easier GDPR/CCPA alignment
- **Developer safety** - Devs can access database without PII exposure
- **Query safety** - MCP queries can't return PII
- **Audit trail** - Full log of what was redacted

### Negative

- **Irreversible** - Can't recover original data if over-redaction occurs
- **Async delay** - 1-2s sanitization delay before storage
- **False negatives risk** - May miss novel PII patterns
- **Utility loss** - Over-redaction reduces learning value
- **Complexity** - Hybrid pipeline is more complex than simple storage

### Neutral

- **Processing overhead** - Sanitization adds computational cost
- **Confidence thresholds** - Must tune detection sensitivity
- **Review workflow** - Borderline cases need manual review
- **Detector maintenance** - Must update PII patterns over time

## Alternatives Considered

### Alternative 1: Sanitize on Query

**Description**: Store raw data, sanitize when querying.

**Pros**:
- Can recover original data if needed
- Simpler storage path
- Faster writes

**Cons**:
- **Database contains PII** - Breach exposes everything
- **Too late** - PII already persisted and spread
- **Query bugs leak PII** - One bug exposes all data
- **Compliance risk** - Storing PII requires strict controls
- **Multiple sanitization points** - Must sanitize every query path

**Why not chosen**: Violates zero-trust principle. Database breach or query bug exposes all PII.

### Alternative 2: Sanitize on Upload Only

**Description**: Store raw locally, sanitize only for global sharing.

**Pros**:
- Local utility preserved
- Only sanitize what's shared
- Can debug with full data

**Cons**:
- **Local database contains PII** - User machine breach exposes PII
- **Accidental sharing risk** - One bug uploads raw data
- **Developer access risk** - Devs see PII during debugging
- **Log leakage** - Logs may contain PII
- **MCP queries return PII** - Agents see raw data

**Why not chosen**: Too many opportunities for PII leakage. Doesn't minimize data surface area.

### Alternative 3: Trust Users to Redact

**Description**: Provide UI for users to review and redact before storage.

**Pros**:
- User control
- High precision (users know what's sensitive)
- No false positives

**Cons**:
- **Users make mistakes** - Will forget to redact
- **Poor UX** - Friction on every interaction
- **Incomplete coverage** - Users miss subtle PII
- **Not scalable** - Can't review every conversation

**Why not chosen**: Users are not reliable. Automated approach required.

### Alternative 4: Encryption Only (No Redaction)

**Description**: Encrypt sensitive data, don't redact.

**Pros**:
- Reversible
- Data preserved
- Simple implementation

**Cons**:
- **Key management complexity** - Where to store keys?
- **Still have access to raw data** - Can decrypt when needed
- **Doesn't minimize surface** - PII still in system
- **Compliance unclear** - Encrypted PII may still be PII
- **Key leak exposes all** - Single point of failure

**Why not chosen**: Doesn't eliminate PII, just obscures it. Key management introduces new risks.

### Alternative 5: Layered Detection (Rules + ML NER + LLM)

**Description**: Use multiple detection layers: regex, ML NER models, LLM adjudicator.

**Pros**:
- Higher accuracy than single method
- Catches different PII types
- Reduces false negatives

**Cons**:
- More complex pipeline
- Higher latency
- More expensive (ML model + LLM calls)
- More maintenance

**Why not chosen**: **ACTUALLY CHOSEN** - This is the hybrid approach we're implementing (rules + LLM). Could add ML NER post-MVP for even better accuracy.

## Implementation

### PII Taxonomy

Define what we detect:

```typescript
enum PIICategory {
  API_KEY = "API_KEY",           // API keys, tokens, passwords
  EMAIL = "EMAIL",               // Email addresses
  PHONE = "PHONE",               // Phone numbers (all formats)
  SSN = "SSN",                   // Social Security Numbers
  CREDIT_CARD = "CREDIT_CARD",   // Credit card numbers
  IP_ADDRESS = "IP_ADDRESS",     // IPv4/IPv6 addresses
  MAC_ADDRESS = "MAC_ADDRESS",   // Hardware addresses
  PERSON_NAME = "PERSON_NAME",   // Human names (not code names)
  FILE_PATH = "FILE_PATH",       // Absolute paths with usernames
  URL_WITH_TOKEN = "URL_WITH_TOKEN", // URLs with auth params
  AWS_KEY = "AWS_KEY",           // AWS access keys
  PRIVATE_KEY = "PRIVATE_KEY",   // SSH/TLS private keys
  JWT = "JWT",                   // JSON Web Tokens
  ORGANIZATION = "ORGANIZATION"  // Company/org names
}
```

### Detection Patterns

```typescript
const piiPatterns = {
  EMAIL: /\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/g,
  PHONE: /\b(\+\d{1,3}[-.]?)?\(?\d{3}\)?[-.]?\d{3}[-.]?\d{4}\b/g,
  API_KEY: /\b(sk_live_|pk_live_|api_key_|apikey=)[A-Za-z0-9_-]{20,}\b/gi,
  AWS_KEY: /\b(AKIA[0-9A-Z]{16})\b/g,
  FILE_PATH: /\/Users\/[^\/\s]+\/.*|\/home\/[^\/\s]+\/.*/g,
  URL_WITH_TOKEN: /https?:\/\/[^\s]+[?&](token|key|auth|api_key)=[^\s&]+/gi,
  // ... more patterns
};
```

### Layered Detection Pipeline

```typescript
interface SanitizationResult {
  sanitized: string;
  detections: Detection[];
  confidence: number; // 0-1
  method: "rules" | "ai" | "hybrid";
}

interface Detection {
  category: PIICategory;
  original: string;
  placeholder: string;
  confidence: number;
  position: { start: number; end: number };
  detector: "rules" | "ai";
}

async function sanitize(text: string): Promise<SanitizationResult> {
  // Layer 1: Fast rule-based detection (< 10ms)
  const ruleDetections = detectWithRules(text);

  // Layer 2: AI-powered context-aware detection (< 2s)
  const aiDetections = await detectWithAI(text, ruleDetections);

  // Layer 3: Hybrid validator combines results
  const allDetections = mergeDetections(ruleDetections, aiDetections);

  // Layer 4: Apply redactions
  const sanitized = applyRedactions(text, allDetections);

  // Layer 5: Audit log
  await logSanitization(text, sanitized, allDetections);

  return {
    sanitized,
    detections: allDetections,
    confidence: calculateConfidence(allDetections),
    method: "hybrid"
  };
}
```

### Reversible Pseudonymization (Optional)

For within-session linking:

```typescript
interface PseudonymizationMapping {
  sessionId: string;
  mappings: Map<string, string>; // original → placeholder
  encrypted: boolean;
  ttl: number; // Auto-delete after N seconds
}

// Per-session mapping stored separately with envelope encryption
const sessionMapping = {
  sessionId: "conv-123",
  mappings: new Map([
    ["user@example.com", "<EMAIL_1>"],
    ["John Doe", "<PERSON_1>"]
  ]),
  encrypted: true,
  ttl: 86400 // 24 hours
};
```

### Confidence Thresholds

```typescript
interface SanitizationPolicy {
  minConfidence: number; // 0.8 = require 80% confidence
  reviewThreshold: number; // 0.6 = manual review if 60-80%
  blockThreshold: number; // 0.0 = block if any PII detected

  async handleBorderline(result: SanitizationResult): Promise<Action> {
    if (result.confidence < this.minConfidence) {
      if (result.confidence >= this.reviewThreshold) {
        return "QUARANTINE_FOR_REVIEW";
      } else {
        return "BLOCK_STORAGE";
      }
    }
    return "ALLOW_STORAGE";
  }
}
```

### Redaction Format with Entity Tags

```typescript
function applyRedactions(text: string, detections: Detection[]): string {
  let sanitized = text;
  const entityCounts = new Map<PIICategory, number>();

  // Sort by position (reverse) to maintain indices
  detections.sort((a, b) => b.position.start - a.position.start);

  for (const detection of detections) {
    // Increment counter for this entity type
    const count = (entityCounts.get(detection.category) || 0) + 1;
    entityCounts.set(detection.category, count);

    // Generate placeholder
    const placeholder = `<${detection.category}_${count}>`;

    // Replace
    sanitized =
      sanitized.slice(0, detection.position.start) +
      placeholder +
      sanitized.slice(detection.position.end);
  }

  return sanitized;
}
```

### Streaming Sanitization

Avoid buffering raw content:

```typescript
async function* streamingSanitize(
  eventStream: AsyncIterable<string>
): AsyncGenerator<string> {
  let buffer = "";

  for await (const chunk of eventStream) {
    buffer += chunk;

    // Process complete sentences
    const sentences = buffer.split(/[.!?]\s+/);
    buffer = sentences.pop() || ""; // Keep incomplete sentence

    for (const sentence of sentences) {
      const { sanitized } = await sanitize(sentence);
      yield sanitized + ". ";
    }
  }

  // Process remaining buffer
  if (buffer) {
    const { sanitized } = await sanitize(buffer);
    yield sanitized;
  }
}
```

### Evidence of Sanitization

Store metadata with every record:

```typescript
interface SanitizationEvidence {
  recordId: string;
  timestamp: string;
  detectorVersion: string; // "rules-v1.2 + ai-v2.0"
  detectionsCount: number;
  categoriesDetected: PIICategory[];
  confidence: number;
  reviewStatus: "auto" | "reviewed" | "quarantined";
  auditor: string; // "automated" | "human-reviewer-id"
}
```

### Right to Delete Process

Even for sanitized data:

```typescript
async function handleDeletionRequest(userId: string, conversationId: string) {
  // 1. Delete sanitized conversation
  await db.conversations.delete({ id: conversationId });

  // 2. Delete pseudonymization mappings
  await db.pseudonymMappings.delete({ conversationId });

  // 3. Delete derived learnings
  await db.learnings.delete({ sourceConversationId: conversationId });

  // 4. Add to revocation list for global network
  await db.revocations.insert({
    conversationId,
    timestamp: new Date(),
    reason: "user-requested-deletion"
  });

  // 5. If already uploaded, publish revocation
  const upload = await db.uploads.findOne({ conversationId });
  if (upload) {
    await publishRevocation(upload.ipfsCid);
  }
}
```

### Post-Ingest Audits

Continuous validation:

```typescript
async function runSanitizationAudit() {
  // Randomly sample stored conversations
  const samples = await db.conversations.sample(100);

  for (const conv of samples) {
    // Re-run detection on stored data
    const { detections } = await sanitize(conv.sanitizedContent);

    if (detections.length > 0) {
      // Found PII in supposedly sanitized data!
      await alert({
        severity: "CRITICAL",
        message: `PII found in stored conversation ${conv.id}`,
        detections
      });

      // Quarantine
      await db.conversations.update(conv.id, {
        status: "QUARANTINED",
        quarantineReason: "post-ingest-pii-detection"
      });
    }
  }
}

// Run nightly
schedule("0 2 * * *", runSanitizationAudit);
```

### Canary Scans

Inject known PII to verify detection:

```typescript
const canaryTests = [
  "My email is canary-test-001@example.com",
  "API key: sk_test_canary_12345",
  "My SSN is 123-45-6789",
  // ... more canaries
];

async function runCanaryTest() {
  for (const canary of canaryTests) {
    const { detections } = await sanitize(canary);

    if (detections.length === 0) {
      await alert({
        severity: "CRITICAL",
        message: "Sanitization canary test failed",
        canary
      });
    }
  }
}

// Run on every deployment
```

## Risks and Mitigations

### Risk: False Negatives (Missed PII)

**Impact**: Critical - Privacy violation

**Mitigation**:
- Layered detection (rules + AI)
- Post-ingest audits (random sampling)
- Canary tests for known patterns
- User reporting mechanism
- Kill-switch for publishing if issues found
- Continuous pattern updates

### Risk: Over-Redaction (Utility Loss)

**Impact**: Medium - Reduced learning value

**Mitigation**:
- Confidence thresholds (tune to balance precision/recall)
- Context-aware AI detection (distinguish names from code)
- Manual review queue for borderline cases
- Feedback loop to improve detection
- Metrics on redaction rate

### Risk: Novel PII Patterns

**Impact**: High - New PII types not detected

**Mitigation**:
- Continuous pattern updates
- AI detection catches unknowns
- User feedback
- Regular security audits
- Bug bounty for finding missed PII

## Related Documents

### Architecture
- [Sanitization Pipeline Architecture](../architecture/architecture-sanitization-pipeline-2025-01-16.md)
- [Global Context Network](../architecture/architecture-global-context-network-2025-01-16.md)

### Decisions
- [ADR-001: Use Claude Hooks](./decision-use-claude-hooks-2025-01-16.md)
- [ADR-005: Use SQLite](./decision-use-sqlite-2025-01-16.md)

### Plans
- [Phase 2: Sanitization Pipeline](../plans/plan-phase-2-sanitization-2025-01-16.md)

### Reference
- [PII Detection Patterns](../reference/reference-pii-patterns-2025-01-16.md)

================
File: decisions/decision-subagent-driven-development-2025-01-16.md
================
---
title: ADR-002: Subagent-Driven Development
category: decision
date: 2025-01-16
status: accepted
deciders: Claude + Dennison
tags: [subagents, claude-agent-sdk, development-workflow, architecture]
---

# ADR-002: Subagent-Driven Development

## Status

Accepted

Date: 2025-01-16

## Context

The Global Context Network is a complex system with multiple specialized components:
- Event capture with strict latency constraints
- Privacy-critical sanitization pipeline
- Async job processing with reliability guarantees
- Learning extraction requiring domain expertise
- MCP server implementation
- Blockchain/IPFS integration

Each component requires:
- **Specialized expertise** in its domain
- **Comprehensive testing** with high coverage
- **Quality validation** at every step
- **Consistent implementation** across components
- **Parallel development** where possible

Traditional development approaches struggle with:
1. **Context limits** - Single agent can't hold all system knowledge
2. **Specialization** - One agent can't be expert in all domains
3. **Quality variance** - No built-in validation of implementation quality
4. **Sequential bottlenecks** - Can't parallelize independent tasks
5. **Test generation gaps** - Manual test writing is slow and incomplete

The system naturally decomposes into a DAG of asynchronous enrichment tasks (capture → sanitize → store → extract → publish) where independent agents map well to pipeline stages.

## Decision

Use specialized subagents (via Claude Agent SDK) for ALL implementation and testing.

**Core Principle**: Never implement directly - always delegate to specialized subagents.

**Subagent Types**:
1. **Implementation subagents** - Build features (hooks, sanitization, MCP, etc.)
2. **Test generation subagents** - Create comprehensive test suites
3. **Test validation subagents** - Validate test quality and coverage
4. **Quality gate subagents** - Enforce code standards and security
5. **Integration subagents** - Verify component interactions

**Orchestration**:
- Main agent coordinates subagent execution
- DAG orchestration with explicit inputs/outputs
- Idempotency contracts per subagent
- Parallel execution of independent subagents
- Sequential execution for dependencies

## Consequences

### Positive

- **Parallel execution** - Independent components built simultaneously
- **Specialized expertise** - Each subagent expert in its domain
- **Built-in validation** - Quality gates at every step
- **Comprehensive testing** - Automated test generation and validation
- **Consistent patterns** - Same approach across all components
- **Clear separation** - Focused responsibility per subagent
- **Auditability** - Complete trace of decisions and artifacts
- **Maintainability** - Easy to update individual subagents

### Negative

- **Orchestration complexity** - Managing subagent dependencies and DAG
- **Vendor dependency** - Requires Claude Agent SDK and API access
- **Cost** - API token usage for subagent-to-subagent communication
- **Non-determinism** - LLM outputs can vary between runs
- **Debugging complexity** - Harder to trace issues across subagents
- **Learning curve** - Team must understand subagent orchestration

### Neutral

- **Requires Claude Agent SDK** - Adds dependency on SDK
- **Prompt engineering** - Quality depends on subagent prompt design
- **Artifact storage** - Need to store subagent outputs and prompts
- **Versioning** - Must version subagent configurations

## Alternatives Considered

### Alternative 1: Human-Written Code with Automated Checks

**Description**: Developers write code manually, CI runs automated linting/tests.

**Pros**:
- Full control over implementation
- No LLM dependency
- Deterministic results
- Standard industry practice

**Cons**:
- Slower development (no parallel execution)
- Inconsistent quality across developers
- Manual test writing is time-consuming
- No automated test quality validation
- Harder to maintain consistency across components

**Why not chosen**: Too slow for MVP timeline, lacks automated test generation, no built-in quality validation.

### Alternative 2: Monolithic Agent (Single Large Prompt)

**Description**: One agent with a large prompt containing all system knowledge.

**Pros**:
- Simpler orchestration
- No coordination overhead
- Single context window

**Cons**:
- Context limits (can't hold entire system)
- No specialization
- Can't parallelize
- Lower quality (jack-of-all-trades)
- Loses focus across components

**Why not chosen**: Doesn't scale, can't parallelize, quality suffers from lack of specialization.

### Alternative 3: Orchestrator Frameworks (Temporal, Prefect, Dagster)

**Description**: Use workflow orchestration framework for task DAG.

**Pros**:
- Battle-tested orchestration
- Built-in retry and error handling
- Good observability
- Scales to production

**Cons**:
- Still need to write task code manually
- Doesn't provide specialized expertise
- No automated test generation
- Operational overhead (deploy orchestrator)
- Overkill for MVP

**Why not chosen**: Solves orchestration but not the core problem (specialized implementation and test generation). Could be adopted post-MVP.

### Alternative 4: Non-Claude Agent Ecosystems (LangChain, LlamaIndex, OpenAI Assistants)

**Description**: Use alternative agent frameworks.

**Pros**:
- Reduces vendor lock-in
- More ecosystem options
- Potentially lower cost

**Cons**:
- Less integrated with Claude Code
- Different quality characteristics
- Need to learn new frameworks
- May lack specialization features
- Migration cost if switching

**Why not chosen**: Claude Agent SDK integrates best with Claude Code, proven quality. Can evaluate alternatives post-MVP.

### Alternative 5: Reduced Surface (Few Composable Tools)

**Description**: One orchestrator agent with a few composable tools instead of many subagents.

**Pros**:
- Simpler architecture
- Easier to reason about
- Lower cost

**Cons**:
- Less specialization
- Can't parallelize as effectively
- Lower quality per component
- Manual test generation still needed

**Why not chosen**: Doesn't leverage specialization benefits, sacrifices quality for simplicity.

## Implementation

### DAG Orchestration

```typescript
interface SubagentConfig {
  name: string;
  description: string;
  prompt: string;
  tools: string[];
  model: "sonnet" | "opus" | "haiku";
  temperature: number; // Near-deterministic for CI
  inputs: string[]; // Required input artifacts
  outputs: string[]; // Produced artifacts
  idempotencyKey: (inputs: any) => string;
}

interface SubagentResult {
  success: boolean;
  artifacts: Record<string, any>;
  metrics: {
    latency: number;
    tokenSpend: number;
    retries: number;
  };
}
```

### Subagent Execution

```typescript
async function executeSubagent(
  config: SubagentConfig,
  inputs: any
): Promise<SubagentResult> {
  // Check idempotency
  const key = config.idempotencyKey(inputs);
  if (cache.has(key)) {
    return cache.get(key);
  }

  // Execute with SDK
  const result = await query({
    prompt: config.prompt,
    options: {
      model: config.model,
      temperature: config.temperature,
      agents: { [config.name]: config }
    }
  });

  // Track metrics
  const metrics = {
    latency: Date.now() - start,
    tokenSpend: result.tokenUsage,
    retries: retryCount
  };

  // Cache result
  cache.set(key, { success: true, artifacts: result, metrics });

  return { success: true, artifacts: result, metrics };
}
```

### Prompt Template Versioning

Store prompts with version control:

```typescript
// subagents/v1/hook-developer.ts
export const hookDeveloperPrompt = {
  version: "1.0",
  template: `You are a Claude Code hooks expert.

  Implement:
  - UserPromptSubmit hook (< 100ms)
  - Stop hook (< 100ms)
  - Event serialization
  - Error handling (never block user)

  Follow TDD: write tests first.

  Inputs: {{requirements}}

  Success criteria:
  - All tests pass
  - Hook latency < 100ms p95
  - No user blocking
  - Proper error handling`,
  temperature: 0.3 // Near-deterministic
};
```

### Cost and SLO Budgets

Per-subagent budget tracking:

```typescript
interface SubagentBudget {
  maxTokensPerRun: number;
  maxLatencyMs: number;
  maxRetries: number;
  alertThreshold: number; // % of budget
}

const budgets: Record<string, SubagentBudget> = {
  "hook-developer": {
    maxTokensPerRun: 10000,
    maxLatencyMs: 30000,
    maxRetries: 3,
    alertThreshold: 0.8
  }
};
```

### Guardrails and Acceptance Criteria

Define quality thresholds per subagent:

```typescript
interface SubagentAcceptanceCriteria {
  minTestCoverage: number;
  maxPIILeakageScore: number;
  maxSecurityIssues: number;
  requiredChecks: string[];
}

const criteria = {
  "sanitization-pipeline": {
    minTestCoverage: 0.95, // Critical component
    maxPIILeakageScore: 0.0, // Zero tolerance
    maxSecurityIssues: 0,
    requiredChecks: ["pii-detection", "redaction-audit"]
  }
};
```

### Observability Per Subagent

Track metrics for each subagent:

```typescript
interface SubagentMetrics {
  invocationCount: number;
  successRate: number;
  averageLatency: number;
  p95Latency: number;
  totalTokenSpend: number;
  errorRate: number;
  retryRate: number;
}
```

### Determinism and Reproducibility

For CI and debugging:

1. **Set low temperature** (0.1-0.3) for near-deterministic outputs
2. **Use fixed seeds** when possible
3. **Mock external dependencies** for test subagents
4. **Store prompt versions** with git hash
5. **Capture full inputs/outputs** for replay

### Traceability

Each subagent execution produces:

```typescript
interface SubagentTrace {
  subagentName: string;
  version: string;
  executionId: string;
  timestamp: string;
  inputs: any;
  outputs: any;
  promptUsed: string;
  metrics: SubagentMetrics;
  artifacts: string[]; // Paths to generated files
}
```

## Risks and Mitigations

### Risk: Cost Explosion from Agent Chatter

**Impact**: High - Could exceed budget

**Mitigation**:
- Set token budgets per subagent
- Monitor spend in real-time
- Alert at 80% of budget
- Use Haiku for simple tasks
- Cache subagent results aggressively

### Risk: Non-Determinism Breaks CI

**Impact**: Medium - Flaky builds

**Mitigation**:
- Low temperature (0.1-0.3) for production subagents
- Retry with same seed
- Quarantine flaky results
- Human review for critical paths

### Risk: Debugging Difficulty

**Impact**: Medium - Hard to trace issues

**Mitigation**:
- Full trace logging per subagent
- Artifact preservation
- Replay capability
- Clear error messages with context

### Risk: Vendor Lock-In

**Impact**: Medium - Hard to migrate

**Mitigation**:
- Abstract subagent interface
- Store prompts as configuration
- Document alternative frameworks
- Plan migration path for post-MVP

## Related Documents

### Architecture
- [Subagent System Architecture](../architecture/architecture-subagent-system-2025-01-16.md)
- [Global Context Network](../architecture/architecture-global-context-network-2025-01-16.md)

### Decisions
- [ADR-003: Claude Testing Harness](./decision-claude-testing-harness-2025-01-16.md)

### Guides
- [Using Subagents Guide](../guides/guide-using-subagents-2025-01-16.md)
- [TDD Workflow with Subagents](../guides/guide-tdd-workflow-2025-01-16.md)

### Reference
- [Subagent Types Reference](../reference/reference-subagent-types-2025-01-16.md)
- [Claude Agent SDK API](../reference/reference-claude-agent-sdk-api-2025-01-16.md)

================
File: decisions/decision-use-claude-hooks-2025-01-16.md
================
---
title: ADR-001: Use Claude Code Hooks for Event Capture
category: decision
date: 2025-01-16
status: accepted
deciders: Claude + Dennison
tags: [hooks, event-capture, claude-code, privacy]
---

# ADR-001: Use Claude Code Hooks for Event Capture

## Status

Accepted

Date: 2025-01-16

## Context

The Global Context Network needs to capture user prompts and agent responses to extract learnings. This capture must:

1. **Never block user interaction** - UX constraint of p95 < 100ms
2. **Minimize data surface area pre-sanitization** - Privacy-first architecture
3. **Capture complete conversations** - User prompts, agent responses, tool calls
4. **Preserve context** - Conversation flow, timestamps, metadata
5. **Be reliable** - No missed events, persist across restarts

The capture point must happen as close to the source as possible to ensure sanitization occurs before data spreads through the system.

## Decision

Use Claude Code's native hook system (UserPromptSubmit and Stop hooks) for event capture.

**Implementation**:
- Configure hooks via `.claude/hooks.json`
- UserPromptSubmit hook captures user input
- Stop hook captures agent responses and tool calls
- Events queued to persistent storage < 50ms
- Fire-and-forget with bounded ring buffer
- Explicit user opt-in per project

**Performance SLOs**:
- Hook execution p95 < 100ms
- Event queueing < 50ms
- Timeout after 100ms to prevent blocking
- Bounded ring buffer (max 1000 events) for backpressure

## Consequences

### Positive

- **Non-blocking capture** - Hooks execute asynchronously, never block user
- **Source-level access** - Captures data before it spreads through system
- **Complete conversation context** - Access to full prompt/response pairs
- **Native integration** - Uses Claude Code's supported APIs
- **Minimal data surface area** - Sanitization can happen immediately after capture
- **Tool call visibility** - Captures all tool invocations and results
- **Privacy-preserving** - Nothing persisted until sanitization passes

### Negative

- **Vendor lock-in** - Tightly coupled to Claude Code
- **API stability risk** - Hook contract may change between versions
- **Configuration overhead** - Requires hooks.json setup
- **Limited portability** - Can't easily switch to other AI coding tools
- **Versioning complexity** - Need to handle hook schema changes

### Neutral

- **Per-project opt-in** - Users must explicitly enable per project
- **Requires configuration** - Not zero-config out of the box
- **Event schema versioning** - Must track hook versions for compatibility

## Alternatives Considered

### Alternative 1: IDE/LSP Plugin Instrumentation

**Description**: Build VS Code extension that captures prompts/responses via Language Server Protocol.

**Pros**:
- Not tied to Claude Code specifically
- Could work with multiple AI coding tools
- More portable across editors

**Cons**:
- Higher latency (>100ms) due to additional layers
- Can't capture internal state or tool calls
- More complex setup and maintenance
- Delayed capture point (data already spread)

**Why not chosen**: Higher latency violates UX constraints, and delayed capture point increases PII surface area before sanitization.

### Alternative 2: Export APIs (Periodic Batch Export)

**Description**: Export conversations periodically via Claude Code's export functionality.

**Pros**:
- Simpler integration
- No runtime performance impact
- Decoupled from real-time execution

**Cons**:
- No real-time capture
- Missing intermediate states
- Can't capture ongoing conversations
- User must remember to export
- Higher PII risk (longer time before sanitization)

**Why not chosen**: Fails to meet "never lose data" requirement and delays sanitization dangerously.

### Alternative 3: HTTP/SOCKS Proxy with MITM

**Description**: Intercept HTTP traffic between Claude Code and Anthropic API.

**Pros**:
- Tool-agnostic
- Complete capture of API traffic

**Cons**:
- Not viable with certificate pinning
- Breaks E2E encryption
- Complex setup
- Security risk
- Can't capture local tool calls

**Why not chosen**: Security concerns and incompatible with Claude Code's implementation.

### Alternative 4: Manual Logging

**Description**: Users manually trigger capture via commands.

**Pros**:
- Simple implementation
- Full user control

**Cons**:
- Error-prone (users forget)
- Incomplete coverage
- Poor UX
- Not suitable for automated learning extraction

**Why not chosen**: Unreliable, defeats purpose of automated learning extraction.

### Alternative 5: File System Watchers

**Description**: Watch Claude Code's conversation storage files.

**Pros**:
- No Claude Code integration needed
- Simple implementation

**Cons**:
- Too late (data already persisted)
- Can't capture thinking/tool calls
- Depends on undocumented file formats
- Brittle to Claude Code updates
- Misses pre-sanitization window

**Why not chosen**: Violates privacy-first principle (capture happens after persistence).

## Implementation

### Hook Configuration

```json
{
  "hooks": {
    "UserPromptSubmit": {
      "command": "node",
      "args": [".claude/hooks/capture-prompt.js"],
      "timeout": 100
    },
    "Stop": {
      "command": "node",
      "args": [".claude/hooks/capture-response.js"],
      "timeout": 100
    }
  }
}
```

### Event Schema

Define canonical event model versioned for compatibility:

```typescript
interface CapturedEvent {
  version: "1.0";
  timestamp: string; // ISO8601
  type: "UserPromptSubmit" | "Stop";
  conversationId: string;
  clientVersion: string;

  // UserPromptSubmit fields
  prompt?: string;

  // Stop fields
  response?: string;
  toolCalls?: ToolCall[];

  // Metadata
  redactionStatus: "pending" | "sanitized" | "failed";
  hookVersion: string;
}
```

### Consent and Scope

- **Explicit opt-in** - Per-project .claude/hooks.json must be created
- **Guard rails** - Nothing persisted until sanitization passes
- **User control** - Users can disable hooks at any time
- **Transparency** - Clear documentation of what's captured

### Performance Safeguards

- **Timeout enforcement** - 100ms hard limit
- **Ring buffer** - Bounded queue (1000 events max)
- **Backpressure handling** - Drop oldest events if overwhelmed
- **Offline mode** - Queue persists, flushes when online
- **Sampling** - Can reduce capture rate if system overloaded

### Observability

Privacy-safe counters (no PII logged):

```typescript
{
  eventsCaptures: number;
  eventsDropped: number;
  eventsSanitized: number;
  eventsFailed: number;
  averageHookLatency: number;
  p95HookLatency: number;
}
```

### Compatibility and Versioning

- **Hook contract documentation** - Events, fields, versions tracked
- **Version detection** - Check Claude Code version on startup
- **Fallback strategy** - Graceful degradation if hooks unavailable
- **Migration plan** - Handle schema changes across versions

### What We Do NOT Capture

**CRITICAL: Chain-of-thought prohibition**

- **Do NOT capture hidden chain-of-thought** - Violates provider policies
- **Only capture observable outputs** - User-visible responses only
- **Only capture tool calls** - Structured, user-approved actions
- **Only capture explicit rationales** - If model emits them publicly

This aligns with Anthropic's usage policies and prevents compliance risks.

## Risks and Mitigations

### Risk: Hook API Changes

**Impact**: High - Could break capture entirely

**Mitigation**:
- Version detection on startup
- Graceful degradation if unsupported
- Test against multiple Claude Code versions
- Monitor Claude Code release notes

### Risk: Performance Degradation

**Impact**: High - Could block users

**Mitigation**:
- Hard 100ms timeout
- Ring buffer prevents unbounded growth
- Monitoring of p95 latency
- Circuit breaker if latency spikes

### Risk: Incomplete Capture

**Impact**: Medium - Missing events reduces learning quality

**Mitigation**:
- Persistent queue survives restarts
- Retry failed events
- Alert on high drop rate
- Audit trail of dropped events

## Related Documents

### Architecture
- [Global Context Network Architecture](../architecture/architecture-global-context-network-2025-01-16.md)
- [Event Capture System](../architecture/architecture-hooks-event-capture-2025-01-16.md)

### Decisions
- [ADR-004: Sanitize Before Storage](./decision-sanitize-before-storage-2025-01-16.md)
- [ADR-006: Async Processing Model](./decision-async-processing-model-2025-01-16.md)

### Plans
- [Phase 1: Event Capture](../plans/plan-phase-1-event-capture-2025-01-16.md)

### Reference
- [Event Schema Reference](../reference/reference-event-schema-2025-01-16.md)

================
File: decisions/decision-use-sqlite-2025-01-16.md
================
---
title: ADR-005: Use SQLite for MVP Storage
category: decision
date: 2025-01-16
status: accepted
deciders: Claude + Dennison
tags: [database, sqlite, storage, local-first]
---

# ADR-005: Use SQLite for MVP Storage

## Status

Accepted

Date: 2025-01-16

## Context

The Global Context Network MVP needs persistent storage for:

1. **Sanitized conversations** - User prompts and agent responses
2. **Extracted learnings** - Insights and patterns
3. **Job queue** - Async processing tasks
4. **Upload tracking** - Network synchronization state
5. **Sanitization audit log** - PII redaction history

**Requirements**:
- ACID compliance (data integrity critical)
- Fast queries (< 100ms p95 for MCP server)
- Persistent across restarts
- Local-first (no network dependency)
- Simple setup (zero-config ideal)
- Migration support (schema evolution)
- Indexing for performance
- Transaction support for atomicity

**Constraints**:
- MVP is single-user, local-only
- Development machine environment
- No distributed access needed (yet)
- Budget-conscious (avoid operational overhead)

## Decision

Use SQLite with migrations for MVP storage.

**Configuration**:
- Write-Ahead Logging (WAL) mode for concurrency
- `synchronous=NORMAL` for performance/safety balance
- `busy_timeout=5000` for write contention
- Versioned migrations (forward-only)
- Indexes on all query paths

**Migration path to PostgreSQL** defined for post-MVP scaling.

## Consequences

### Positive

- **Zero-configuration** - Embedded database, no setup
- **ACID compliance** - Full transactional guarantees
- **Fast queries** - Indexed queries < 100ms easily achieved
- **Easy backup** - Single file copy
- **No operational overhead** - No server to maintain
- **Proven technology** - Battle-tested, stable
- **Great tooling** - SQLite CLI, many GUIs
- **Small footprint** - Minimal resource usage
- **Clear migration path** - Can upgrade to PostgreSQL later

### Negative

- **Single writer** - Only one write at a time (fine for MVP)
- **Not distributed** - Can't share across machines
- **File-based limits** - Performance degrades at very large sizes
- **No built-in replication** - Must implement separately
- **Limited concurrency** - Not ideal for high-concurrency workloads

### Neutral

- **File permissions** - Must manage OS-level access
- **Backup strategy** - Need to implement file copying
- **Corruption recovery** - Rare but need plan
- **Size monitoring** - Watch for growth

## Alternatives Considered

### Alternative 1: PostgreSQL

**Description**: Use PostgreSQL from the start.

**Pros**:
- Multi-writer concurrency
- Excellent performance at scale
- Robust replication
- Advanced features (JSONB, full-text search)
- Industry standard

**Cons**:
- **Overkill for MVP** - Single user doesn't need multi-writer
- **Setup complexity** - Install, configure, manage server
- **Operational overhead** - Monitor, backup, upgrade server
- **Resource usage** - Heavier than SQLite
- **Network dependency** - Even for local use

**Why not chosen**: Too much overhead for single-user MVP. Can migrate later when multi-user is needed.

### Alternative 2: MongoDB

**Description**: Use document database.

**Pros**:
- Flexible schema
- Good for unstructured data
- Horizontal scaling
- (Note: MongoDB does have ACID transactions since v4.x in replica sets)

**Cons**:
- **Operational overhead** - Server management
- **Document model not needed** - Our data is structured
- **Replica set needed for ACID** - Adds complexity
- **Resource usage** - Heavier than SQLite
- **Migration complexity** - Harder to move to SQL later

**Why not chosen**: Document model and schema flexibility not needed. Operational overhead too high for MVP.

### Alternative 3: JSON Files

**Description**: Store data as JSON files on disk.

**Pros**:
- Very simple
- Human-readable
- Easy to inspect/debug
- No dependencies

**Cons**:
- **No query performance** - Must load entire files
- **No transactions** - Race conditions possible
- **No ACID guarantees** - Data corruption risk
- **Indexing impossible** - Linear scans only
- **Concurrency issues** - File locking problems

**Why not chosen**: Unacceptable performance and reliability for production system.

### Alternative 4: In-Memory Database (Redis, Memcached)

**Description**: Keep all data in memory.

**Pros**:
- Extremely fast
- Simple data structures
- Good for caching

**Cons**:
- **Data loss on restart** - Not persistent (or requires snapshots)
- **Memory constraints** - Limited by RAM
- **No complex queries** - Limited query capabilities
- **Operational overhead** - Server management

**Why not chosen**: "Never lose data" requirement demands persistence. Not suitable for primary storage.

### Alternative 5: DuckDB

**Description**: Use DuckDB (analytical database) for local storage.

**Pros**:
- Embedded like SQLite
- Excellent analytical queries
- Columnar storage
- Very fast aggregations

**Cons**:
- **OLAP not OLTP** - Optimized for analytics, not transactions
- **Overkill for MVP** - We don't have complex analytical needs yet
- **Less mature** - Newer than SQLite
- **Write performance** - Optimized for reads, not writes

**Why not chosen**: Wrong optimization target. We need OLTP (transactional), not OLAP (analytical). Could add later for analytics.

### Alternative 6: SQLCipher (SQLite with Encryption)

**Description**: Use encrypted SQLite variant.

**Pros**:
- All SQLite benefits
- Encryption at rest
- Good for sensitive data
- Drop-in SQLite replacement

**Cons**:
- Performance overhead (encryption/decryption)
- Key management complexity
- Not needed for MVP (data is sanitized)

**Why not chosen**: Since we sanitize before storage, encryption at rest is lower priority. Can add post-MVP if needed.

### Alternative 7: LiteFS / Litestream

**Description**: SQLite with replication/streaming backup.

**Pros**:
- SQLite compatibility
- Built-in replication
- Continuous backup
- Multi-region support

**Cons**:
- Additional complexity
- Not needed for single-user MVP
- Operational overhead

**Why not chosen**: Replication not needed for MVP. Can add when multi-user support required.

## Implementation

### SQLite Configuration

```typescript
import Database from "better-sqlite3";

const db = new Database("global-context.db", {
  // WAL mode for better concurrency
  // Allows readers while writer is active
  wal: true,

  // Read-only mode (false for read-write)
  readonly: false,

  // Create if doesn't exist
  fileMustExist: false,

  // Timeout for busy database
  timeout: 5000 // 5 seconds
});

// Performance and safety tuning
db.pragma("synchronous = NORMAL"); // Balance safety and performance
db.pragma("cache_size = 10000"); // ~40MB cache
db.pragma("temp_store = memory"); // Temporary tables in memory
db.pragma("mmap_size = 30000000000"); // Memory-mapped I/O
db.pragma("journal_mode = WAL"); // Write-Ahead Logging
db.pragma("busy_timeout = 5000"); // 5 second timeout on locks
```

### Schema Versioning and Migrations

```typescript
interface Migration {
  version: number;
  name: string;
  up: string; // SQL to apply migration
  down: string; // SQL to rollback (optional for MVP)
}

const migrations: Migration[] = [
  {
    version: 1,
    name: "initial-schema",
    up: `
      CREATE TABLE conversations (
        id TEXT PRIMARY KEY,
        created_at INTEGER NOT NULL,
        updated_at INTEGER NOT NULL,
        status TEXT NOT NULL,
        message_count INTEGER DEFAULT 0
      );

      CREATE INDEX idx_conversations_created ON conversations(created_at);
      CREATE INDEX idx_conversations_status ON conversations(status);

      CREATE TABLE migrations (
        version INTEGER PRIMARY KEY,
        name TEXT NOT NULL,
        applied_at INTEGER NOT NULL
      );
    `,
    down: `
      DROP TABLE conversations;
      DROP TABLE migrations;
    `
  },
  {
    version: 2,
    name: "add-learnings-table",
    up: `
      CREATE TABLE learnings (
        id TEXT PRIMARY KEY,
        conversation_id TEXT NOT NULL,
        category TEXT NOT NULL,
        content TEXT NOT NULL,
        confidence REAL NOT NULL,
        created_at INTEGER NOT NULL,
        FOREIGN KEY (conversation_id) REFERENCES conversations(id)
      );

      CREATE INDEX idx_learnings_conversation ON learnings(conversation_id);
      CREATE INDEX idx_learnings_category ON learnings(category);
      CREATE INDEX idx_learnings_confidence ON learnings(confidence);
    `,
    down: "DROP TABLE learnings;"
  }
  // ... more migrations
];

async function runMigrations() {
  // Ensure migrations table exists
  db.exec(`
    CREATE TABLE IF NOT EXISTS migrations (
      version INTEGER PRIMARY KEY,
      name TEXT NOT NULL,
      applied_at INTEGER NOT NULL
    );
  `);

  // Get current version
  const current = db.prepare("SELECT MAX(version) as version FROM migrations").get();
  const currentVersion = current?.version || 0;

  // Apply pending migrations
  for (const migration of migrations) {
    if (migration.version > currentVersion) {
      console.log(`Applying migration ${migration.version}: ${migration.name}`);

      db.transaction(() => {
        db.exec(migration.up);
        db.prepare(`
          INSERT INTO migrations (version, name, applied_at)
          VALUES (?, ?, ?)
        `).run(migration.version, migration.name, Date.now());
      })();

      console.log(`✓ Migration ${migration.version} applied`);
    }
  }
}
```

### Index Strategy

All query paths must be indexed:

```sql
-- Conversations
CREATE INDEX idx_conversations_created ON conversations(created_at);
CREATE INDEX idx_conversations_status ON conversations(status);

-- Messages
CREATE INDEX idx_messages_conversation ON messages(conversation_id);
CREATE INDEX idx_messages_created ON messages(created_at);

-- Learnings
CREATE INDEX idx_learnings_conversation ON learnings(conversation_id);
CREATE INDEX idx_learnings_category ON learnings(category);
CREATE INDEX idx_learnings_confidence ON learnings(confidence);
CREATE INDEX idx_learnings_created ON learnings(created_at);

-- Composite index for common query
CREATE INDEX idx_learnings_category_confidence
  ON learnings(category, confidence);

-- Job queue
CREATE INDEX idx_jobs_status ON job_queue(status);
CREATE INDEX idx_jobs_priority_created ON job_queue(priority, created_at);
```

### Query Budget Enforcement

```typescript
interface QueryBudget {
  maxDuration: number; // ms
  slowQueryThreshold: number; // ms
  logSlowQueries: boolean;
}

const budget: QueryBudget = {
  maxDuration: 100, // p95 target
  slowQueryThreshold: 50, // Log if > 50ms
  logSlowQueries: true
};

function query<T>(sql: string, params: any[]): T {
  const start = Date.now();

  try {
    const result = db.prepare(sql).all(...params);
    const duration = Date.now() - start;

    if (duration > budget.slowQueryThreshold) {
      console.warn(`Slow query (${duration}ms): ${sql}`);
    }

    return result as T;
  } catch (error) {
    console.error(`Query failed: ${sql}`, error);
    throw error;
  }
}
```

### Backup Strategy

```typescript
async function backup() {
  const timestamp = new Date().toISOString().replace(/:/g, "-");
  const backupPath = `./backups/global-context-${timestamp}.db`;

  // Use SQLite backup API
  const backup = db.backup(backupPath);

  return new Promise((resolve, reject) => {
    backup.step(-1); // Copy entire database
    backup.finish();

    // Verify backup
    const backupDb = new Database(backupPath, { readonly: true });
    const integrity = backupDb.pragma("integrity_check");
    backupDb.close();

    if (integrity[0].integrity_check === "ok") {
      console.log(`✓ Backup created: ${backupPath}`);
      resolve(backupPath);
    } else {
      reject(new Error("Backup integrity check failed"));
    }
  });
}

// Schedule daily backups
schedule("0 3 * * *", backup);
```

### File Permissions

```typescript
import { chmod } from "fs/promises";

// Restrict database file to owner only
async function secureDatabaseFile() {
  await chmod("global-context.db", 0o600); // rw-------
  await chmod("global-context.db-shm", 0o600); // Shared memory file
  await chmod("global-context.db-wal", 0o600); // WAL file
}
```

### Corruption Recovery

```typescript
async function checkDatabaseIntegrity(): Promise<boolean> {
  try {
    const result = db.pragma("integrity_check");
    return result[0].integrity_check === "ok";
  } catch (error) {
    console.error("Integrity check failed:", error);
    return false;
  }
}

async function recoverFromCorruption() {
  console.error("Database corruption detected");

  // 1. Close database
  db.close();

  // 2. Try to dump to SQL
  const dumpPath = `./recovery/dump-${Date.now()}.sql`;
  exec(`sqlite3 global-context.db .dump > ${dumpPath}`);

  // 3. Create new database from dump
  const recoveredPath = `./recovery/recovered-${Date.now()}.db`;
  exec(`sqlite3 ${recoveredPath} < ${dumpPath}`);

  // 4. Verify recovered database
  const recoveredDb = new Database(recoveredPath);
  const integrity = recoveredDb.pragma("integrity_check");

  if (integrity[0].integrity_check === "ok") {
    console.log("✓ Database recovered successfully");
    // Replace original with recovered
    fs.renameSync(recoveredPath, "global-context.db");
  } else {
    console.error("Recovery failed - restore from backup");
    // Restore latest backup
    await restoreFromBackup();
  }
}
```

### Migration Threshold to PostgreSQL

Define when to migrate:

```typescript
interface MigrationTriggers {
  maxDatabaseSize: number; // bytes
  maxConcurrentWriters: number;
  requiresCrossMAchineAccess: boolean;
  requiresReplication: boolean;
}

const postgresThresholds: MigrationTriggers = {
  maxDatabaseSize: 5 * 1024 * 1024 * 1024, // 5GB
  maxConcurrentWriters: 1, // > 1 needs PostgreSQL
  requiresCrossMAchineAccess: false, // true needs PostgreSQL
  requiresReplication: false // true needs PostgreSQL
};

function shouldMigrateToPostgres(): boolean {
  const dbSize = fs.statSync("global-context.db").size;

  return (
    dbSize > postgresThresholds.maxDatabaseSize ||
    // Future checks:
    // concurrentWriters > postgresThresholds.maxConcurrentWriters ||
    // requiresCrossMAchineAccess ||
    // requiresReplication
  );
}
```

## Risks and Mitigations

### Risk: Database Corruption

**Impact**: High - Data loss

**Mitigation**:
- Daily backups with integrity checks
- WAL mode reduces corruption risk
- Regular integrity checks
- Recovery procedure documented
- Keep multiple backup generations

### Risk: Performance Degradation at Scale

**Impact**: Medium - Slow queries

**Mitigation**:
- Monitor database size
- Index all query paths
- Prune old data
- Migrate to PostgreSQL if needed
- Set query budgets and alerts

### Risk: Concurrent Write Contention

**Impact**: Low - MVP is single-threaded

**Mitigation**:
- WAL mode allows concurrent reads
- Busy timeout prevents immediate failures
- Transaction batching reduces locks
- Monitor lock wait times

## Related Documents

### Architecture
- [Global Context Network Architecture](../architecture/architecture-global-context-network-2025-01-16.md)
- [Database Schema](../architecture/architecture-database-schema-2025-01-16.md)

### Decisions
- [ADR-004: Sanitize Before Storage](./decision-sanitize-before-storage-2025-01-16.md)
- [ADR-006: Async Processing Model](./decision-async-processing-model-2025-01-16.md)

### Plans
- [Phase 3: Database and Storage](../plans/plan-phase-3-database-storage-2025-01-16.md)

### Reference
- [Database Schema Reference](../reference/reference-database-schema-2025-01-16.md)

================
File: decisions/INDEX.md
================
# Architecture Decision Records (ADRs)

> Last updated: 2025-01-16

## Overview

This directory contains Architecture Decision Records for the Global Context Network MVP. Each ADR documents a significant architectural decision, the context that led to it, alternatives considered, and consequences.

## Purpose

ADRs capture the "why" behind major architectural decisions:
- Context that motivated the decision
- The decision itself
- Alternatives considered with pros/cons
- Consequences (positive, negative, neutral)
- Implementation notes
- Risks and mitigations

## Documents

### Active ADRs

| ADR | Date | Document | Decision | Status |
|-----|------|----------|----------|--------|
| 001 | 2025-01-16 | [decision-use-claude-hooks-2025-01-16.md](./decision-use-claude-hooks-2025-01-16.md) | Use Claude Code hooks for event capture | Accepted |
| 002 | 2025-01-16 | [decision-subagent-driven-development-2025-01-16.md](./decision-subagent-driven-development-2025-01-16.md) | All implementation via specialized subagents | Accepted |
| 003 | 2025-01-16 | [decision-claude-testing-harness-2025-01-16.md](./decision-claude-testing-harness-2025-01-16.md) | Claude Agent SDK for test generation and validation | Accepted |
| 004 | 2025-01-16 | [decision-sanitize-before-storage-2025-01-16.md](./decision-sanitize-before-storage-2025-01-16.md) | Sanitize ALL data BEFORE database insertion | Accepted |
| 005 | 2025-01-16 | [decision-use-sqlite-2025-01-16.md](./decision-use-sqlite-2025-01-16.md) | SQLite with migrations for MVP storage | Accepted |
| 006 | 2025-01-16 | [decision-async-processing-model-2025-01-16.md](./decision-async-processing-model-2025-01-16.md) | SQLite-based job queue with async workers | Accepted |

## Decision Summary

### Core Principles

The ADRs embody these key principles:

1. **Privacy First** (ADR-004) - Sanitize before storage, zero-trust PII handling
2. **Never Block User** (ADR-001, ADR-006) - Async everything, hooks < 100ms
3. **Quality Gates** (ADR-002, ADR-003) - Testing harness, subagent validation
4. **Local-First MVP** (ADR-005, ADR-006) - SQLite, no external dependencies
5. **Migration Path** - All decisions support future scaling

### Technology Stack Decisions

| Aspect | Decision | ADR | Rationale |
|--------|----------|-----|-----------|
| Event Capture | Claude Code Hooks | 001 | Source-level capture, < 100ms, complete context |
| Development Model | Subagent-Driven | 002 | Parallel execution, specialized expertise, quality gates |
| Testing Strategy | Claude Testing Harness | 003 | Comprehensive coverage, automated quality scoring |
| Privacy Architecture | Sanitize Before Storage | 004 | Zero-trust PII, database inherently safe |
| Database | SQLite with WAL | 005 | Zero-config, ACID, fast queries, easy backup |
| Async Processing | SQLite Job Queue | 006 | Persistent, no external deps, offline tolerant |

### Key Trade-offs

**Chosen**:
- Simple setup (SQLite, embedded queue)
- Privacy first (sanitize before storage)
- Quality over speed (comprehensive testing)
- Local-first (no cloud dependencies for MVP)

**Deferred**:
- Distributed processing (Temporal, PostgreSQL, Redis)
- Advanced analytics (DuckDB)
- Blockchain/token rewards (simplified in MVP)
- Multi-user support

## ADR Writing Guidelines

### ADR Template Structure

```markdown
---
title: ADR-NNN: [Decision Title]
category: decision
date: YYYY-MM-DD
status: [proposed|accepted|deprecated|superseded]
deciders: [Names]
---

# ADR-NNN: [Decision Title]

## Status
[Status and date]

## Context
[What problem are we solving? What constraints?]

## Decision
[What did we decide to do?]

## Consequences
### Positive
### Negative
### Neutral

## Alternatives Considered
### Alternative 1: [Name]
**Description**: [What]
**Pros**: [List]
**Cons**: [List]
**Why not chosen**: [Reason]

## Implementation
[How will this be implemented?]

## Risks and Mitigations
### Risk: [Name]
**Impact**: [High/Medium/Low]
**Mitigation**: [How we address it]

## Related Documents
[Links to architecture, plans, guides]
```

### When to Create an ADR

Create an ADR when:
- Making a significant architectural decision
- Choosing between multiple viable approaches
- Decision will be hard to reverse
- Decision affects multiple components
- Team needs alignment on approach
- Future developers will ask "why did we do this?"

Don't create an ADR for:
- Trivial implementation details
- Temporary/experimental approaches
- Decisions easily reversed
- Pure coding style preferences

### ADR Status Lifecycle

- **Proposed** - Under discussion, not yet decided
- **Accepted** - Decision made and being implemented
- **Deprecated** - No longer recommended but may exist in code
- **Superseded** - Replaced by another ADR (link to it)

## Future ADRs (Identified by GPT-5 Review)

### Critical for Post-MVP

| Priority | Topic | Rationale |
|----------|-------|-----------|
| HIGH | Global Sharing Architecture | IPFS vs blockchain, what to share, pinning strategy |
| HIGH | Consent and Licensing | Opt-in model, data licensing, right-to-delete |
| HIGH | PII Detection Strategy | Layered detection, taxonomy, confidence thresholds |
| HIGH | Security and Provenance | Signing artifacts, key management, attestations |
| MEDIUM | Token Rewards Model | Defer vs implement, sybil resistance |
| MEDIUM | Observability and Cost SLOs | Telemetry, budgets, alerting |
| MEDIUM | Data Model Versioning | Schema evolution, cross-client compatibility |
| LOW | Chain-of-Thought Capture Policy | What to capture vs avoid |
| LOW | Right-to-Delete vs Immutability | GDPR/CCPA alignment strategy |

## GPT-5 Review Feedback

### What We Did Well
- Concise, principle-driven
- Honest about trade-offs
- Oriented to MVP constraints
- Clear migration paths

### What We Improved
- Corrected MongoDB ACID claim (ADR-005)
- Added more alternatives per ADR
- Expanded implementation notes
- Added risk/mitigation sections
- Removed "capture thinking" language (provider policy)
- Added consent and scope considerations (ADR-001)
- Improved "why" explanations

### Areas for Future Work
- Add missing ADRs for global sharing layer
- Document consent and licensing model
- Detail PII detection taxonomy
- Define security and provenance strategy

## Related Categories

- [Architecture](../architecture/INDEX.md) - System design documents
- [Plans](../plans/INDEX.md) - Implementation plans
- [Reference](../reference/INDEX.md) - Technical specifications

## Cross-References

### By Theme

**Privacy & Security**:
- ADR-004: Sanitize Before Storage
- ADR-001: Claude Hooks (includes consent)

**Development Workflow**:
- ADR-002: Subagent-Driven Development
- ADR-003: Claude Testing Harness

**Technical Infrastructure**:
- ADR-005: SQLite Database
- ADR-006: Async Processing Model

**User Experience**:
- ADR-001: Claude Hooks (< 100ms requirement)
- ADR-006: Async Processing (never block user)

## Quick Tips

- All ADRs follow the standard template
- Read ADR-001, ADR-004, ADR-002 for core principles
- Check "Alternatives Considered" to understand trade-offs
- Review "Implementation" sections for technical details
- "Related Documents" link to architecture and plans

================
File: guides/guide-claude-agent-sdk-integration-2025-01-16.md
================
# Claude Agent SDK Integration Guide

> Complete guide to integrating Claude Agent SDK for subagent orchestration

---
title: Claude Agent SDK Integration Guide
category: guide
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [guide, claude-agent-sdk, subagents, integration, orchestration]
---

## Overview

This guide shows you how to integrate the Claude Agent SDK into your TypeScript project to orchestrate specialized subagents. You'll learn the core concepts, installation, configuration, and advanced patterns for building multi-agent systems.

**Time to complete**: 60-90 minutes

## What You'll Learn

- Install and configure Claude Agent SDK
- Create your first subagent configuration
- Invoke subagents and handle streaming responses
- Integrate MCP servers for tools
- Handle errors and implement retry logic
- Run subagents in parallel and sequence

## Prerequisites

- **Phase 0 Setup Complete**: TypeScript project with Vitest
- **Node.js 18+**: `node --version`
- **Anthropic API Key**: Get from https://console.anthropic.com
- **Understanding of async/await**: Basic Promise knowledge

## Core Concepts

### What is the Claude Agent SDK?

The Claude Agent SDK enables you to:
- Define specialized "subagents" with focused prompts and tools
- Delegate tasks to these subagents programmatically
- Stream responses asynchronously
- Integrate external tools via Model Context Protocol (MCP)

### The `query()` API

The primary API for invoking agents:

```typescript
import { query } from '@anthropic-ai/claude-agent-sdk';

const response = query({
  prompt: "Your task description",
  options: {
    model: "claude-sonnet-4-5",
    agents: { /* subagent definitions */ },
    mcpServers: { /* MCP server connections */ }
  }
});
```

### Subagent Architecture

```
Main Orchestrator
    │
    ├─► Subagent A (specialized task)
    ├─► Subagent B (specialized task)
    └─► Subagent C (validation)
```

Each subagent has:
- **Description**: What it does
- **Prompt**: Specialized instructions
- **Tools**: Available capabilities (Read, Write, Bash, MCP tools)
- **Model**: Which Claude model to use

## Step 1: Install Claude Agent SDK

### 1.1 Install Package

**IMPORTANT NOTE**: As of January 2025, the Claude Agent SDK package name may be different from what's shown here. Check the official Anthropic documentation for the correct package name and installation instructions.

For this guide, we'll use the placeholder package name:

```bash
# Install Claude Agent SDK (VERIFY ACTUAL PACKAGE NAME)
npm install @anthropic-ai/claude-agent-sdk

# Install types if separate package
npm install -D @types/anthropic-ai__claude-agent-sdk
```

**Official Documentation**: https://docs.anthropic.com/en/docs/agents

### 1.2 Set Up Environment Variables

Add to `.env`:

```bash
# Anthropic API Key (REQUIRED)
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxxxxxxxxx

# Optional: Override default model
DEFAULT_MODEL=claude-sonnet-4-5

# Optional: Enable debug logging
AGENT_SDK_DEBUG=true
```

### 1.3 Load Environment Variables

Update `src/index.ts` (or create if missing):

```typescript
import { config } from 'dotenv';

// Load environment variables
config();

// Validate required environment variables
if (!process.env.ANTHROPIC_API_KEY) {
  throw new Error('ANTHROPIC_API_KEY is required. Set it in .env file.');
}

console.log('✓ Environment variables loaded');
```

### Verification Step 1

```bash
# Test environment loading
node -r ts-node/register src/index.ts
```

**Expected output**:
```
✓ Environment variables loaded
```

## Step 2: Create Your First Subagent

### 2.1 Create Agents Directory

```bash
mkdir -p src/agents
```

### 2.2 Define a Simple Subagent

Create `src/agents/hello-agent.ts`:

```typescript
import { AgentDefinition } from '@anthropic-ai/claude-agent-sdk';

/**
 * Simple "hello world" subagent that greets users
 */
export const helloAgent: AgentDefinition = {
  description: 'Greets users in a friendly manner',
  prompt: `You are a friendly greeter.
  When given a name, respond with a warm, personalized greeting.
  Be enthusiastic but professional.`,
  tools: [], // No tools needed for simple greeting
  model: 'claude-sonnet-4-5',
};

/**
 * All subagent definitions for easy import
 */
export const agents = {
  'hello-agent': helloAgent,
};
```

### 2.3 Create Orchestrator

Create `src/agents/orchestrator.ts`:

```typescript
import { query } from '@anthropic-ai/claude-agent-sdk';
import { agents } from './hello-agent';

/**
 * Invokes a subagent and returns the complete response
 */
export async function invokeSubagent(
  agentName: string,
  prompt: string
): Promise<string> {
  console.log(`Invoking subagent: ${agentName}`);
  console.log(`Prompt: ${prompt}`);

  const response = query({
    prompt,
    options: {
      model: 'claude-sonnet-4-5',
      agents,
      apiKey: process.env.ANTHROPIC_API_KEY,
    },
  });

  let fullResponse = '';
  let messageCount = 0;

  for await (const message of response) {
    messageCount++;

    // Log message type for debugging
    if (process.env.AGENT_SDK_DEBUG === 'true') {
      console.log('Message:', message.type, message.subtype || '');
    }

    // Handle different message types
    if (message.type === 'system' && message.subtype === 'subagent_start') {
      console.log(`  → Subagent started: ${message.agent_name}`);
    }

    if (message.type === 'system' && message.subtype === 'subagent_end') {
      console.log(`  ✓ Subagent completed: ${message.agent_name}`);
    }

    if (message.type === 'text') {
      fullResponse += message.text;
    }
  }

  console.log(`Received ${messageCount} messages`);
  return fullResponse;
}
```

### 2.4 Create Test Runner

Create `src/agents/run-hello.ts`:

```typescript
import { config } from 'dotenv';
import { invokeSubagent } from './orchestrator';

config();

async function main() {
  try {
    console.log('=== Hello Agent Test ===\n');

    const response = await invokeSubagent('hello-agent', 'My name is Alice');

    console.log('\n=== Response ===');
    console.log(response);
  } catch (error) {
    console.error('Error:', error);
    process.exit(1);
  }
}

main();
```

### Verification Step 2

```bash
# Run the hello agent
ts-node src/agents/run-hello.ts
```

**Expected output**:
```
=== Hello Agent Test ===

Invoking subagent: hello-agent
Prompt: My name is Alice
  → Subagent started: hello-agent
  ✓ Subagent completed: hello-agent
Received 5 messages

=== Response ===
Hello Alice! It's wonderful to meet you. I hope you're having a great day!
```

## Step 3: Advanced Subagent Patterns

### 3.1 Subagent with File Access

Create `src/agents/implementation-agents.ts`:

```typescript
import { AgentDefinition } from '@anthropic-ai/claude-agent-sdk';

/**
 * Implementation subagent that can write code
 */
export const codeWriterAgent: AgentDefinition = {
  description: 'Writes TypeScript code following best practices',
  prompt: `You are an expert TypeScript developer.
  When asked to implement a function:
  1. Write clean, type-safe code
  2. Add JSDoc comments
  3. Handle edge cases
  4. Follow functional programming principles when possible
  5. Use strict TypeScript types (no 'any')`,
  tools: ['Write', 'Read', 'Edit'], // File manipulation tools
  model: 'claude-sonnet-4-5',
};

/**
 * Test generator subagent
 */
export const testGeneratorAgent: AgentDefinition = {
  description: 'Generates comprehensive unit tests using Vitest',
  prompt: `You are a testing expert specializing in Vitest.
  When asked to generate tests:
  1. Use describe/it/expect structure
  2. Cover happy path, edge cases, and errors
  3. Use proper arrange-act-assert pattern
  4. Mock external dependencies
  5. Aim for >85% coverage
  Target: Comprehensive, maintainable tests.`,
  tools: ['Write', 'Read', 'Edit'],
  model: 'claude-sonnet-4-5',
};

export const implementationAgents = {
  'code-writer': codeWriterAgent,
  'test-generator': testGeneratorAgent,
};
```

### 3.2 Parallel Subagent Execution

Create `src/agents/parallel-orchestrator.ts`:

```typescript
import { query } from '@anthropic-ai/claude-agent-sdk';

/**
 * Runs multiple subagents in parallel
 */
export async function runParallelSubagents(
  tasks: Array<{ agentName: string; prompt: string }>,
  agents: Record<string, any>
): Promise<string[]> {
  console.log(`Running ${tasks.length} subagents in parallel`);

  const promises = tasks.map(async (task) => {
    const response = query({
      prompt: task.prompt,
      options: {
        model: 'claude-sonnet-4-5',
        agents,
        apiKey: process.env.ANTHROPIC_API_KEY,
      },
    });

    let fullResponse = '';
    for await (const message of response) {
      if (message.type === 'text') {
        fullResponse += message.text;
      }
    }
    return fullResponse;
  });

  return Promise.all(promises);
}
```

Example usage:

```typescript
const results = await runParallelSubagents(
  [
    { agentName: 'code-writer', prompt: 'Implement add(a, b) function' },
    { agentName: 'test-generator', prompt: 'Generate tests for add(a, b)' },
  ],
  implementationAgents
);

console.log('Implementation:', results[0]);
console.log('Tests:', results[1]);
```

### 3.3 Sequential with Dependencies

Create `src/agents/sequential-orchestrator.ts`:

```typescript
import { query } from '@anthropic-ai/claude-agent-sdk';

/**
 * Runs subagents sequentially, passing results between them
 */
export async function runSequentialSubagents(
  steps: Array<{
    agentName: string;
    promptTemplate: (previousResults: string[]) => string;
  }>,
  agents: Record<string, any>
): Promise<string[]> {
  const results: string[] = [];

  for (const step of steps) {
    const prompt = step.promptTemplate(results);

    const response = query({
      prompt,
      options: {
        model: 'claude-sonnet-4-5',
        agents,
        apiKey: process.env.ANTHROPIC_API_KEY,
      },
    });

    let fullResponse = '';
    for await (const message of response) {
      if (message.type === 'text') {
        fullResponse += message.text;
      }
    }

    results.push(fullResponse);
  }

  return results;
}
```

Example usage (TDD workflow):

```typescript
const tddResults = await runSequentialSubagents(
  [
    {
      agentName: 'test-generator',
      promptTemplate: () => 'Generate failing test for sanitizeApiKeys(text)',
    },
    {
      agentName: 'code-writer',
      promptTemplate: (results) =>
        `Implement minimal code to pass this test:\n\n${results[0]}`,
    },
    {
      agentName: 'code-quality-validator',
      promptTemplate: (results) =>
        `Review this implementation:\n\nTest: ${results[0]}\n\nCode: ${results[1]}`,
    },
  ],
  { ...implementationAgents, ...validationAgents }
);
```

## Step 4: Integrate MCP Tools

### 4.1 Understanding MCP Integration

MCP servers expose tools that subagents can use. For example, a test-runner MCP server might expose:
- `run_unit_tests`: Run Vitest unit tests
- `get_coverage_report`: Get coverage statistics
- `validate_test_quality`: Score test quality

### 4.2 MCP Server Configuration

Create `src/mcp/config.ts`:

```typescript
import { MCPServerConfig } from '@anthropic-ai/claude-agent-sdk';

/**
 * MCP server configurations
 */
export const mcpServers: Record<string, MCPServerConfig> = {
  'test-runner': {
    url: process.env.MCP_TEST_RUNNER_URL || 'http://localhost:3000',
    transport: 'http',
    auth: {
      type: 'none', // Or 'bearer' with token
    },
  },
};
```

### 4.3 Subagent with MCP Tools

Update `src/agents/implementation-agents.ts`:

```typescript
export const testValidatorAgent: AgentDefinition = {
  description: 'Validates test quality using MCP tools',
  prompt: `You are a test quality expert.
  Use the validate_test_quality tool to score tests.
  Require a score ≥ 0.8 to pass.
  Provide specific feedback on failing tests.`,
  tools: [
    'Read',
    'mcp__test-runner__validate_test_quality',
    'mcp__test-runner__get_coverage_report',
  ],
  model: 'claude-sonnet-4-5',
};
```

### 4.4 Invoking with MCP

```typescript
import { query } from '@anthropic-ai/claude-agent-sdk';
import { mcpServers } from '../mcp/config';

const response = query({
  prompt: 'Validate the tests in src/sanitization/sanitize.test.ts',
  options: {
    model: 'claude-sonnet-4-5',
    agents: {
      'test-validator': testValidatorAgent,
    },
    mcpServers, // Connect MCP servers
    apiKey: process.env.ANTHROPIC_API_KEY,
  },
});
```

**Expected MCP Tool Call**:
```json
{
  "type": "tool_use",
  "name": "mcp__test-runner__validate_test_quality",
  "input": {
    "testFilePath": "src/sanitization/sanitize.test.ts"
  }
}
```

**Expected MCP Response**:
```json
{
  "score": 0.92,
  "feedback": "Excellent coverage of edge cases. Clear test names.",
  "issues": []
}
```

## Step 5: Error Handling and Retry Logic

### 5.1 Error Types

Common errors when using the SDK:

- **Authentication Error**: Invalid API key
- **Rate Limit Error**: Too many requests (HTTP 429)
- **Network Error**: Connection timeout
- **Validation Error**: Invalid agent configuration

### 5.2 Retry with Exponential Backoff

Create `src/agents/retry.ts`:

```typescript
/**
 * Retries a function with exponential backoff
 */
export async function retryWithBackoff<T>(
  fn: () => Promise<T>,
  maxAttempts = 3,
  initialDelayMs = 1000
): Promise<T> {
  let lastError: Error | undefined;

  for (let attempt = 1; attempt <= maxAttempts; attempt++) {
    try {
      return await fn();
    } catch (error) {
      lastError = error as Error;

      // Don't retry on authentication errors
      if (error instanceof Error && error.message.includes('authentication')) {
        throw error;
      }

      if (attempt < maxAttempts) {
        const delayMs = initialDelayMs * Math.pow(2, attempt - 1);
        console.warn(`Attempt ${attempt} failed. Retrying in ${delayMs}ms...`);
        await sleep(delayMs);
      }
    }
  }

  throw new Error(`Failed after ${maxAttempts} attempts: ${lastError?.message}`);
}

function sleep(ms: number): Promise<void> {
  return new Promise((resolve) => setTimeout(resolve, ms));
}
```

### 5.3 Safe Subagent Invocation

```typescript
import { retryWithBackoff } from './retry';

export async function safeInvokeSubagent(
  agentName: string,
  prompt: string,
  agents: Record<string, any>
): Promise<string> {
  return retryWithBackoff(async () => {
    return invokeSubagent(agentName, prompt, agents);
  });
}
```

### 5.4 Token Budget Guard

Create `src/agents/budget.ts`:

```typescript
/**
 * Tracks token usage to prevent runaway costs
 */
export class TokenBudget {
  private usedTokens = 0;

  constructor(private maxTokens: number) {}

  /**
   * Check if we can spend more tokens
   */
  canSpend(estimatedTokens: number): boolean {
    return this.usedTokens + estimatedTokens <= this.maxTokens;
  }

  /**
   * Record token usage
   */
  recordUsage(tokens: number): void {
    this.usedTokens += tokens;
  }

  /**
   * Get remaining budget
   */
  remaining(): number {
    return this.maxTokens - this.usedTokens;
  }

  /**
   * Reset budget
   */
  reset(): void {
    this.usedTokens = 0;
  }
}

// Usage
const budget = new TokenBudget(100000); // 100k tokens max

if (!budget.canSpend(5000)) {
  throw new Error('Token budget exceeded');
}

// After subagent invocation
budget.recordUsage(response.usage.total_tokens);
```

## Step 6: Complete Example

### 6.1 TDD Workflow with Subagents

Create `src/agents/tdd-workflow.ts`:

```typescript
import { query } from '@anthropic-ai/claude-agent-sdk';
import { implementationAgents } from './implementation-agents';
import { retryWithBackoff } from './retry';

interface TDDResult {
  test: string;
  implementation: string;
  validationScore: number;
}

/**
 * Complete TDD cycle: Red → Green → Refactor
 */
export async function runTDDCycle(
  featureDescription: string
): Promise<TDDResult> {
  console.log('=== TDD Cycle ===');
  console.log('Feature:', featureDescription);

  // RED: Generate failing test
  console.log('\n🔴 RED: Generating test...');
  const test = await retryWithBackoff(async () => {
    const response = query({
      prompt: `Generate a failing test for: ${featureDescription}`,
      options: {
        model: 'claude-sonnet-4-5',
        agents: { 'test-generator': implementationAgents['test-generator'] },
        apiKey: process.env.ANTHROPIC_API_KEY,
      },
    });

    let result = '';
    for await (const message of response) {
      if (message.type === 'text') result += message.text;
    }
    return result;
  });

  console.log('✓ Test generated');

  // GREEN: Implement minimal code
  console.log('\n🟢 GREEN: Implementing code...');
  const implementation = await retryWithBackoff(async () => {
    const response = query({
      prompt: `Implement minimal code to pass this test:\n\n${test}`,
      options: {
        model: 'claude-sonnet-4-5',
        agents: { 'code-writer': implementationAgents['code-writer'] },
        apiKey: process.env.ANTHROPIC_API_KEY,
      },
    });

    let result = '';
    for await (const message of response) {
      if (message.type === 'text') result += message.text;
    }
    return result;
  });

  console.log('✓ Implementation complete');

  // Validate
  console.log('\n✅ Validating...');
  const validationScore = 0.9; // Would use MCP tool in real implementation

  return { test, implementation, validationScore };
}
```

### 6.2 Run Complete Example

Create `src/agents/run-tdd-example.ts`:

```typescript
import { config } from 'dotenv';
import { runTDDCycle } from './tdd-workflow';

config();

async function main() {
  try {
    const result = await runTDDCycle(
      'A function sanitizeApiKeys(text) that redacts API keys and tokens'
    );

    console.log('\n=== Results ===\n');
    console.log('TEST:\n', result.test);
    console.log('\nIMPLEMENTATION:\n', result.implementation);
    console.log('\nVALIDATION SCORE:', result.validationScore);
  } catch (error) {
    console.error('Error:', error);
    process.exit(1);
  }
}

main();
```

## Verification

### Run All Examples

```bash
# Hello agent
ts-node src/agents/run-hello.ts

# TDD workflow example
ts-node src/agents/run-tdd-example.ts
```

## You're Done When...

- ✅ Claude Agent SDK installed and configured
- ✅ Environment variables set (ANTHROPIC_API_KEY)
- ✅ Simple subagent working (hello-agent)
- ✅ Streaming responses handled correctly
- ✅ Error handling with retry implemented
- ✅ Understand parallel and sequential patterns
- ✅ Ready to integrate MCP tools

## Troubleshooting

### Issue: Authentication error

```
Error: Invalid API key
```

**Solution**:
- Verify `ANTHROPIC_API_KEY` in `.env`
- Check API key is valid at https://console.anthropic.com
- Ensure `.env` is loaded: `config()` called before using SDK

### Issue: Rate limit errors

```
Error: Rate limit exceeded (HTTP 429)
```

**Solution**:
- Implement retry with backoff (see Step 5.2)
- Add delays between requests
- Use token budget guard

### Issue: Streaming not working

```
TypeError: response is not iterable
```

**Solution**:
- Use `for await (const message of response)`
- Not `response.forEach()` or `map()`
- Ensure async/await pattern is correct

### Issue: MCP tools not found

```
Error: Tool mcp__test-runner__validate_test_quality not found
```

**Solution**:
- Verify MCP server is running
- Check `mcpServers` configuration
- Ensure tool names match exactly (case-sensitive)

## Best Practices

1. **Always use environment variables** for API keys
2. **Implement retry logic** for production code
3. **Monitor token usage** to control costs
4. **Log subagent invocations** for debugging
5. **Use specific prompts** for better subagent performance
6. **Clean up resources** after streaming completes
7. **Test error paths** (missing API key, network failures)

## Next Steps

Now that you understand the Claude Agent SDK, proceed to:

1. [Using Subagents Guide](./guide-using-subagents-2025-01-16.md) - Patterns for delegation
2. [Testing Harness Usage](./guide-testing-harness-usage-2025-01-16.md) - AI-powered testing
3. [TDD Workflow Guide](./guide-tdd-workflow-2025-01-16.md) - Test-driven development with subagents

## Related Documents

- [Subagent System Architecture](../architecture/architecture-subagent-system-2025-01-16.md)
- [Testing Harness Architecture](../architecture/architecture-testing-harness-2025-01-16.md)
- [Implementation Roadmap](../plans/plan-implementation-roadmap-2025-01-16.md)

================
File: guides/guide-phase-0-foundation-setup-2025-01-16.md
================
# Phase 0 Foundation Setup Guide

> Complete step-by-step guide to set up TypeScript, Vitest, and SQLite infrastructure

---
title: Phase 0 Foundation Setup Guide
category: guide
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [guide, phase-0, typescript, vitest, sqlite, setup]
---

## Overview

This guide walks you through setting up the foundation for the Global Context Network MVP. By the end, you'll have a production-ready TypeScript project with strict type checking, comprehensive testing infrastructure, and SQLite database with migrations.

**Time to complete**: 60-90 minutes

## What You'll Build

- TypeScript project with strict mode enabled
- Vitest testing infrastructure with coverage
- SQLite database with type-safe queries
- Migration system for schema evolution
- Linting and formatting toolchain
- Complete project structure

## Prerequisites

- **Node.js 18+**: Check with `node --version`
- **npm 8+**: Check with `npm --version`
- **Basic TypeScript knowledge**: Understanding of types, interfaces, async/await
- **Command line familiarity**: Comfortable with terminal/bash commands

### OS-Specific Requirements

**Windows Users**:
```bash
# Install build tools for better-sqlite3
npm install --global windows-build-tools
```

**macOS/Linux**:
```bash
# Ensure you have build-essential (usually pre-installed)
# macOS: Install Xcode Command Line Tools if prompted
```

## Step 1: Initialize TypeScript Project

### 1.1 Create Project Directory

```bash
# Create and enter project directory
mkdir global-context-network
cd global-context-network

# Initialize git
git init
```

### 1.2 Initialize npm Project

```bash
# Create package.json
npm init -y
```

### 1.3 Install Dependencies

```bash
# TypeScript and build tools
npm install -D typescript@5.3.3 ts-node@10.9.2 @types/node@20.10.6

# Testing infrastructure
npm install -D vitest@1.1.0 @vitest/ui@1.1.0 @vitest/coverage-v8@1.1.0

# Database
npm install better-sqlite3@9.2.2
npm install -D @types/better-sqlite3@7.6.8

# Code quality
npm install -D eslint@8.56.0 @typescript-eslint/eslint-plugin@6.17.0 @typescript-eslint/parser@6.17.0
npm install -D prettier@3.1.1

# Utility libraries
npm install dotenv@16.3.1
```

**Expected output**:
```
added 234 packages, and audited 235 packages in 12s
```

### 1.4 Create TypeScript Configuration

Create `tsconfig.json`:

```json
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "commonjs",
    "lib": ["ES2022"],
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "esModuleInterop": true,
    "allowSyntheticDefaultImports": true,
    "strict": true,
    "noImplicitAny": true,
    "strictNullChecks": true,
    "strictFunctionTypes": true,
    "strictPropertyInitialization": true,
    "noImplicitThis": true,
    "alwaysStrict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "outDir": "./dist",
    "rootDir": "./src",
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist", "**/*.test.ts"]
}
```

### 1.5 Create ESLint Configuration

Create `.eslintrc.cjs`:

```javascript
module.exports = {
  parser: '@typescript-eslint/parser',
  extends: [
    'eslint:recommended',
    'plugin:@typescript-eslint/recommended',
  ],
  parserOptions: {
    ecmaVersion: 2022,
    sourceType: 'module',
    project: './tsconfig.json',
  },
  rules: {
    '@typescript-eslint/no-explicit-any': 'error',
    '@typescript-eslint/explicit-function-return-type': 'warn',
    '@typescript-eslint/no-unused-vars': ['error', { argsIgnorePattern: '^_' }],
  },
};
```

### 1.6 Create Prettier Configuration

Create `.prettierrc`:

```json
{
  "semi": true,
  "trailingComma": "es5",
  "singleQuote": true,
  "printWidth": 100,
  "tabWidth": 2
}
```

### 1.7 Update package.json Scripts

Add to `package.json`:

```json
{
  "scripts": {
    "typecheck": "tsc --noEmit",
    "build": "tsc",
    "lint": "eslint src --ext .ts",
    "lint:fix": "eslint src --ext .ts --fix",
    "format": "prettier --write \"src/**/*.ts\"",
    "format:check": "prettier --check \"src/**/*.ts\"",
    "test": "vitest",
    "test:ui": "vitest --ui",
    "test:once": "vitest run",
    "coverage": "vitest run --coverage",
    "db:migrate": "ts-node src/db/migrate.ts",
    "db:reset": "rm -f data/context.db && npm run db:migrate"
  }
}
```

### Verification Step 1

```bash
# Type check should pass (no files yet, that's OK)
npm run typecheck

# Lint should pass
npm run lint
```

**Expected output**:
```
✓ No TypeScript errors
✓ ESLint: no problems
```

## Step 2: Set Up Testing Infrastructure

### 2.1 Create Vitest Configuration

Create `vitest.config.ts`:

```typescript
import { defineConfig } from 'vitest/config';
import path from 'path';

export default defineConfig({
  test: {
    globals: true,
    environment: 'node',
    coverage: {
      provider: 'v8',
      reporter: ['text', 'json', 'html', 'lcov'],
      reportsDirectory: './coverage',
      include: ['src/**/*.ts'],
      exclude: [
        'src/**/*.test.ts',
        'src/**/*.spec.ts',
        'src/types/**',
        'src/db/migrate.ts',
      ],
      all: true,
      lines: 85,
      functions: 85,
      branches: 80,
      statements: 85,
    },
    include: ['src/**/*.test.ts', 'src/**/*.spec.ts'],
    exclude: ['node_modules', 'dist'],
  },
  resolve: {
    alias: {
      '@': path.resolve(__dirname, './src'),
    },
  },
});
```

### 2.2 Create Test Utilities Directory

```bash
mkdir -p src/test-utils
```

Create `src/test-utils/db.ts`:

```typescript
import Database from 'better-sqlite3';
import { join } from 'path';
import { tmpdir } from 'os';
import { randomUUID } from 'crypto';

/**
 * Creates an in-memory SQLite database for testing
 */
export function createTestDatabase(): Database.Database {
  return new Database(':memory:', { verbose: console.log });
}

/**
 * Creates a temporary file-based database for testing
 */
export function createTempDatabase(): Database.Database {
  const dbPath = join(tmpdir(), `test-${randomUUID()}.db`);
  return new Database(dbPath);
}

/**
 * Runs migrations on a test database
 */
export function migrateTestDatabase(db: Database.Database): void {
  // Run schema creation
  db.exec(`
    CREATE TABLE IF NOT EXISTS conversations (
      id TEXT PRIMARY KEY,
      started_at INTEGER NOT NULL,
      ended_at INTEGER,
      message_count INTEGER DEFAULT 0,
      sanitized BOOLEAN DEFAULT 0,
      created_at INTEGER DEFAULT (unixepoch())
    );

    CREATE TABLE IF NOT EXISTS messages (
      id TEXT PRIMARY KEY,
      conversation_id TEXT NOT NULL,
      role TEXT NOT NULL,
      content TEXT NOT NULL,
      timestamp INTEGER NOT NULL,
      created_at INTEGER DEFAULT (unixepoch()),
      FOREIGN KEY (conversation_id) REFERENCES conversations(id)
    );

    CREATE INDEX idx_messages_conversation ON messages(conversation_id);
    CREATE INDEX idx_conversations_started ON conversations(started_at);
  `);
}

/**
 * Cleans up test database
 */
export function cleanupTestDatabase(db: Database.Database): void {
  try {
    db.close();
  } catch (error) {
    console.warn('Failed to close database:', error);
  }
}
```

### 2.3 Create Example Test

Create `src/test-utils/db.test.ts`:

```typescript
import { describe, it, expect, afterEach } from 'vitest';
import { createTestDatabase, migrateTestDatabase, cleanupTestDatabase } from './db';

describe('Test Database Utilities', () => {
  let db: ReturnType<typeof createTestDatabase>;

  afterEach(() => {
    if (db) {
      cleanupTestDatabase(db);
    }
  });

  it('should create an in-memory database', () => {
    db = createTestDatabase();
    expect(db).toBeDefined();
    expect(db.memory).toBe(true);
  });

  it('should run migrations successfully', () => {
    db = createTestDatabase();
    migrateTestDatabase(db);

    // Verify tables exist
    const tables = db
      .prepare("SELECT name FROM sqlite_master WHERE type='table' ORDER BY name")
      .all();

    const tableNames = tables.map((t: any) => t.name);
    expect(tableNames).toContain('conversations');
    expect(tableNames).toContain('messages');
  });

  it('should insert and retrieve a conversation', () => {
    db = createTestDatabase();
    migrateTestDatabase(db);

    const conversationId = 'test-123';
    const startedAt = Date.now();

    db.prepare(
      `INSERT INTO conversations (id, started_at) VALUES (?, ?)`
    ).run(conversationId, startedAt);

    const result = db.prepare('SELECT * FROM conversations WHERE id = ?').get(conversationId);

    expect(result).toBeDefined();
    expect((result as any).id).toBe(conversationId);
    expect((result as any).started_at).toBe(startedAt);
  });
});
```

### Verification Step 2

```bash
# Run tests
npm run test:once
```

**Expected output**:
```
✓ src/test-utils/db.test.ts (3)
  ✓ Test Database Utilities (3)
    ✓ should create an in-memory database
    ✓ should run migrations successfully
    ✓ should insert and retrieve a conversation

Test Files  1 passed (1)
     Tests  3 passed (3)
```

## Step 3: Set Up Database Infrastructure

### 3.1 Create Database Directory

```bash
mkdir -p src/db
mkdir -p data
```

### 3.2 Create Database Schema

Create `src/db/schema.sql`:

```sql
-- Conversations table (sanitized)
CREATE TABLE IF NOT EXISTS conversations (
  id TEXT PRIMARY KEY,
  started_at INTEGER NOT NULL,
  ended_at INTEGER,
  message_count INTEGER DEFAULT 0,
  sanitized BOOLEAN DEFAULT 0,
  created_at INTEGER DEFAULT (unixepoch())
);

-- Messages table (sanitized)
CREATE TABLE IF NOT EXISTS messages (
  id TEXT PRIMARY KEY,
  conversation_id TEXT NOT NULL,
  role TEXT NOT NULL CHECK(role IN ('user', 'assistant')),
  content TEXT NOT NULL,
  timestamp INTEGER NOT NULL,
  created_at INTEGER DEFAULT (unixepoch()),
  FOREIGN KEY (conversation_id) REFERENCES conversations(id) ON DELETE CASCADE
);

-- Learnings table
CREATE TABLE IF NOT EXISTS learnings (
  id TEXT PRIMARY KEY,
  conversation_id TEXT NOT NULL,
  category TEXT NOT NULL,
  title TEXT NOT NULL,
  content TEXT NOT NULL,
  tags TEXT, -- JSON array
  confidence REAL NOT NULL CHECK(confidence >= 0 AND confidence <= 1),
  created_at INTEGER DEFAULT (unixepoch()),
  FOREIGN KEY (conversation_id) REFERENCES conversations(id) ON DELETE CASCADE
);

-- Job queue table
CREATE TABLE IF NOT EXISTS job_queue (
  id TEXT PRIMARY KEY,
  type TEXT NOT NULL,
  payload TEXT NOT NULL, -- JSON
  status TEXT NOT NULL CHECK(status IN ('pending', 'processing', 'completed', 'failed')),
  attempts INTEGER DEFAULT 0,
  max_attempts INTEGER DEFAULT 3,
  error TEXT,
  created_at INTEGER DEFAULT (unixepoch()),
  updated_at INTEGER DEFAULT (unixepoch())
);

-- Sanitization log (audit trail)
CREATE TABLE IF NOT EXISTS sanitization_log (
  id TEXT PRIMARY KEY,
  conversation_id TEXT NOT NULL,
  pii_type TEXT NOT NULL,
  redaction_count INTEGER NOT NULL,
  timestamp INTEGER NOT NULL,
  FOREIGN KEY (conversation_id) REFERENCES conversations(id) ON DELETE CASCADE
);

-- Indexes for performance
CREATE INDEX IF NOT EXISTS idx_messages_conversation ON messages(conversation_id);
CREATE INDEX IF NOT EXISTS idx_messages_timestamp ON messages(timestamp);
CREATE INDEX IF NOT EXISTS idx_conversations_started ON conversations(started_at);
CREATE INDEX IF NOT EXISTS idx_learnings_conversation ON learnings(conversation_id);
CREATE INDEX IF NOT EXISTS idx_learnings_category ON learnings(category);
CREATE INDEX IF NOT EXISTS idx_learnings_confidence ON learnings(confidence);
CREATE INDEX IF NOT EXISTS idx_job_queue_status ON job_queue(status);
CREATE INDEX IF NOT EXISTS idx_job_queue_created ON job_queue(created_at);
```

### 3.3 Create Migration Runner

Create `src/db/migrate.ts`:

```typescript
import Database from 'better-sqlite3';
import { readFileSync } from 'fs';
import { join } from 'path';

const DB_PATH = process.env.DB_PATH || join(__dirname, '../../data/context.db');

export function runMigrations(): Database.Database {
  console.log(`Running migrations on database: ${DB_PATH}`);

  const db = new Database(DB_PATH);
  db.pragma('journal_mode = WAL');
  db.pragma('foreign_keys = ON');

  // Read and execute schema
  const schemaPath = join(__dirname, 'schema.sql');
  const schema = readFileSync(schemaPath, 'utf-8');

  db.exec(schema);

  console.log('✓ Migrations complete');
  return db;
}

// Run if executed directly
if (require.main === module) {
  runMigrations();
}
```

### 3.4 Create Database Connection Module

Create `src/db/index.ts`:

```typescript
import Database from 'better-sqlite3';
import { join } from 'path';

const DB_PATH = process.env.DB_PATH || join(__dirname, '../../data/context.db');

let dbInstance: Database.Database | null = null;

/**
 * Get singleton database connection
 */
export function getDatabase(): Database.Database {
  if (!dbInstance) {
    try {
      dbInstance = new Database(DB_PATH);
      dbInstance.pragma('journal_mode = WAL');
      dbInstance.pragma('foreign_keys = ON');
      console.log(`✓ Database connected: ${DB_PATH}`);
    } catch (error) {
      console.error('Failed to connect to database:', error);
      throw error;
    }
  }
  return dbInstance;
}

/**
 * Close database connection
 */
export function closeDatabase(): void {
  if (dbInstance) {
    try {
      dbInstance.close();
      dbInstance = null;
      console.log('✓ Database connection closed');
    } catch (error) {
      console.warn('Failed to close database:', error);
    }
  }
}

/**
 * Execute database query with error handling
 */
export function executeQuery<T>(
  queryFn: (db: Database.Database) => T
): T {
  const db = getDatabase();
  try {
    return queryFn(db);
  } catch (error) {
    console.error('Database query failed:', error);
    throw error;
  }
}
```

### 3.5 Create Database Test

Create `src/db/index.test.ts`:

```typescript
import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import { getDatabase, closeDatabase, executeQuery } from './index';
import { join } from 'path';
import { tmpdir } from 'os';
import { randomUUID } from 'crypto';

// Use temp database for tests
process.env.DB_PATH = join(tmpdir(), `test-${randomUUID()}.db`);

describe('Database Connection', () => {
  beforeAll(async () => {
    // Run migrations
    const { runMigrations } = await import('./migrate');
    runMigrations();
  });

  afterAll(() => {
    closeDatabase();
  });

  it('should connect to database', () => {
    const db = getDatabase();
    expect(db).toBeDefined();
  });

  it('should execute queries successfully', () => {
    const result = executeQuery((db) => {
      return db.prepare('SELECT 1 as result').get();
    });

    expect(result).toEqual({ result: 1 });
  });

  it('should insert and retrieve data', () => {
    const conversationId = 'test-' + randomUUID();

    executeQuery((db) => {
      db.prepare(
        'INSERT INTO conversations (id, started_at) VALUES (?, ?)'
      ).run(conversationId, Date.now());
    });

    const conversation = executeQuery((db) => {
      return db.prepare('SELECT * FROM conversations WHERE id = ?').get(conversationId);
    });

    expect(conversation).toBeDefined();
    expect((conversation as any).id).toBe(conversationId);
  });
});
```

### Verification Step 3

```bash
# Run migrations
npm run db:migrate

# Run database tests
npm run test:once -- src/db/index.test.ts
```

**Expected output**:
```
Running migrations on database: /path/to/data/context.db
✓ Migrations complete

✓ src/db/index.test.ts (3)
  ✓ Database Connection (3)
```

## Step 4: Create Environment Configuration

### 4.1 Create .env File

Create `.env`:

```bash
# Database
DB_PATH=./data/context.db

# Logging
LOG_LEVEL=info

# Anthropic API (for future use)
ANTHROPIC_API_KEY=your-api-key-here

# MCP Test Runner (for future use)
MCP_TEST_RUNNER_URL=http://localhost:3000
```

### 4.2 Create .env.example

Create `.env.example`:

```bash
# Database
DB_PATH=./data/context.db

# Logging
LOG_LEVEL=info

# Anthropic API
ANTHROPIC_API_KEY=sk-ant-xxxxx

# MCP Test Runner
MCP_TEST_RUNNER_URL=http://localhost:3000
```

### 4.3 Create .gitignore

Create `.gitignore`:

```
# Dependencies
node_modules/

# Build output
dist/
*.tsbuildinfo

# Environment
.env
.env.local

# Database
data/
*.db
*.db-shm
*.db-wal

# Testing
coverage/
.vitest/

# Logs
logs/
*.log

# OS
.DS_Store
Thumbs.db

# IDE
.vscode/
.idea/
*.swp
*.swo

# Repomix
*repomix*.txt
```

## Step 5: Create Project Structure

### 5.1 Create Directory Structure

```bash
mkdir -p src/{hooks,sanitization,queue,learning,mcp,types}
```

### 5.2 Create Types Directory

Create `src/types/index.ts`:

```typescript
/**
 * Core domain types
 */

export interface Conversation {
  id: string;
  started_at: number;
  ended_at?: number;
  message_count: number;
  sanitized: boolean;
  created_at: number;
}

export interface Message {
  id: string;
  conversation_id: string;
  role: 'user' | 'assistant';
  content: string;
  timestamp: number;
  created_at: number;
}

export interface Learning {
  id: string;
  conversation_id: string;
  category: LearningCategory;
  title: string;
  content: string;
  tags: string[];
  confidence: number;
  created_at: number;
}

export type LearningCategory =
  | 'pattern'
  | 'best_practice'
  | 'anti_pattern'
  | 'bug_fix'
  | 'optimization'
  | 'tool_usage'
  | 'workflow'
  | 'decision';

export interface Job {
  id: string;
  type: JobType;
  payload: unknown;
  status: JobStatus;
  attempts: number;
  max_attempts: number;
  error?: string;
  created_at: number;
  updated_at: number;
}

export type JobType = 'sanitize_conversation' | 'extract_learning' | 'mine_upload';

export type JobStatus = 'pending' | 'processing' | 'completed' | 'failed';

export interface SanitizationLog {
  id: string;
  conversation_id: string;
  pii_type: PIIType;
  redaction_count: number;
  timestamp: number;
}

export type PIIType =
  | 'api_key'
  | 'file_path'
  | 'email'
  | 'ip_address'
  | 'name'
  | 'phone'
  | 'url_token';
```

### 5.3 Verify Project Structure

```bash
tree -L 2 src/
```

**Expected output**:
```
src/
├── db
│   ├── index.test.ts
│   ├── index.ts
│   ├── migrate.ts
│   └── schema.sql
├── hooks
├── learning
├── mcp
├── queue
├── sanitization
├── test-utils
│   ├── db.test.ts
│   └── db.ts
└── types
    └── index.ts
```

## Final Verification

### Run All Checks

```bash
# Type check
npm run typecheck

# Lint
npm run lint

# Format check
npm run format:check

# Run all tests
npm run test:once

# Generate coverage
npm run coverage

# Build
npm run build
```

**Expected output**:
```
✓ TypeScript: No errors
✓ ESLint: No problems
✓ Prettier: All files formatted
✓ Tests: 6 passed
✓ Coverage: 100% (minimal code so far)
✓ Build: Successful
```

### Verify Database

```bash
# Check database was created
ls -lh data/context.db

# Inspect schema
sqlite3 data/context.db ".schema"
```

**Expected output**:
```
-rw-r--r-- 1 user staff 28K Jan 16 10:00 data/context.db

CREATE TABLE conversations (...);
CREATE TABLE messages (...);
CREATE TABLE learnings (...);
...
```

## You're Done When...

- ✅ All npm scripts run successfully
- ✅ Type checking passes with strict mode
- ✅ All tests pass (6/6)
- ✅ Coverage report generates
- ✅ Database migrations run without errors
- ✅ Project builds to `dist/` directory
- ✅ `.env` file configured
- ✅ Directory structure matches specification

## Troubleshooting

### Issue: better-sqlite3 build fails

**Windows**:
```bash
npm install --global windows-build-tools
npm rebuild better-sqlite3
```

**macOS**:
```bash
xcode-select --install
npm rebuild better-sqlite3
```

**Linux**:
```bash
sudo apt-get install build-essential
npm rebuild better-sqlite3
```

### Issue: TypeScript errors on strict mode

Check `tsconfig.json` has:
```json
{
  "compilerOptions": {
    "strict": true,
    "noImplicitAny": true
  }
}
```

Add explicit types to all functions and variables.

### Issue: Vitest not finding tests

Ensure test files end with `.test.ts` or `.spec.ts` and are in `src/` directory.

### Issue: Database locked

Close any open connections:
```bash
npm run db:reset
```

If still locked, find and kill SQLite processes:
```bash
# macOS/Linux
lsof | grep context.db
kill -9 <PID>
```

## Next Steps

Now that your foundation is set up, you can proceed to:

1. [Claude Agent SDK Integration](./guide-claude-agent-sdk-integration-2025-01-16.md) - Set up the Agent SDK for subagent orchestration
2. [Using Subagents](./guide-using-subagents-2025-01-16.md) - Learn to delegate to specialized agents
3. [Phase 1 Hook Development](./guide-phase-1-hook-development-2025-01-16.md) - Implement event capture hooks

## Related Documents

- [Global Context Network Architecture](../architecture/architecture-global-context-network-2025-01-16.md)
- [Database Schema Reference](../reference/reference-database-schema-2025-01-16.md)
- [Testing Strategy](../reference/reference-testing-strategy-2025-01-16.md)
- [Implementation Roadmap](../plans/plan-implementation-roadmap-2025-01-16.md)

================
File: guides/guide-phase-1-hook-development-2025-01-16.md
================
# Phase 1 Hook Development Guide

> Implement Claude Code hooks for event capture with <100ms performance

---
title: Phase 1 Hook Development Guide
category: guide
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [guide, phase-1, hooks, claude-code, event-capture]
---

## Overview

This guide walks you through implementing Claude Code hooks to capture conversation events. You'll learn how to create fast, non-blocking hooks that sanitize and queue events without impacting user experience.

**Time to complete**: 120-150 minutes

## What You'll Build

- UserPromptSubmit hook (captures user input)
- Stop hook (captures agent responses)
- Event queue system (persistent, async)
- Sanitization at hook boundary
- Complete event capture pipeline

## Prerequisites

- **Phase 0 Setup Complete**: [guide-phase-0-foundation-setup-2025-01-16.md](./guide-phase-0-foundation-setup-2025-01-16.md)
- **TDD Workflow Understood**: [guide-tdd-workflow-2025-01-16.md](./guide-tdd-workflow-2025-01-16.md)
- **Subagents Guide Complete**: [guide-using-subagents-2025-01-16.md](./guide-using-subagents-2025-01-16.md)
- **Understanding of Claude Code hooks**: Basic knowledge of lifecycle

## Understanding Claude Code Hooks

### What Are Hooks?

Hooks are scripts that Claude Code invokes at specific lifecycle events:

| Hook | When It Fires | Purpose |
|------|---------------|---------|
| `UserPromptSubmit` | User sends message | Capture user input |
| `Stop` | Agent finishes response | Capture agent output |

### Hook Requirements

**Critical Performance Constraint**: < 100ms execution time

Why? Hooks run synchronously in the user's workflow. Slow hooks = bad UX.

**Strategy**:
- ✅ Fast, rule-based sanitization (< 10ms)
- ✅ Fire-and-forget queue write (< 50ms)
- ✅ Async processing for expensive operations
- ❌ Never do: API calls, heavy computation, blocking I/O

### Hook Lifecycle

```
User Types → UserPromptSubmit Hook → Queue Event → Return (< 100ms)
                                           ↓
                                    Async Processing
                                    (sanitization, extraction)

Agent Responds → Stop Hook → Complete Event → Return (< 100ms)
                                    ↓
                              Queue for Processing
```

## Step 1: Create Hook Directory Structure

### 1.1 Set Up Directories

```bash
mkdir -p .claude/hooks
```

### 1.2 Create hooks.json Configuration

Create `.claude/hooks/hooks.json`:

```json
{
  "hooks": [
    {
      "name": "UserPromptSubmit",
      "script": ".claude/hooks/user-prompt-submit.ts",
      "enabled": true
    },
    {
      "name": "Stop",
      "script": ".claude/hooks/stop.ts",
      "enabled": true
    }
  ]
}
```

## Step 2: Implement Fast Sanitization

### 2.1 Create Sanitization Module

**CRITICAL**: Sanitize BEFORE any storage, including queue.

Create `src/sanitization/fast-sanitize.ts`:

```typescript
/**
 * Fast, rule-based sanitization for hook-level redaction
 * Performance target: < 10ms per message
 */

export interface SanitizationResult {
  sanitized: string;
  redactions: Array<{ type: string; count: number }>;
  durationMs: number;
}

// Regex patterns for common PII
const PII_PATTERNS = {
  API_KEY: /\b(sk-[a-zA-Z0-9]{48}|api[_-]?key[_:\s]*[a-zA-Z0-9]{20,})/gi,
  EMAIL: /\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/g,
  IP_V4: /\b(?:\d{1,3}\.){3}\d{1,3}\b/g,
  ABSOLUTE_PATH: /(?:\/Users\/[^\/\s]+|C:\\Users\\[^\\\s]+)(?:[\/\\][^\s]+)*/g,
  URL_TOKEN: /\b(https?:\/\/[^\s]+[?&](token|key|secret|auth)=[^\s&]+)/gi,
};

export function fastSanitize(text: string): SanitizationResult {
  const startTime = Date.now();
  let sanitized = text;
  const redactions: Array<{ type: string; count: number }> = [];

  // API Keys
  const apiKeyCount = (text.match(PII_PATTERNS.API_KEY) || []).length;
  if (apiKeyCount > 0) {
    sanitized = sanitized.replace(PII_PATTERNS.API_KEY, '[REDACTED_API_KEY]');
    redactions.push({ type: 'api_key', count: apiKeyCount });
  }

  // Emails
  const emailCount = (text.match(PII_PATTERNS.EMAIL) || []).length;
  if (emailCount > 0) {
    sanitized = sanitized.replace(PII_PATTERNS.EMAIL, '[REDACTED_EMAIL]');
    redactions.push({ type: 'email', count: emailCount });
  }

  // IP Addresses
  const ipCount = (text.match(PII_PATTERNS.IP_V4) || []).length;
  if (ipCount > 0) {
    sanitized = sanitized.replace(PII_PATTERNS.IP_V4, '[REDACTED_IP]');
    redactions.push({ type: 'ip_address', count: ipCount });
  }

  // Absolute Paths (with usernames)
  const pathCount = (text.match(PII_PATTERNS.ABSOLUTE_PATH) || []).length;
  if (pathCount > 0) {
    sanitized = sanitized.replace(PII_PATTERNS.ABSOLUTE_PATH, '[REDACTED_PATH]');
    redactions.push({ type: 'file_path', count: pathCount });
  }

  // URL Tokens
  const urlTokenCount = (text.match(PII_PATTERNS.URL_TOKEN) || []).length;
  if (urlTokenCount > 0) {
    sanitized = sanitized.replace(PII_PATTERNS.URL_TOKEN, '[REDACTED_URL]');
    redactions.push({ type: 'url_token', count: urlTokenCount });
  }

  const durationMs = Date.now() - startTime;

  return { sanitized, redactions, durationMs };
}
```

### 2.2 Test Fast Sanitization

Create `src/sanitization/fast-sanitize.test.ts`:

```typescript
import { describe, it, expect } from 'vitest';
import { fastSanitize } from './fast-sanitize';

describe('fastSanitize', () => {
  it('should redact OpenAI API keys', () => {
    const input = 'My key is sk-abc123def456ghi789jkl012mno345pqr678stu901';
    const result = fastSanitize(input);
    expect(result.sanitized).toBe('My key is [REDACTED_API_KEY]');
    expect(result.redactions).toContainEqual({ type: 'api_key', count: 1 });
  });

  it('should redact email addresses', () => {
    const input = 'Contact me at user@example.com';
    const result = fastSanitize(input);
    expect(result.sanitized).toBe('Contact me at [REDACTED_EMAIL]');
  });

  it('should redact absolute file paths', () => {
    const input = 'File at /Users/john/Documents/secret.txt';
    const result = fastSanitize(input);
    expect(result.sanitized).toBe('File at [REDACTED_PATH]');
  });

  it('should execute in < 10ms', () => {
    const input = 'No PII here just normal text';
    const result = fastSanitize(input);
    expect(result.durationMs).toBeLessThan(10);
  });

  it('should handle empty strings', () => {
    const result = fastSanitize('');
    expect(result.sanitized).toBe('');
    expect(result.redactions).toHaveLength(0);
  });
});
```

Run tests:

```bash
npm run test:once -- sanitize
```

## Step 3: Implement Event Queue

### 3.1 Create Queue Module

Create `src/queue/event-queue.ts`:

```typescript
import Database from 'better-sqlite3';
import { randomUUID } from 'crypto';

export interface QueuedEvent {
  id: string;
  conversation_id: string;
  role: 'user' | 'assistant';
  content: string; // Already sanitized
  timestamp: number;
  status: 'pending' | 'processing' | 'completed' | 'failed';
  created_at: number;
}

export class EventQueue {
  private db: Database.Database;

  constructor(dbPath: string) {
    this.db = new Database(dbPath);
    this.db.pragma('journal_mode = WAL');
    this.initQueue();
  }

  private initQueue(): void {
    this.db.exec(`
      CREATE TABLE IF NOT EXISTS event_queue (
        id TEXT PRIMARY KEY,
        conversation_id TEXT NOT NULL,
        role TEXT NOT NULL CHECK(role IN ('user', 'assistant')),
        content TEXT NOT NULL,
        timestamp INTEGER NOT NULL,
        status TEXT NOT NULL DEFAULT 'pending',
        created_at INTEGER DEFAULT (unixepoch())
      );

      CREATE INDEX IF NOT EXISTS idx_queue_status ON event_queue(status);
      CREATE INDEX IF NOT EXISTS idx_queue_conversation ON event_queue(conversation_id);
    `);
  }

  /**
   * Enqueue event (must be fast - < 50ms)
   */
  enqueue(event: Omit<QueuedEvent, 'id' | 'status' | 'created_at'>): string {
    const id = randomUUID();

    this.db
      .prepare(
        `INSERT INTO event_queue (id, conversation_id, role, content, timestamp, status)
         VALUES (?, ?, ?, ?, ?, 'pending')`
      )
      .run(id, event.conversation_id, event.role, event.content, event.timestamp);

    return id;
  }

  /**
   * Get pending events for processing
   */
  getPending(limit = 100): QueuedEvent[] {
    return this.db
      .prepare(
        `SELECT * FROM event_queue WHERE status = 'pending' ORDER BY created_at LIMIT ?`
      )
      .all(limit) as QueuedEvent[];
  }

  /**
   * Update event status
   */
  updateStatus(id: string, status: QueuedEvent['status']): void {
    this.db.prepare(`UPDATE event_queue SET status = ? WHERE id = ?`).run(status, id);
  }

  close(): void {
    this.db.close();
  }
}
```

### 3.2 Test Event Queue

Create `src/queue/event-queue.test.ts`:

```typescript
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { EventQueue } from './event-queue';
import { join } from 'path';
import { tmpdir } from 'os';
import { randomUUID } from 'crypto';
import { unlinkSync, existsSync } from 'fs';

describe('EventQueue', () => {
  let queue: EventQueue;
  let dbPath: string;

  beforeEach(() => {
    dbPath = join(tmpdir(), `test-queue-${randomUUID()}.db`);
    queue = new EventQueue(dbPath);
  });

  afterEach(() => {
    queue.close();
    if (existsSync(dbPath)) unlinkSync(dbPath);
  });

  it('should enqueue events quickly', () => {
    const start = Date.now();

    const eventId = queue.enqueue({
      conversation_id: 'conv-123',
      role: 'user',
      content: 'Test message',
      timestamp: Date.now(),
    });

    const duration = Date.now() - start;

    expect(eventId).toBeTruthy();
    expect(duration).toBeLessThan(50); // < 50ms requirement
  });

  it('should retrieve pending events', () => {
    queue.enqueue({
      conversation_id: 'conv-123',
      role: 'user',
      content: 'Message 1',
      timestamp: Date.now(),
    });

    const pending = queue.getPending();
    expect(pending).toHaveLength(1);
    expect(pending[0].status).toBe('pending');
  });

  it('should update event status', () => {
    const id = queue.enqueue({
      conversation_id: 'conv-123',
      role: 'user',
      content: 'Test',
      timestamp: Date.now(),
    });

    queue.updateStatus(id, 'completed');

    const pending = queue.getPending();
    expect(pending).toHaveLength(0); // No longer pending
  });
});
```

## Step 4: Implement UserPromptSubmit Hook

### 4.1 Create Hook Script

Create `.claude/hooks/user-prompt-submit.ts`:

```typescript
#!/usr/bin/env ts-node

import { fastSanitize } from '../../src/sanitization/fast-sanitize';
import { EventQueue } from '../../src/queue/event-queue';
import { randomUUID } from 'crypto';
import { join } from 'path';
import { appendFileSync } from 'fs';

const DB_PATH = process.env.DB_PATH || join(__dirname, '../../data/context.db');
const LOG_PATH = join(__dirname, '../../logs/hooks.log');

/**
 * UserPromptSubmit Hook
 * Captures user input, sanitizes it, and queues for processing
 * CRITICAL: Must execute in < 100ms
 */

interface HookInput {
  prompt: string;
  conversation_id?: string;
}

function log(message: string): void {
  const timestamp = new Date().toISOString();
  try {
    appendFileSync(LOG_PATH, `[${timestamp}] UserPromptSubmit: ${message}\n`);
  } catch {
    // Fail silently - never break user flow
  }
}

function main(): void {
  const startTime = Date.now();

  try {
    // Parse input from stdin
    const input = process.argv[2] || '{}';
    const data: HookInput = JSON.parse(input);

    const prompt = data.prompt || '';
    const conversationId = data.conversation_id || randomUUID();

    // SANITIZE BEFORE STORAGE (privacy guarantee)
    const sanitizationResult = fastSanitize(prompt);

    // Queue sanitized event (fast, non-blocking)
    const queue = new EventQueue(DB_PATH);
    queue.enqueue({
      conversation_id: conversationId,
      role: 'user',
      content: sanitizationResult.sanitized,
      timestamp: Date.now(),
    });
    queue.close();

    const duration = Date.now() - startTime;

    log(
      `Captured user prompt. Redactions: ${sanitizationResult.redactions.length}. Duration: ${duration}ms`
    );

    // CRITICAL: Verify < 100ms
    if (duration > 100) {
      log(`⚠ WARNING: Hook took ${duration}ms (> 100ms threshold)`);
    }
  } catch (error) {
    // FAIL SILENTLY - never throw to caller
    const errorMsg = error instanceof Error ? error.message : String(error);
    log(`Error: ${errorMsg}`);
  }
}

main();
```

Make executable:

```bash
chmod +x .claude/hooks/user-prompt-submit.ts
```

## Step 5: Implement Stop Hook

### 5.1 Create Stop Hook Script

Create `.claude/hooks/stop.ts`:

```typescript
#!/usr/bin/env ts-node

import { fastSanitize } from '../../src/sanitization/fast-sanitize';
import { EventQueue } from '../../src/queue/event-queue';
import { join } from 'path';
import { appendFileSync } from 'fs';

const DB_PATH = process.env.DB_PATH || join(__dirname, '../../data/context.db');
const LOG_PATH = join(__dirname, '../../logs/hooks.log');

interface HookInput {
  response: string;
  conversation_id: string;
}

function log(message: string): void {
  const timestamp = new Date().toISOString();
  try {
    appendFileSync(LOG_PATH, `[${timestamp}] Stop: ${message}\n`);
  } catch {
    // Fail silently
  }
}

function main(): void {
  const startTime = Date.now();

  try {
    const input = process.argv[2] || '{}';
    const data: HookInput = JSON.parse(input);

    const response = data.response || '';
    const conversationId = data.conversation_id;

    // Sanitize response
    const sanitizationResult = fastSanitize(response);

    // Queue sanitized event
    const queue = new EventQueue(DB_PATH);
    queue.enqueue({
      conversation_id: conversationId,
      role: 'assistant',
      content: sanitizationResult.sanitized,
      timestamp: Date.now(),
    });
    queue.close();

    const duration = Date.now() - startTime;

    log(
      `Captured assistant response. Redactions: ${sanitizationResult.redactions.length}. Duration: ${duration}ms`
    );

    if (duration > 100) {
      log(`⚠ WARNING: Hook took ${duration}ms (> 100ms threshold)`);
    }
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error);
    log(`Error: ${errorMsg}`);
  }
}

main();
```

Make executable:

```bash
chmod +x .claude/hooks/stop.ts
```

## Step 6: Manual Testing

### 6.1 Create Test Script

Create `test-hooks.ts`:

```typescript
import { exec } from 'child_process';
import { promisify } from 'util';

const execAsync = promisify(exec);

async function testHooks() {
  console.log('Testing UserPromptSubmit hook...\n');

  const userPromptPayload = JSON.stringify({
    prompt: 'My API key is sk-abc123def456ghi789jkl012mno345pqr678stu901',
    conversation_id: 'test-conv-123',
  });

  const { stdout: userOutput } = await execAsync(
    `./.claude/hooks/user-prompt-submit.ts '${userPromptPayload}'`
  );

  console.log('UserPromptSubmit output:', userOutput || '(no output - good!)');

  console.log('\nTesting Stop hook...\n');

  const stopPayload = JSON.stringify({
    response: 'Sure! Contact me at admin@example.com for more info.',
    conversation_id: 'test-conv-123',
  });

  const { stdout: stopOutput } = await execAsync(
    `./.claude/hooks/stop.ts '${stopPayload}'`
  );

  console.log('Stop output:', stopOutput || '(no output - good!)');

  console.log('\nChecking queued events...\n');

  const { EventQueue } = await import('./src/queue/event-queue');
  const queue = new EventQueue('./data/context.db');

  const pending = queue.getPending();
  console.log(`Pending events: ${pending.length}`);

  pending.forEach((event) => {
    console.log(`  - ${event.role}: ${event.content.substring(0, 50)}...`);
  });

  queue.close();

  console.log('\n✓ Hook test complete');
}

testHooks().catch(console.error);
```

Run test:

```bash
ts-node test-hooks.ts
```

**Expected output**:
```
Testing UserPromptSubmit hook...
UserPromptSubmit output: (no output - good!)

Testing Stop hook...
Stop output: (no output - good!)

Checking queued events...
Pending events: 2
  - user: My API key is [REDACTED_API_KEY]
  - assistant: Sure! Contact me at [REDACTED_EMAIL] for more...

✓ Hook test complete
```

### 6.2 Check Logs

```bash
tail logs/hooks.log
```

**Expected output**:
```
[2025-01-16T10:30:00.000Z] UserPromptSubmit: Captured user prompt. Redactions: 1. Duration: 23ms
[2025-01-16T10:30:00.100Z] Stop: Captured assistant response. Redactions: 1. Duration: 19ms
```

## Verification

### Performance Check

All hook executions should be < 100ms:

```bash
grep "Duration:" logs/hooks.log | awk -F'Duration: ' '{print $2}' | sort -n
```

All values should be < 100ms.

### Privacy Check

No raw PII should be in database:

```bash
sqlite3 data/context.db "SELECT content FROM event_queue LIMIT 10"
```

Should see `[REDACTED_*]` placeholders, not actual PII.

## You're Done When...

- ✅ UserPromptSubmit hook captures user input
- ✅ Stop hook captures agent responses
- ✅ All PII sanitized before storage
- ✅ Hook execution < 100ms
- ✅ Events queued in database
- ✅ Logs show successful captures
- ✅ Manual test passes

## Troubleshooting

### Hook not firing

Check hooks.json is valid and scripts are executable:

```bash
cat .claude/hooks/hooks.json
ls -l .claude/hooks/*.ts
```

### Hook too slow (> 100ms)

Profile with timing:

```typescript
console.time('sanitize');
const result = fastSanitize(text);
console.timeEnd('sanitize');
```

Optimize regex patterns or reduce text length.

### Queue errors

Check database exists and is writable:

```bash
ls -lh data/context.db
sqlite3 data/context.db "SELECT COUNT(*) FROM event_queue"
```

## Next Steps

Hooks are now capturing events! Next:

1. **Phase 2**: [Sanitization Pipeline](../plans/plan-phase-2-sanitization-2025-01-16.md) - Full AI-powered sanitization
2. **Phase 3**: [Database & Storage](../plans/plan-phase-3-database-storage-2025-01-16.md) - Persistent storage
3. **Phase 4**: [Async Processing](../plans/plan-phase-4-async-processing-2025-01-16.md) - Background workers

## Related Documents

- [Hooks & Event Capture Architecture](../architecture/architecture-hooks-event-capture-2025-01-16.md)
- [Sanitization Pipeline Architecture](../architecture/architecture-sanitization-pipeline-2025-01-16.md)
- [TDD Workflow Guide](./guide-tdd-workflow-2025-01-16.md)

================
File: guides/guide-tdd-workflow-2025-01-16.md
================
# TDD Workflow Guide

> Master the Red-Green-Refactor cycle with AI-powered subagents

---
title: TDD Workflow with Subagents Guide
category: guide
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [guide, tdd, testing, red-green-refactor, workflow]
---

## Overview

This guide teaches you Test-Driven Development (TDD) enhanced with AI subagents. You'll learn the Red-Green-Refactor cycle where subagents generate tests, implement code, and validate quality automatically.

**Time to complete**: 60-90 minutes

## What You'll Learn

- The Red-Green-Refactor cycle with subagents
- How to write failing tests first (RED)
- Implementing minimal code to pass (GREEN)
- Refactoring with confidence (REFACTOR)
- Complete TDD workflow end-to-end
- Avoiding common TDD pitfalls

## Prerequisites

- **Testing Harness Complete**: [guide-testing-harness-usage-2025-01-16.md](./guide-testing-harness-usage-2025-01-16.md)
- **Subagents Guide Complete**: [guide-using-subagents-2025-01-16.md](./guide-using-subagents-2025-01-16.md)
- **Phase 0 Setup Complete**: [guide-phase-0-foundation-setup-2025-01-16.md](./guide-phase-0-foundation-setup-2025-01-16.md)

## TDD Philosophy

### Why Test First?

**Traditional Development** (Code-First):
```
Implement → Test → Debug → Fix → Repeat
```
Result: Tests miss edge cases, low coverage, bugs slip through

**Test-Driven Development** (Test-First):
```
Test → Implement → Validate → Refactor
```
Result: Comprehensive tests, high coverage, confidence in changes

### Benefits with Subagents

1. **Comprehensive Tests**: AI generates edge cases you might miss
2. **Quality Validation**: Automated quality gates ensure standards
3. **Faster Iteration**: Parallel generation and validation
4. **Consistent Patterns**: Subagents follow best practices
5. **Built-in Documentation**: Tests serve as specifications

## The Red-Green-Refactor Cycle

```
🔴 RED   → Write failing test
🟢 GREEN → Minimal code to pass
🔵 REFACTOR → Improve while keeping tests green
✅ VALIDATE → Quality gates pass
```

## Step 1: RED Phase - Write Failing Test

### 1.1 Delegate to Test Generator

**Goal**: Generate a comprehensive, failing test

Create `src/workflows/red-phase.ts`:

```typescript
import { invokeSubagent } from '../agents/orchestration/invoke';
import { testGeneratorSubagents } from '../agents/subagents/test-generators';

export async function redPhase(featureDescription: string): Promise<string> {
  console.log('🔴 RED PHASE: Generating failing test\n');

  const testCode = await invokeSubagent(
    'unit-test-generator',
    `Generate comprehensive failing test for:

${featureDescription}

Requirements:
- Test happy path
- Test edge cases: null, undefined, empty, very large inputs
- Test error conditions
- Use clear, descriptive names
- Follow arrange-act-assert pattern
- Aim for >85% coverage when implemented

The function doesn't exist yet - expect compilation errors.`,
    { agents: testGeneratorSubagents }
  );

  return testCode;
}
```

### 1.2 Validate Test Quality

```typescript
import { validateTestQuality } from '../agents/workflows/validate-tests';

export async function validateRedPhase(testFilePath: string): Promise<void> {
  console.log('📊 Validating test quality...\n');

  const validation = await validateTestQuality(testFilePath);

  if (validation.score < 0.8) {
    throw new Error(
      `Test quality insufficient: ${validation.score}\nIssues: ${validation.issues.join(', ')}`
    );
  }

  console.log(`✓ Test quality score: ${validation.score}`);
  if (validation.issues.length > 0) {
    console.log(`  Suggestions: ${validation.issues.join(', ')}`);
  }
}
```

### 1.3 Run Test (Confirm Failure)

```typescript
import { exec } from 'child_process';
import { promisify } from 'util';

const execAsync = promisify(exec);

export async function confirmTestFails(testPattern: string): Promise<void> {
  console.log('▶ Running test (expecting failure)...\n');

  try {
    await execAsync(`npm run test:once -- ${testPattern}`);
    throw new Error('⚠ WARNING: Test passed before implementation!');
  } catch (error: any) {
    if (error.message.includes('WARNING')) {
      throw error;
    }
    console.log('✓ Test failed as expected (good!)');
    console.log('  Error:', error.message.split('\n')[0]);
  }
}
```

### 1.4 Complete RED Phase Example

```typescript
export async function completeRedPhase(
  featureDescription: string,
  testFilePath: string
): Promise<string> {
  // 1. Generate test
  const testCode = await redPhase(featureDescription);

  // 2. Write test file
  writeFileSync(testFilePath, testCode);
  console.log(`✓ Test written to: ${testFilePath}\n`);

  // 3. Validate quality
  await validateRedPhase(testFilePath);

  // 4. Confirm it fails
  await confirmTestFails(testFilePath);

  console.log('\n🔴 RED PHASE COMPLETE\n');
  return testCode;
}
```

**Verification Checklist**:
- ✅ Test generated by subagent
- ✅ Test quality score ≥ 0.8
- ✅ Test fails for the right reason (function doesn't exist)
- ✅ Test is comprehensive (happy path + edge cases)

## Step 2: GREEN Phase - Minimal Implementation

### 2.1 Delegate to Implementation Agent

**Goal**: Write minimal code to make tests pass

Create `src/workflows/green-phase.ts`:

```typescript
import { invokeSubagent } from '../agents/orchestration/invoke';
import { implementationSubagents } from '../agents/subagents/implementation';

export async function greenPhase(
  testCode: string,
  featureDescription: string
): Promise<string> {
  console.log('🟢 GREEN PHASE: Implementing minimal code\n');

  const implementationCode = await invokeSubagent(
    'code-writer', // or specific agent like 'sanitization-developer'
    `Implement MINIMAL code to pass these tests:

Feature: ${featureDescription}

Tests:
${testCode}

Requirements:
- Write simplest possible implementation
- Don't over-engineer
- Handle all test cases
- Use strict TypeScript types
- Add JSDoc comments
- Focus on making tests pass, not perfection`,
    { agents: implementationSubagents }
  );

  return implementationCode;
}
```

### 2.2 Run Tests (Confirm Pass)

```typescript
export async function confirmTestsPass(testPattern: string): Promise<void> {
  console.log('▶ Running tests (expecting success)...\n');

  try {
    const { stdout } = await execAsync(`npm run test:once -- ${testPattern}`);
    console.log('✓ All tests passing!');

    // Extract test count
    const match = stdout.match(/(\d+) passed/);
    if (match) {
      console.log(`  Passed: ${match[1]} tests`);
    }
  } catch (error: any) {
    console.error('✗ Tests still failing:');
    console.error(error.message);
    throw new Error('GREEN phase failed: tests not passing');
  }
}
```

### 2.3 Validate Implementation

```typescript
import { invokeSubagent } from '../agents/orchestration/invoke';
import { validatorSubagents } from '../agents/subagents/validators';

export async function validateImplementation(
  testCode: string,
  implCode: string
): Promise<void> {
  console.log('📊 Validating implementation quality...\n');

  const validationResult = await invokeSubagent(
    'code-quality-validator',
    `Validate this implementation:

Tests:
${testCode}

Implementation:
${implCode}

Check for:
- All tests pass
- Handles all edge cases
- No security issues
- Proper error handling
- Type safety
- Code quality

Return JSON: { "score": 0.9, "passed": true, "issues": [] }`,
    { agents: validatorSubagents }
  );

  const validation = JSON.parse(validationResult);

  if (!validation.passed || validation.score < 0.8) {
    throw new Error(
      `Implementation quality insufficient: ${validation.score}\nIssues: ${validation.issues.join(', ')}`
    );
  }

  console.log(`✓ Implementation quality score: ${validation.score}`);
}
```

### 2.4 Complete GREEN Phase Example

```typescript
export async function completeGreenPhase(
  testCode: string,
  featureDescription: string,
  implFilePath: string,
  testPattern: string
): Promise<string> {
  // 1. Generate implementation
  const implCode = await greenPhase(testCode, featureDescription);

  // 2. Write implementation file
  writeFileSync(implFilePath, implCode);
  console.log(`✓ Implementation written to: ${implFilePath}\n`);

  // 3. Run tests
  await confirmTestsPass(testPattern);

  // 4. Validate implementation
  await validateImplementation(testCode, implCode);

  console.log('\n🟢 GREEN PHASE COMPLETE\n');
  return implCode;
}
```

**Verification Checklist**:
- ✅ Minimal implementation (not over-engineered)
- ✅ All tests pass
- ✅ Implementation quality score ≥ 0.8
- ✅ No security issues
- ✅ Proper type safety

## Step 3: REFACTOR Phase - Improve Quality

### 3.1 Identify Improvement Opportunities

**Goal**: Clean up code while keeping tests green

Create `src/workflows/refactor-phase.ts`:

```typescript
import { invokeSubagent } from '../agents/orchestration/invoke';
import { implementationSubagents } from '../agents/subagents/implementation';

export async function identifyRefactorings(implCode: string): Promise<string[]> {
  console.log('🔵 REFACTOR PHASE: Analyzing code...\n');

  const analysis = await invokeSubagent(
    'code-quality-validator',
    `Analyze this code for refactoring opportunities:

${implCode}

Look for:
- Code duplication
- Long functions (>20 lines)
- Complex conditionals
- Magic numbers
- Unclear variable names
- Missing abstractions

Return JSON array of specific refactorings: ["Extract regex to constant", ...]`,
    { agents: implementationSubagents }
  );

  return JSON.parse(analysis);
}
```

### 3.2 Apply Refactorings

```typescript
export async function applyRefactoring(
  implCode: string,
  refactoring: string
): Promise<string> {
  console.log(`  Applying: ${refactoring}`);

  const refactoredCode = await invokeSubagent(
    'code-writer',
    `Refactor this code:

Current Code:
${implCode}

Refactoring: ${refactoring}

Requirements:
- Apply refactoring only
- Don't change functionality
- Keep code working
- Improve readability/maintainability`,
    { agents: implementationSubagents }
  );

  return refactoredCode;
}
```

### 3.3 Test After Each Refactoring

```typescript
export async function refactorWithTesting(
  implCode: string,
  testPattern: string
): Promise<string> {
  const refactorings = await identifyRefactorings(implCode);

  if (refactorings.length === 0) {
    console.log('✓ No refactorings needed\n');
    return implCode;
  }

  console.log(`Found ${refactorings.length} refactoring opportunities\n`);

  let currentCode = implCode;

  for (const refactoring of refactorings) {
    // Apply refactoring
    currentCode = await applyRefactoring(currentCode, refactoring);

    // Run tests immediately
    try {
      await confirmTestsPass(testPattern);
      console.log(`  ✓ Tests still passing\n`);
    } catch (error) {
      console.error(`  ✗ Tests failed after refactoring!`);
      throw new Error(`Refactoring broke tests: ${refactoring}`);
    }
  }

  return currentCode;
}
```

### 3.4 Complete REFACTOR Phase Example

```typescript
export async function completeRefactorPhase(
  implCode: string,
  implFilePath: string,
  testPattern: string
): Promise<string> {
  console.log('🔵 REFACTOR PHASE: Improving code quality\n');

  // 1. Apply refactorings
  const refactoredCode = await refactorWithTesting(implCode, testPattern);

  // 2. Write refactored code
  writeFileSync(implFilePath, refactoredCode);

  // 3. Final validation
  await validateImplementation('', refactoredCode);

  console.log('\n🔵 REFACTOR PHASE COMPLETE\n');
  return refactoredCode;
}
```

**Verification Checklist**:
- ✅ Code quality improved
- ✅ Tests still passing after each change
- ✅ No functionality changed
- ✅ Code more maintainable
- ✅ Quality score increased

## Step 4: Complete TDD Cycle

### 4.1 Full Workflow

Create `src/workflows/complete-tdd-cycle.ts`:

```typescript
import { completeRedPhase } from './red-phase';
import { completeGreenPhase } from './green-phase';
import { completeRefactorPhase } from './refactor-phase';
import { getCoverageViaMCP } from '../agents/workflows/run-tests';

export async function completeTDDCycle(
  featureDescription: string,
  testFilePath: string,
  implFilePath: string
): Promise<void> {
  console.log('═══ TDD CYCLE START ═══\n');
  console.log(`Feature: ${featureDescription}\n`);

  const testPattern = testFilePath.replace(/^src\//, '').replace(/\.test\.ts$/, '');

  try {
    // RED: Write failing test
    const testCode = await completeRedPhase(featureDescription, testFilePath);

    // GREEN: Implement minimal code
    const implCode = await completeGreenPhase(
      testCode,
      featureDescription,
      implFilePath,
      testPattern
    );

    // REFACTOR: Improve code quality
    await completeRefactorPhase(implCode, implFilePath, testPattern);

    // COVERAGE: Verify coverage
    console.log('📈 Checking coverage...\n');
    const coverage = await getCoverageViaMCP();
    console.log('Coverage:', coverage);

    if (coverage.lines < 85) {
      console.warn(`⚠ Warning: Coverage ${coverage.lines}% < 85%`);
    } else {
      console.log('✓ Coverage excellent\n');
    }

    console.log('═══ TDD CYCLE COMPLETE ═══');
    console.log('✅ Feature implemented with tests');
  } catch (error) {
    console.error('\n✗ TDD cycle failed:', error);
    throw error;
  }
}
```

### 4.2 Example Usage

Create `src/workflows/examples/sanitize-api-keys-tdd.ts`:

```typescript
import { config } from 'dotenv';
import { completeTDDCycle } from '../complete-tdd-cycle';

config();

async function main() {
  await completeTDDCycle(
    'Function sanitizeApiKeys(text: string): string that redacts all API keys and tokens in text',
    'src/sanitization/sanitize.test.ts',
    'src/sanitization/sanitize.ts'
  );
}

main().catch(console.error);
```

Run it:

```bash
ts-node src/workflows/examples/sanitize-api-keys-tdd.ts
```

**Expected output**:
```
═══ TDD CYCLE START ═══

Feature: Function sanitizeApiKeys(text: string): string...

🔴 RED PHASE: Generating failing test
  → Invoking: unit-test-generator
  ✓ Completed: unit-test-generator
✓ Test written to: src/sanitization/sanitize.test.ts

📊 Validating test quality...
✓ Test quality score: 0.92

▶ Running test (expecting failure)...
✓ Test failed as expected (good!)

🔴 RED PHASE COMPLETE

🟢 GREEN PHASE: Implementing minimal code
  → Invoking: code-writer
  ✓ Completed: code-writer
✓ Implementation written to: src/sanitization/sanitize.ts

▶ Running tests (expecting success)...
✓ All tests passing!
  Passed: 8 tests

📊 Validating implementation quality...
✓ Implementation quality score: 0.88

🟢 GREEN PHASE COMPLETE

🔵 REFACTOR PHASE: Improving code quality
  Applying: Extract regex patterns to constants
  ✓ Tests still passing
  Applying: Extract validation to helper function
  ✓ Tests still passing

🔵 REFACTOR PHASE COMPLETE

📈 Checking coverage...
Coverage: { lines: 94.2, statements: 92.1, functions: 100, branches: 87.5 }
✓ Coverage excellent

═══ TDD CYCLE COMPLETE ═══
✅ Feature implemented with tests
```

## Step 5: Commit Discipline

### 5.1 Commit After Each Phase

```typescript
import { exec } from 'child_process';
import { promisify } from 'util';

const execAsync = promisify(exec);

export async function commitPhase(
  phase: 'red' | 'green' | 'refactor',
  message: string
): Promise<void> {
  await execAsync('git add .');
  await execAsync(`git commit -m "${phase.toUpperCase()}: ${message}"`);
  console.log(`✓ Committed: ${phase} phase\n`);
}
```

Usage:

```typescript
// After RED
await commitPhase('red', 'Add failing tests for sanitizeApiKeys');

// After GREEN
await commitPhase('green', 'Implement sanitizeApiKeys to pass tests');

// After REFACTOR
await commitPhase('refactor', 'Extract regex patterns to constants');
```

## Common Pitfalls and Solutions

### Pitfall 1: Skipping Test Generation

❌ **Wrong**: "Tests take too long, I'll just implement"

✅ **Right**: "Tests first, always. Use subagents to generate fast"

### Pitfall 2: Over-Implementation in GREEN

❌ **Wrong**: Implementing perfect, production-ready code in GREEN phase

✅ **Right**: Simplest possible code to pass tests. Improve in REFACTOR.

### Pitfall 3: Changing Tests After GREEN

❌ **Wrong**: Tests fail, so change tests to match implementation

✅ **Right**: Tests define requirements. Fix implementation, not tests.

### Pitfall 4: Skipping REFACTOR

❌ **Wrong**: "It works, ship it"

✅ **Right**: Clean code is as important as working code. Always refactor.

### Pitfall 5: Large Test Suites at Once

❌ **Wrong**: Write 50 tests, then implement everything

✅ **Right**: One test at a time, or small batches. Keep cycle fast.

## Verification

You're doing TDD correctly when:

- ✅ You always write tests first
- ✅ Tests fail before implementation
- ✅ You write minimal code to pass
- ✅ Tests pass after implementation
- ✅ You refactor with confidence
- ✅ Coverage is >85%
- ✅ All quality gates pass

## Next Steps

Now apply TDD to real features:

1. [Phase 1 Hook Development](./guide-phase-1-hook-development-2025-01-16.md) - Apply TDD to hooks
2. [Phase 2 Sanitization](../plans/plan-phase-2-sanitization-2025-01-16.md) - TDD for sanitization
3. Continue TDD for all features

## Related Documents

- [Testing Harness Architecture](../architecture/architecture-testing-harness-2025-01-16.md)
- [Subagent System Architecture](../architecture/architecture-subagent-system-2025-01-16.md)
- [Testing Strategy](../reference/reference-testing-strategy-2025-01-16.md)

================
File: guides/guide-testing-harness-usage-2025-01-16.md
================
# Testing Harness Usage Guide

> Learn how to use the Claude-powered testing harness for AI-driven test generation and validation

---
title: Testing Harness Usage Guide
category: guide
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [guide, testing, vitest, mcp, test-generation, validation]
---

## Overview

This guide teaches you how to use the Claude-powered testing harness - a system where AI subagents generate, validate, and run tests automatically. The harness ensures comprehensive test coverage and quality through AI-powered validation.

**Time to complete**: 90-120 minutes

## What You'll Learn

- Set up the testing MCP server
- Generate tests with test-generator subagents
- Validate test quality automatically
- Run tests and interpret results
- Use coverage validation
- Integrate testing into your workflow

## Prerequisites

- **Phase 0 Setup Complete**: [guide-phase-0-foundation-setup-2025-01-16.md](./guide-phase-0-foundation-setup-2025-01-16.md)
- **Subagents Guide Complete**: [guide-using-subagents-2025-01-16.md](./guide-using-subagents-2025-01-16.md)
- **Vitest Installed**: Should be done in Phase 0
- **Understanding of testing**: Basic test concepts

## Testing Philosophy

**Test-Driven Development with AI Validation**

Traditional TDD:
1. Write test manually
2. Run test (should fail)
3. Implement code
4. Run test (should pass)

AI-Enhanced TDD:
1. **AI generates comprehensive test** (validator checks quality)
2. Run test (should fail)
3. **AI implements minimal code** (validator checks implementation)
4. Run test (should pass)
5. **AI validates quality** (coverage, security, performance)

## Step 1: Set Up MCP Test Runner Server

### 1.1 Create MCP Server Directory

```bash
mkdir -p src/mcp/test-runner
```

### 1.2 Install MCP SDK

```bash
npm install @modelcontextprotocol/sdk
```

### 1.3 Create Test Runner Server

Create `src/mcp/test-runner/server.ts`:

```typescript
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import {
  CallToolRequestSchema,
  ListToolsRequestSchema,
} from '@modelcontextprotocol/sdk/types.js';
import { exec } from 'child_process';
import { promisify } from 'util';
import { readFileSync, existsSync } from 'fs';
import { join } from 'path';

const execAsync = promisify(exec);

class TestRunnerServer {
  private server: Server;

  constructor() {
    this.server = new Server(
      {
        name: 'test-runner',
        version: '1.0.0',
      },
      {
        capabilities: {
          tools: {},
        },
      }
    );

    this.setupToolHandlers();

    this.server.onerror = (error) => console.error('[MCP Error]', error);
    process.on('SIGINT', async () => {
      await this.server.close();
      process.exit(0);
    });
  }

  private setupToolHandlers() {
    this.server.setRequestHandler(ListToolsRequestSchema, async () => ({
      tools: [
        {
          name: 'run_unit_tests',
          description: 'Run Vitest unit tests',
          inputSchema: {
            type: 'object',
            properties: {
              testPattern: {
                type: 'string',
                description: 'Optional test file pattern (e.g., "sanitize")',
              },
            },
          },
        },
        {
          name: 'run_integration_tests',
          description: 'Run integration tests',
          inputSchema: {
            type: 'object',
            properties: {
              testPattern: {
                type: 'string',
                description: 'Optional test file pattern',
              },
            },
          },
        },
        {
          name: 'run_e2e_tests',
          description: 'Run end-to-end tests',
          inputSchema: {
            type: 'object',
            properties: {
              testPattern: {
                type: 'string',
                description: 'Optional test file pattern',
              },
            },
          },
        },
        {
          name: 'get_coverage_report',
          description: 'Get test coverage statistics',
          inputSchema: {
            type: 'object',
            properties: {},
          },
        },
        {
          name: 'validate_test_quality',
          description: 'Validates test code quality and returns score',
          inputSchema: {
            type: 'object',
            properties: {
              testFilePath: {
                type: 'string',
                description: 'Path to test file to validate',
              },
            },
            required: ['testFilePath'],
          },
        },
      ],
    }));

    this.server.setRequestHandler(CallToolRequestSchema, async (request) => {
      switch (request.params.name) {
        case 'run_unit_tests':
          return this.runUnitTests(request.params.arguments?.testPattern as string);

        case 'run_integration_tests':
          return this.runIntegrationTests(request.params.arguments?.testPattern as string);

        case 'run_e2e_tests':
          return this.runE2ETests(request.params.arguments?.testPattern as string);

        case 'get_coverage_report':
          return this.getCoverageReport();

        case 'validate_test_quality':
          return this.validateTestQuality(
            request.params.arguments?.testFilePath as string
          );

        default:
          throw new Error(`Unknown tool: ${request.params.name}`);
      }
    });
  }

  private async runUnitTests(testPattern?: string) {
    const pattern = testPattern ? ` -- ${testPattern}` : '';
    const cmd = `npm run test:once${pattern}`;

    try {
      const { stdout, stderr } = await execAsync(cmd);
      return {
        content: [
          {
            type: 'text',
            text: JSON.stringify({
              success: true,
              stdout,
              stderr,
            }),
          },
        ],
      };
    } catch (error: any) {
      return {
        content: [
          {
            type: 'text',
            text: JSON.stringify({
              success: false,
              error: error.message,
              stdout: error.stdout,
              stderr: error.stderr,
            }),
          },
        ],
      };
    }
  }

  private async runIntegrationTests(testPattern?: string) {
    const pattern = testPattern || 'integration';
    return this.runUnitTests(pattern);
  }

  private async runE2ETests(testPattern?: string) {
    const pattern = testPattern || 'e2e';
    return this.runUnitTests(pattern);
  }

  private async getCoverageReport() {
    const coveragePath = join(process.cwd(), 'coverage', 'coverage-summary.json');

    if (!existsSync(coveragePath)) {
      // Run coverage first
      try {
        await execAsync('npm run coverage');
      } catch (error) {
        return {
          content: [
            {
              type: 'text',
              text: JSON.stringify({
                success: false,
                error: 'Coverage generation failed',
              }),
            },
          ],
        };
      }
    }

    try {
      const coverage = JSON.parse(readFileSync(coveragePath, 'utf-8'));
      const total = coverage.total;

      return {
        content: [
          {
            type: 'text',
            text: JSON.stringify({
              success: true,
              coverage: {
                lines: total.lines.pct,
                statements: total.statements.pct,
                functions: total.functions.pct,
                branches: total.branches.pct,
              },
            }),
          },
        ],
      };
    } catch (error: any) {
      return {
        content: [
          {
            type: 'text',
            text: JSON.stringify({
              success: false,
              error: error.message,
            }),
          },
        ],
      };
    }
  }

  private async validateTestQuality(testFilePath: string) {
    if (!existsSync(testFilePath)) {
      return {
        content: [
          {
            type: 'text',
            text: JSON.stringify({
              score: 0,
              issues: [`Test file not found: ${testFilePath}`],
            }),
          },
        ],
      };
    }

    const testContent = readFileSync(testFilePath, 'utf-8');

    // Simple static analysis
    let score = 1.0;
    const issues: string[] = [];

    // Check for describe blocks
    if (!testContent.includes('describe(')) {
      score -= 0.2;
      issues.push('Missing describe() blocks');
    }

    // Check for it/test blocks
    const testCount = (testContent.match(/it\(|test\(/g) || []).length;
    if (testCount < 3) {
      score -= 0.3;
      issues.push('Insufficient test cases (< 3)');
    }

    // Check for expect statements
    const expectCount = (testContent.match(/expect\(/g) || []).length;
    if (expectCount < testCount) {
      score -= 0.2;
      issues.push('Some tests missing assertions');
    }

    // Check for edge case keywords
    const hasEdgeCases =
      testContent.includes('edge') ||
      testContent.includes('boundary') ||
      testContent.includes('null') ||
      testContent.includes('undefined') ||
      testContent.includes('empty');

    if (!hasEdgeCases) {
      score -= 0.2;
      issues.push('No obvious edge case testing');
    }

    return {
      content: [
        {
          type: 'text',
          text: JSON.stringify({
            score: Math.max(0, score),
            issues,
            strengths:
              score >= 0.8 ? ['Good test structure', 'Adequate coverage'] : [],
          }),
        },
      ],
    };
  }

  async run() {
    const transport = new StdioServerTransport();
    await this.server.connect(transport);
    console.error('Test Runner MCP server running on stdio');
  }
}

const server = new TestRunnerServer();
server.run().catch(console.error);
```

### 1.4 Add Server Script

Add to `package.json`:

```json
{
  "scripts": {
    "mcp:test-runner": "node dist/mcp/test-runner/server.js"
  }
}
```

### 1.5 Build and Run

```bash
# Build
npm run build

# Run MCP server (in separate terminal)
npm run mcp:test-runner
```

**Expected output**:
```
Test Runner MCP server running on stdio
```

## Step 2: Generate Tests with Subagents

### 2.1 Create Test Generator Workflow

Create `src/agents/workflows/generate-tests.ts`:

```typescript
import { invokeSubagent } from '../orchestration/invoke';
import { testGeneratorSubagents } from '../subagents/test-generators';

export async function generateUnitTests(
  functionDescription: string,
  filePath?: string
): Promise<string> {
  const prompt = `Generate comprehensive unit tests for:
  
Description: ${functionDescription}
${filePath ? `File: ${filePath}` : ''}

Requirements:
- Use Vitest (describe, it, expect)
- Test happy path
- Test edge cases (null, undefined, empty, very large)
- Test error conditions
- Use arrange-act-assert pattern
- Clear, descriptive test names
- Aim for >85% coverage`;

  return invokeSubagent('unit-test-generator', prompt, {
    agents: testGeneratorSubagents,
  });
}
```

### 2.2 Example Usage

```typescript
import { generateUnitTests } from './workflows/generate-tests';

const tests = await generateUnitTests(
  'Function sanitizeApiKeys(text: string): string that redacts API keys',
  'src/sanitization/sanitize.ts'
);

console.log(tests);
```

**Expected output**:
```typescript
import { describe, it, expect } from 'vitest';
import { sanitizeApiKeys } from './sanitize';

describe('sanitizeApiKeys', () => {
  it('should redact OpenAI API keys', () => {
    const input = 'My key is sk-abc123...';
    const result = sanitizeApiKeys(input);
    expect(result).toBe('My key is [REDACTED_API_KEY]');
  });

  it('should handle empty strings', () => {
    expect(sanitizeApiKeys('')).toBe('');
  });

  it('should handle null/undefined', () => {
    expect(() => sanitizeApiKeys(null as any)).toThrow();
  });

  // ... more tests
});
```

## Step 3: Validate Test Quality

### 3.1 Use MCP Validation Tool

Create `src/agents/workflows/validate-tests.ts`:

```typescript
import { invokeSubagent } from '../orchestration/invoke';
import { validatorSubagents } from '../subagents/validators';
import { mcpServers } from '../../mcp/config';

export async function validateTestQuality(
  testFilePath: string
): Promise<{
  score: number;
  passed: boolean;
  issues: string[];
}> {
  const prompt = `Validate test quality for: ${testFilePath}

Use the validate_test_quality tool to get automated quality score.
Then review manually for:
- Test structure
- Coverage completeness
- Clear naming
- Proper assertions

Return JSON with:
- score (0-1)
- passed (true if score >= 0.8)
- issues (array of strings)`;

  const response = await invokeSubagent('test-quality-validator', prompt, {
    agents: validatorSubagents,
    mcpServers,
  });

  return JSON.parse(response);
}
```

### 3.2 Quality Gate

```typescript
export async function testQualityGate(testFilePath: string): Promise<void> {
  const validation = await validateTestQuality(testFilePath);

  if (!validation.passed) {
    throw new Error(
      `Test quality gate failed (score: ${validation.score})\nIssues:\n${validation.issues.join('\n')}`
    );
  }

  console.log(`✓ Test quality gate passed (score: ${validation.score})`);
}
```

## Step 4: Run Tests and Get Coverage

### 4.1 Run Tests via MCP

```typescript
import { query } from '@anthropic-ai/claude-agent-sdk';
import { mcpServers } from '../mcp/config';

export async function runTestsViaMCP(
  testPattern?: string
): Promise<{ success: boolean; output: string }> {
  const prompt = `Run unit tests${testPattern ? ` matching: ${testPattern}` : ''}

Use the run_unit_tests tool.
Return the results.`;

  const response = query({
    prompt,
    options: {
      model: 'claude-sonnet-4-5',
      agents: {},
      mcpServers,
      tools: ['mcp__test-runner__run_unit_tests'],
      apiKey: process.env.ANTHROPIC_API_KEY,
    },
  });

  let result = '';
  for await (const message of response) {
    if (message.type === 'text') result += message.text;
  }

  const data = JSON.parse(result);
  return data;
}
```

### 4.2 Get Coverage Report

```typescript
export async function getCoverageViaMCP(): Promise<{
  lines: number;
  statements: number;
  functions: number;
  branches: number;
}> {
  const prompt = 'Get test coverage report using get_coverage_report tool';

  const response = query({
    prompt,
    options: {
      model: 'claude-sonnet-4-5',
      agents: {},
      mcpServers,
      tools: ['mcp__test-runner__get_coverage_report'],
      apiKey: process.env.ANTHROPIC_API_KEY,
    },
  });

  let result = '';
  for await (const message of response) {
    if (message.type === 'text') result += message.text;
  }

  const data = JSON.parse(result);
  return data.coverage;
}
```

## Step 5: Complete Testing Workflow

### 5.1 Full TDD Cycle with Testing Harness

Create `src/agents/workflows/tdd-with-harness.ts`:

```typescript
import { generateUnitTests } from './generate-tests';
import { validateTestQuality } from './validate-tests';
import { runTestsViaMCP, getCoverageViaMCP } from './run-tests';
import { invokeSubagent } from '../orchestration/invoke';
import { implementationSubagents } from '../subagents/implementation';

export async function tddCycleWithHarness(
  featureDescription: string
): Promise<void> {
  console.log('=== TDD Cycle with Testing Harness ===\n');

  // 1. RED: Generate test
  console.log('🔴 RED: Generating tests...');
  const testCode = await generateUnitTests(featureDescription);
  console.log('✓ Tests generated\n');

  // 2. Validate test quality
  console.log('📊 Validating test quality...');
  const validation = await validateTestQuality('./generated-test.ts');
  if (!validation.passed) {
    throw new Error(`Test quality insufficient: ${validation.score}`);
  }
  console.log(`✓ Test quality: ${validation.score}\n`);

  // 3. Run tests (should fail)
  console.log('▶ Running tests (expecting failure)...');
  const initialRun = await runTestsViaMCP();
  if (initialRun.success) {
    console.warn('⚠ Warning: Tests passed before implementation!');
  } else {
    console.log('✓ Tests failed as expected\n');
  }

  // 4. GREEN: Implement
  console.log('🟢 GREEN: Implementing code...');
  const implementation = await invokeSubagent(
    'code-writer',
    `Implement minimal code to pass these tests:\n\n${testCode}`,
    { agents: implementationSubagents }
  );
  console.log('✓ Implementation complete\n');

  // 5. Run tests (should pass)
  console.log('▶ Running tests (expecting success)...');
  const finalRun = await runTestsViaMCP();
  if (!finalRun.success) {
    throw new Error('Tests still failing after implementation');
  }
  console.log('✓ Tests passing\n');

  // 6. Coverage check
  console.log('📈 Checking coverage...');
  const coverage = await getCoverageViaMCP();
  console.log('Coverage:', coverage);

  if (coverage.lines < 85) {
    console.warn(`⚠ Warning: Line coverage ${coverage.lines}% < 85%`);
  } else {
    console.log('✓ Coverage acceptable\n');
  }

  console.log('=== TDD Cycle Complete ===');
}
```

## Verification

Create `src/agents/test-harness.ts`:

```typescript
import { config } from 'dotenv';
import { tddCycleWithHarness } from './workflows/tdd-with-harness';

config();

async function main() {
  await tddCycleWithHarness(
    'Function sanitizeApiKeys(text: string) that redacts API keys'
  );
}

main().catch(console.error);
```

```bash
# Start MCP server in one terminal
npm run mcp:test-runner

# Run harness in another terminal
ts-node src/agents/test-harness.ts
```

## You're Done When...

- ✅ MCP test-runner server running
- ✅ Can generate tests via subagents
- ✅ Test quality validation working
- ✅ Can run tests via MCP
- ✅ Coverage reports accessible
- ✅ Complete TDD cycle functioning

## Troubleshooting

### MCP Server Not Running

```bash
# Check if process is running
ps aux | grep test-runner

# Restart server
npm run mcp:test-runner
```

### Tool Not Found

Ensure MCP server exposes the tool and client references it correctly:
- Server: `tools: [{ name: 'run_unit_tests', ... }]`
- Client: `tools: ['mcp__test-runner__run_unit_tests']`

### Coverage Not Generated

```bash
# Run coverage manually first
npm run coverage

# Check coverage directory exists
ls coverage/
```

## Best Practices

1. **Always validate test quality** before implementation
2. **Use MCP tools for consistency** across subagents
3. **Set coverage thresholds** (85% minimum)
4. **Run tests frequently** during development
5. **Monitor MCP server health** for reliable testing
6. **Cost control**: Limit AI validation to critical tests

## Next Steps

- [TDD Workflow Guide](./guide-tdd-workflow-2025-01-16.md) - Deep dive into TDD patterns
- [Phase 1 Hook Development](./guide-phase-1-hook-development-2025-01-16.md) - Apply testing to hooks

## Related Documents

- [Testing Harness Architecture](../architecture/architecture-testing-harness-2025-01-16.md)
- [Testing Strategy Reference](../reference/reference-testing-strategy-2025-01-16.md)

================
File: guides/guide-using-subagents-2025-01-16.md
================
# Using Subagents Guide

> Learn how to delegate tasks to specialized Claude subagents for focused expertise

---
title: Using Subagents Guide
category: guide
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [guide, subagents, delegation, orchestration, patterns]
---

## Overview

This guide teaches you how to effectively use subagents in the Global Context Network project. Subagents are specialized Claude instances with focused prompts and tools, designed to handle specific tasks better than a general-purpose agent.

**Time to complete**: 60-90 minutes

## What You'll Learn

- When to delegate vs implement directly
- How to define effective subagent configurations
- Invoking subagents via Claude Agent SDK
- Monitoring subagent progress
- Handling subagent responses
- Parallel and sequential delegation patterns

## Prerequisites

- **Phase 0 Setup Complete**: [guide-phase-0-foundation-setup-2025-01-16.md](./guide-phase-0-foundation-setup-2025-01-16.md)
- **Claude Agent SDK Integrated**: [guide-claude-agent-sdk-integration-2025-01-16.md](./guide-claude-agent-sdk-integration-2025-01-16.md)
- **Understanding of TypeScript**: async/await, Promises, types

## Core Principle

**Never implement directly - always delegate to specialized subagents.**

Why? Subagents provide:
- **Focused expertise**: Each knows its domain deeply
- **Consistent quality**: Specialized prompts ensure standards
- **Parallel execution**: Independent tasks run simultaneously
- **Built-in validation**: Quality checks at every step

## When to Use Subagents

### Delegate to Subagents When:

✅ **Implementing features**: Use implementation subagents
✅ **Writing tests**: Use test generator subagents
✅ **Validating code**: Use quality validator subagents
✅ **Complex workflows**: Use orchestrator patterns
✅ **Multiple independent tasks**: Use parallel execution

### Implement Directly When:

❌ **Trivial changes**: Simple one-line fixes
❌ **Configuration files**: package.json, tsconfig.json
❌ **Already tested patterns**: Proven, simple code
❌ **Time-sensitive debugging**: Immediate fixes needed

## Step 1: Understanding Subagent Anatomy

### 1.1 Subagent Definition Structure

```typescript
import { AgentDefinition } from '@anthropic-ai/claude-agent-sdk';

const exampleAgent: AgentDefinition = {
  // What this agent does (for orchestrator selection)
  description: 'Implements TypeScript functions with strict types',

  // Specialized instructions (the agent's expertise)
  prompt: `You are an expert TypeScript developer.
  Your role: Implement functions following these rules:
  1. Use strict TypeScript types (never 'any')
  2. Add comprehensive JSDoc comments
  3. Handle edge cases explicitly
  4. Follow functional programming when possible
  5. Write defensive code with validation

  Quality bar: Production-ready, type-safe, well-documented code.`,

  // Available capabilities
  tools: ['Read', 'Write', 'Edit', 'Bash'],

  // Which model to use
  model: 'claude-sonnet-4-5',
};
```

### 1.2 Effective Prompt Design

**Bad Prompt** (too vague):
```typescript
prompt: "Write good code"
```

**Good Prompt** (specific, actionable):
```typescript
prompt: `You are a sanitization expert.
When implementing PII redaction:
1. Use regex for fast detection (API keys, emails, IPs)
2. Preserve code structure while masking values
3. Log redaction count for audit trail
4. Never miss potential PII - err on side of caution
5. Test with real-world examples

Performance: < 10ms per conversation
Accuracy: < 1% false negatives`
```

### 1.3 Tool Selection

Match tools to subagent needs:

| Subagent Type | Typical Tools |
|---------------|---------------|
| Implementation | Read, Write, Edit, Bash |
| Test Generator | Read, Write, Edit |
| Validator | Read, Grep, mcp__test-runner__* |
| Quality Checker | Read, Grep, Bash |
| Documentation | Read, Write, Edit |

## Step 2: Creating Specialized Subagents

### 2.1 Implementation Subagent

Create `src/agents/subagents/implementation.ts`:

```typescript
import { AgentDefinition } from '@anthropic-ai/claude-agent-sdk';

/**
 * Hook implementation specialist
 */
export const hookDeveloperAgent: AgentDefinition = {
  description: 'Implements Claude Code hooks with <100ms execution time',
  prompt: `You are a Claude Code hooks expert.

  When implementing hooks:
  1. NEVER block user interaction (< 100ms execution)
  2. Fail silently with structured logging
  3. Use fire-and-forget for I/O operations
  4. Validate input before processing
  5. Queue events asynchronously

  Event Schema:
  - id: unique identifier
  - conversation_id: thread identifier
  - role: 'user' | 'assistant'
  - content: sanitized message content
  - timestamp: Unix timestamp

  Error Handling:
  - Try-catch all operations
  - Log errors with context
  - Never throw to caller (hooks must not fail)

  Performance Budget: < 100ms total, < 50ms for queueing.`,
  tools: ['Read', 'Write', 'Edit', 'Bash'],
  model: 'claude-sonnet-4-5',
};

/**
 * Sanitization pipeline specialist
 */
export const sanitizationAgent: AgentDefinition = {
  description: 'Implements PII detection and redaction with hybrid approach',
  prompt: `You are a PII sanitization expert.

  Implement hybrid sanitization:

  Phase 1 - Rule-Based (Fast):
  - Regex for API keys: /sk-[a-zA-Z0-9]{48}/
  - Email: RFC 5322 compliant regex
  - IP addresses: IPv4/IPv6 patterns
  - File paths: absolute paths with usernames
  - URLs with tokens: query params containing 'token', 'key', 'secret'

  Phase 2 - AI-Powered (Accurate):
  - Context-aware name detection (distinguish from variables)
  - Company-specific terminology
  - Phone numbers (international formats)
  - Addresses

  Validation:
  - Combine rule-based + AI results
  - Log all redactions for audit
  - Performance: < 2s per conversation
  - Accuracy: < 1% false negatives, < 5% false positives

  Replacement Strategy:
  - API keys → [REDACTED_API_KEY]
  - Emails → [REDACTED_EMAIL]
  - Paths → [REDACTED_PATH]
  - Names → [REDACTED_NAME]`,
  tools: ['Read', 'Write', 'Edit'],
  model: 'claude-sonnet-4-5',
};

export const implementationSubagents = {
  'hook-developer': hookDeveloperAgent,
  'sanitization-developer': sanitizationAgent,
};
```

### 2.2 Test Generator Subagent

Create `src/agents/subagents/test-generators.ts`:

```typescript
import { AgentDefinition } from '@anthropic-ai/claude-agent-sdk';

/**
 * Unit test generator
 */
export const unitTestGenerator: AgentDefinition = {
  description: 'Generates comprehensive unit tests with Vitest',
  prompt: `You are a testing expert specializing in Vitest.

  When generating unit tests:

  Structure:
  - describe() for component/function
  - it() for individual behaviors
  - expect() for assertions (be specific, not just truthy)

  Coverage Requirements:
  - Happy path
  - Edge cases (empty, null, undefined, very large)
  - Error conditions
  - Boundary values

  Patterns:
  - Arrange-Act-Assert structure
  - One logical assertion per test
  - Clear, descriptive test names
  - Mock external dependencies
  - Use beforeEach for setup, afterEach for cleanup

  Quality:
  - Target: > 85% coverage
  - No flaky tests (deterministic)
  - Fast execution (< 100ms per test)
  - Independent tests (no shared state)

  Example:
  describe('sanitizeApiKeys', () => {
    it('should redact OpenAI API keys', () => {
      const input = 'My key is sk-abc123';
      const result = sanitizeApiKeys(input);
      expect(result).toBe('My key is [REDACTED_API_KEY]');
    });
  });`,
  tools: ['Read', 'Write', 'Edit'],
  model: 'claude-sonnet-4-5',
};

/**
 * Integration test generator
 */
export const integrationTestGenerator: AgentDefinition = {
  description: 'Generates integration tests for component interactions',
  prompt: `You are an integration testing expert.

  When generating integration tests:

  Scope:
  - Test real component interactions
  - Use actual database (test instance)
  - Test file I/O with temp files
  - Verify async behavior

  Patterns:
  - Set up realistic test data
  - Test complete workflows (hook → queue → sanitize → db)
  - Verify side effects (database writes, file creation)
  - Test error propagation between components
  - Clean up resources in afterEach

  Example:
  describe('Event Capture Flow', () => {
    it('should capture user prompt and queue for sanitization', async () => {
      const db = createTestDatabase();
      const queue = new EventQueue(db);

      await captureUserPrompt({ content: 'test' });

      const jobs = queue.getPendingJobs();
      expect(jobs).toHaveLength(1);
      expect(jobs[0].type).toBe('sanitize_conversation');
    });
  });`,
  tools: ['Read', 'Write', 'Edit', 'Bash'],
  model: 'claude-sonnet-4-5',
};

export const testGeneratorSubagents = {
  'unit-test-generator': unitTestGenerator,
  'integration-test-generator': integrationTestGenerator,
};
```

### 2.3 Validator Subagent

Create `src/agents/subagents/validators.ts`:

```typescript
import { AgentDefinition } from '@anthropic-ai/claude-agent-sdk';

/**
 * Test quality validator
 */
export const testQualityValidator: AgentDefinition = {
  description: 'Validates test code quality and completeness',
  prompt: `You are a test quality auditor.

  Review tests for:

  Structure (0.3 weight):
  - Proper describe/it nesting
  - Clear, descriptive names
  - Logical grouping

  Coverage (0.4 weight):
  - Happy path tested
  - Edge cases covered
  - Error conditions tested
  - Boundary values checked

  Quality (0.3 weight):
  - Specific assertions (not just truthy)
  - No test interdependencies
  - Proper mocking
  - Arrange-Act-Assert pattern

  Scoring:
  - 1.0: Excellent, comprehensive
  - 0.8-0.9: Good, minor gaps
  - 0.6-0.7: Acceptable, some issues
  - < 0.6: Fail, major problems

  Return JSON:
  {
    "score": 0.92,
    "strengths": ["Excellent edge case coverage"],
    "weaknesses": ["Missing error condition test"],
    "required_fixes": []
  }`,
  tools: ['Read', 'Grep', 'mcp__test-runner__validate_test_quality'],
  model: 'claude-sonnet-4-5',
};

/**
 * Code quality validator
 */
export const codeQualityValidator: AgentDefinition = {
  description: 'Reviews code for quality, security, and standards compliance',
  prompt: `You are a code quality auditor.

  Review code for:

  TypeScript Standards:
  - Strict mode compliance
  - No 'any' types
  - Proper type annotations
  - Type safety in edge cases

  Code Quality:
  - Clear naming
  - DRY (no duplication)
  - SOLID principles
  - Appropriate abstractions
  - Error handling

  Security:
  - SQL injection vulnerabilities
  - Command injection risks
  - Path traversal
  - Hardcoded secrets

  Performance:
  - O(n) complexity acceptable
  - No unnecessary iterations
  - Efficient database queries

  Fail if:
  - Security vulnerabilities found
  - Uses 'any' type
  - Missing error handling
  - Performance issues

  Return JSON with pass/fail and specific issues.`,
  tools: ['Read', 'Grep', 'Bash'],
  model: 'claude-sonnet-4-5',
};

export const validatorSubagents = {
  'test-quality-validator': testQualityValidator,
  'code-quality-validator': codeQualityValidator,
};
```

## Step 3: Invoking Subagents

### 3.1 Single Subagent Invocation

Create `src/agents/orchestration/invoke.ts`:

```typescript
import { query } from '@anthropic-ai/claude-agent-sdk';

export interface SubagentConfig {
  agents: Record<string, any>;
  mcpServers?: Record<string, any>;
}

/**
 * Invokes a single subagent and returns response
 */
export async function invokeSubagent(
  agentName: string,
  prompt: string,
  config: SubagentConfig
): Promise<string> {
  console.log(`→ Invoking: ${agentName}`);

  const response = query({
    prompt,
    options: {
      model: 'claude-sonnet-4-5',
      agents: config.agents,
      mcpServers: config.mcpServers,
      apiKey: process.env.ANTHROPIC_API_KEY,
    },
  });

  let fullResponse = '';

  for await (const message of response) {
    if (message.type === 'system' && message.subtype === 'subagent_start') {
      console.log(`  ▸ Started: ${message.agent_name}`);
    }

    if (message.type === 'text') {
      fullResponse += message.text;
    }

    if (message.type === 'system' && message.subtype === 'subagent_end') {
      console.log(`  ✓ Completed: ${message.agent_name}`);
    }
  }

  return fullResponse;
}
```

**Example usage**:

```typescript
import { invokeSubagent } from './orchestration/invoke';
import { implementationSubagents } from './subagents/implementation';

const hookCode = await invokeSubagent(
  'hook-developer',
  'Implement UserPromptSubmit hook that queues events in < 100ms',
  { agents: implementationSubagents }
);
```

### 3.2 Parallel Execution

```typescript
/**
 * Runs multiple independent subagents in parallel
 */
export async function runParallel(
  tasks: Array<{ agent: string; prompt: string }>,
  config: SubagentConfig
): Promise<string[]> {
  console.log(`Running ${tasks.length} subagents in parallel`);

  const promises = tasks.map((task) =>
    invokeSubagent(task.agent, task.prompt, config)
  );

  return Promise.all(promises);
}
```

**Example usage** (implement hooks + tests simultaneously):

```typescript
const [hookCode, hookTests] = await runParallel(
  [
    {
      agent: 'hook-developer',
      prompt: 'Implement UserPromptSubmit hook',
    },
    {
      agent: 'unit-test-generator',
      prompt: 'Generate tests for UserPromptSubmit hook',
    },
  ],
  {
    agents: { ...implementationSubagents, ...testGeneratorSubagents },
  }
);
```

### 3.3 Sequential with Dependencies

```typescript
/**
 * Runs subagents in sequence, passing results forward
 */
export async function runSequential(
  steps: Array<{
    agent: string;
    promptTemplate: (results: string[]) => string;
  }>,
  config: SubagentConfig
): Promise<string[]> {
  const results: string[] = [];

  for (const step of steps) {
    const prompt = step.promptTemplate(results);
    const result = await invokeSubagent(step.agent, prompt, config);
    results.push(result);
  }

  return results;
}
```

**Example usage** (TDD Red-Green-Refactor):

```typescript
const [test, implementation, validation] = await runSequential(
  [
    {
      agent: 'unit-test-generator',
      promptTemplate: () => 'Generate test for sanitizeApiKeys(text)',
    },
    {
      agent: 'sanitization-developer',
      promptTemplate: (results) =>
        `Implement minimal code to pass:\n\n${results[0]}`,
    },
    {
      agent: 'code-quality-validator',
      promptTemplate: (results) =>
        `Validate:\n\nTest: ${results[0]}\n\nCode: ${results[1]}`,
    },
  ],
  {
    agents: {
      ...testGeneratorSubagents,
      ...implementationSubagents,
      ...validatorSubagents,
    },
  }
);
```

## Step 4: Real-World Patterns

### 4.1 Implement Feature with Quality Gates

Create `src/agents/workflows/implement-feature.ts`:

```typescript
import { runSequential } from '../orchestration/invoke';
import {
  implementationSubagents,
  testGeneratorSubagents,
  validatorSubagents,
} from '../subagents';

export async function implementFeature(
  featureDescription: string
): Promise<{
  test: string;
  implementation: string;
  qualityScore: number;
}> {
  console.log('=== Implementing Feature with Quality Gates ===');

  const [test, implementation, qualityReport] = await runSequential(
    [
      // RED: Generate test
      {
        agent: 'unit-test-generator',
        promptTemplate: () => `Generate comprehensive tests for: ${featureDescription}`,
      },

      // GREEN: Implement
      {
        agent: 'sanitization-developer', // Use appropriate implementation agent
        promptTemplate: (results) =>
          `Implement minimal code to pass these tests:\n\n${results[0]}`,
      },

      // VALIDATE: Quality gate
      {
        agent: 'code-quality-validator',
        promptTemplate: (results) =>
          `Validate implementation:\n\nTests: ${results[0]}\n\nCode: ${results[1]}`,
      },
    ],
    {
      agents: {
        ...testGeneratorSubagents,
        ...implementationSubagents,
        ...validatorSubagents,
      },
    }
  );

  // Parse quality score from report
  const qualityData = JSON.parse(qualityReport);

  if (qualityData.score < 0.8) {
    throw new Error(
      `Quality gate failed: ${qualityData.score}\nIssues: ${qualityData.issues.join(', ')}`
    );
  }

  return {
    test,
    implementation,
    qualityScore: qualityData.score,
  };
}
```

### 4.2 Parallel Validation

```typescript
/**
 * Runs multiple validators in parallel
 */
export async function validateQuality(
  testCode: string,
  implCode: string
): Promise<{
  testQuality: number;
  codeQuality: number;
  passed: boolean;
}> {
  const [testReport, codeReport] = await runParallel(
    [
      {
        agent: 'test-quality-validator',
        prompt: `Validate test quality:\n\n${testCode}`,
      },
      {
        agent: 'code-quality-validator',
        prompt: `Validate code quality:\n\n${implCode}`,
      },
    ],
    { agents: validatorSubagents }
  );

  const testQuality = JSON.parse(testReport).score;
  const codeQuality = JSON.parse(codeReport).score;

  return {
    testQuality,
    codeQuality,
    passed: testQuality >= 0.8 && codeQuality >= 0.8,
  };
}
```

## Step 5: Monitoring and Debugging

### 5.1 Subagent Progress Logging

```typescript
export async function invokeWithLogging(
  agentName: string,
  prompt: string,
  config: SubagentConfig
): Promise<string> {
  const startTime = Date.now();

  console.log(`[${new Date().toISOString()}] Starting: ${agentName}`);
  console.log(`Prompt length: ${prompt.length} chars`);

  const response = await invokeSubagent(agentName, prompt, config);

  const duration = Date.now() - startTime;
  console.log(`[${new Date().toISOString()}] Completed in ${duration}ms`);
  console.log(`Response length: ${response.length} chars`);

  return response;
}
```

### 5.2 Error Context

```typescript
export async function safeInvoke(
  agentName: string,
  prompt: string,
  config: SubagentConfig
): Promise<string> {
  try {
    return await invokeSubagent(agentName, prompt, config);
  } catch (error) {
    console.error('Subagent failed:', {
      agent: agentName,
      promptPreview: prompt.substring(0, 100),
      error: error instanceof Error ? error.message : String(error),
    });
    throw error;
  }
}
```

## Verification

Create `src/agents/test-subagents.ts`:

```typescript
import { config } from 'dotenv';
import { implementFeature } from './workflows/implement-feature';

config();

async function main() {
  const result = await implementFeature(
    'Function sanitizeApiKeys(text: string): string that redacts API keys'
  );

  console.log('\n=== Results ===');
  console.log('Quality Score:', result.qualityScore);
  console.log('\nTest:\n', result.test);
  console.log('\nImplementation:\n', result.implementation);
}

main();
```

```bash
ts-node src/agents/test-subagents.ts
```

## You're Done When...

- ✅ Understand when to delegate vs implement
- ✅ Can define effective subagent configurations
- ✅ Can invoke subagents with proper error handling
- ✅ Understand parallel and sequential patterns
- ✅ Can monitor subagent progress
- ✅ Have working examples of all patterns

## Best Practices

1. **Specific Prompts**: Give clear, detailed instructions
2. **Appropriate Tools**: Match tools to tasks
3. **Error Handling**: Always wrap in try-catch
4. **Logging**: Track invocations and timing
5. **Validation**: Use quality gates consistently
6. **Parallel When Possible**: Independent tasks run together
7. **Sequential When Dependent**: Pass results forward

## Next Steps

- [Testing Harness Usage](./guide-testing-harness-usage-2025-01-16.md) - AI-powered testing
- [TDD Workflow Guide](./guide-tdd-workflow-2025-01-16.md) - Test-driven development
- [Phase 1 Hook Development](./guide-phase-1-hook-development-2025-01-16.md) - Apply subagents to hooks

## Related Documents

- [Subagent System Architecture](../architecture/architecture-subagent-system-2025-01-16.md)
- [Claude Agent SDK Integration](./guide-claude-agent-sdk-integration-2025-01-16.md)
- [Implementation Roadmap](../plans/plan-implementation-roadmap-2025-01-16.md)

================
File: guides/INDEX.md
================
# Guides Documentation

> Last updated: 2025-01-16

## Overview

This directory contains step-by-step how-to guides for developing the Global Context Network MVP. Each guide is designed to be completed in < 2 hours with working code examples and verification steps.

## Quick Start Path

**Recommended Learning Order**:

```
1. Phase 0 Foundation Setup (90 min)
        ↓
2. Claude Agent SDK Integration (90 min)
        ↓
3. Using Subagents (90 min)
        ↓
4. Testing Harness Usage (120 min)
        ↓
5. TDD Workflow (90 min)
        ↓
6. Phase 1 Hook Development (150 min)
```

**Total Time**: ~10 hours to complete all guides

## Available Guides

| Date | Document | Time | Status | Description |
|------|----------|------|--------|-------------|
| 2025-01-16 | [guide-phase-0-foundation-setup-2025-01-16.md](./guide-phase-0-foundation-setup-2025-01-16.md) | 90 min | ✅ Ready | Set up TypeScript, Vitest, SQLite foundation |
| 2025-01-16 | [guide-claude-agent-sdk-integration-2025-01-16.md](./guide-claude-agent-sdk-integration-2025-01-16.md) | 90 min | ✅ Ready | Integrate Claude Agent SDK for subagent orchestration |
| 2025-01-16 | [guide-using-subagents-2025-01-16.md](./guide-using-subagents-2025-01-16.md) | 90 min | ✅ Ready | Delegate to specialized subagents effectively |
| 2025-01-16 | [guide-testing-harness-usage-2025-01-16.md](./guide-testing-harness-usage-2025-01-16.md) | 120 min | ✅ Ready | Use Claude-powered testing for AI-driven validation |
| 2025-01-16 | [guide-tdd-workflow-2025-01-16.md](./guide-tdd-workflow-2025-01-16.md) | 90 min | ✅ Ready | Master Red-Green-Refactor with subagents |
| 2025-01-16 | [guide-phase-1-hook-development-2025-01-16.md](./guide-phase-1-hook-development-2025-01-16.md) | 150 min | ✅ Ready | Implement Claude Code hooks for event capture |

## Guide Structure

Each guide follows a consistent format:

### 1. Overview
- What you'll learn
- Time to complete
- What you'll build

### 2. Prerequisites
- Required setup
- Prior guides to complete
- Knowledge requirements

### 3. Step-by-Step Instructions
- Numbered steps with clear goals
- Complete, copy-paste code examples
- Expected output shown
- Verification at each step

### 4. Troubleshooting
- Common issues and solutions
- OS-specific caveats
- Debugging tips

### 5. Verification
- "You're done when..." checklist
- How to verify everything works
- What to check

### 6. Next Steps
- Links to related guides
- What to learn next
- How to apply knowledge

## Guide Categories

### Foundation & Setup
- **Phase 0 Foundation Setup**: TypeScript project, Vitest, SQLite, linting
- **Claude Agent SDK Integration**: SDK installation, configuration, basic usage

### Development Patterns
- **Using Subagents**: Delegation patterns, parallel/sequential execution
- **TDD Workflow**: Red-Green-Refactor with AI validation
- **Testing Harness Usage**: AI-powered test generation and validation

### Feature Implementation
- **Phase 1 Hook Development**: Event capture with Claude Code hooks

## Learning Paths

### Path 1: Quick Start (Backend Developer)
If you're experienced with TypeScript/Node.js:

1. **Phase 0 Setup** (skim if familiar)
2. **Claude Agent SDK** (focus on query() API)
3. **Using Subagents** (core delegation patterns)
4. **Phase 1 Hooks** (apply to real feature)

**Time**: ~6 hours

### Path 2: Full TDD Journey
For comprehensive TDD mastery:

1. **Phase 0 Setup**
2. **Testing Harness Usage**
3. **TDD Workflow**
4. **Phase 1 Hooks** (applying TDD)

**Time**: ~7.5 hours

### Path 3: Subagent Expert
Deep dive into AI orchestration:

1. **Phase 0 Setup**
2. **Claude Agent SDK** (all patterns)
3. **Using Subagents** (parallel/sequential)
4. **Testing Harness** (MCP integration)
5. **TDD Workflow** (subagent-driven)

**Time**: ~8 hours

## Prerequisites by Guide

### Phase 0 Foundation Setup
- Node.js 18+
- Basic TypeScript knowledge
- Command line familiarity

### Claude Agent SDK Integration
- Phase 0 complete
- Anthropic API key
- Understanding of async/await

### Using Subagents
- Phase 0 complete
- Claude Agent SDK integrated
- Understanding of delegation patterns

### Testing Harness Usage
- Subagents guide complete
- Vitest installed
- MCP server basics

### TDD Workflow
- Testing harness complete
- Subagents guide complete
- Understanding of TDD concepts

### Phase 1 Hook Development
- Phase 0 complete
- TDD workflow understood
- Subagents guide complete

## Key Concepts Covered

### TypeScript & Tooling
- Strict mode configuration
- ESLint and Prettier setup
- Vitest test runner
- Type-safe database queries

### Claude Agent SDK
- query() API usage
- Subagent definitions
- Streaming responses
- MCP server integration
- Error handling and retry logic

### Testing
- Test-driven development
- AI-powered test generation
- Test quality validation
- Coverage requirements
- Integration and E2E testing

### Subagents
- Delegation patterns
- Parallel execution
- Sequential dependencies
- Quality gates
- Monitoring and debugging

### Claude Code Hooks
- Event capture
- Performance requirements (< 100ms)
- Fast sanitization
- Persistent queues
- Error handling

## Common Patterns

### Pattern 1: Generate Tests with Subagent

```typescript
const testCode = await invokeSubagent(
  'unit-test-generator',
  'Generate tests for sanitizeApiKeys(text)',
  { agents: testGeneratorSubagents }
);
```

### Pattern 2: Validate Quality

```typescript
const validation = await validateTestQuality('./test-file.ts');
if (!validation.passed) {
  throw new Error(`Quality gate failed: ${validation.score}`);
}
```

### Pattern 3: Parallel Execution

```typescript
const [impl, tests] = await runParallel(
  [
    { agent: 'code-writer', prompt: 'Implement feature' },
    { agent: 'test-generator', prompt: 'Generate tests' },
  ],
  config
);
```

### Pattern 4: TDD Cycle

```typescript
// RED: Generate failing test
const test = await generateTest(feature);

// GREEN: Implement minimal code
const impl = await implementFeature(test);

// REFACTOR: Improve quality
const refactored = await refactorCode(impl);
```

## Troubleshooting Resources

### Common Issues

**Issue**: TypeScript strict mode errors

**Solution**: See [Phase 0 Foundation Setup - Troubleshooting](./guide-phase-0-foundation-setup-2025-01-16.md#troubleshooting)

**Issue**: MCP server not connecting

**Solution**: See [Testing Harness Usage - Troubleshooting](./guide-testing-harness-usage-2025-01-16.md#troubleshooting)

**Issue**: Hooks too slow (> 100ms)

**Solution**: See [Phase 1 Hook Development - Troubleshooting](./guide-phase-1-hook-development-2025-01-16.md#troubleshooting)

## Related Categories

- [Architecture](../architecture/INDEX.md) - System design and component architecture
- [Plans](../plans/INDEX.md) - Implementation plans and roadmaps
- [Reference](../reference/INDEX.md) - Technical specifications and APIs
- [Decisions](../decisions/INDEX.md) - ADRs explaining choices

## Quick Reference

### Environment Variables

```bash
# Required for all guides
ANTHROPIC_API_KEY=sk-ant-xxxxx

# Database
DB_PATH=./data/context.db

# MCP Test Runner
MCP_TEST_RUNNER_URL=http://localhost:3000

# Logging
LOG_LEVEL=info
```

### Essential Commands

```bash
# Type checking
npm run typecheck

# Linting
npm run lint

# Tests
npm run test

# Coverage
npm run coverage

# Build
npm run build

# Database migrations
npm run db:migrate

# MCP Test Runner
npm run mcp:test-runner
```

### File Structure

```
project/
├── .claude/
│   └── hooks/           # Claude Code hooks
│       ├── hooks.json
│       ├── user-prompt-submit.ts
│       └── stop.ts
├── src/
│   ├── agents/          # Subagent configurations
│   │   ├── subagents/
│   │   ├── orchestration/
│   │   └── workflows/
│   ├── db/              # Database utilities
│   ├── queue/           # Event queue
│   ├── sanitization/    # PII redaction
│   ├── mcp/             # MCP servers
│   └── types/           # TypeScript types
├── tests/               # Test files
├── data/                # SQLite database
└── docs/                # Documentation
```

## Tips for Success

1. **Follow the order**: Guides build on each other
2. **Complete verification**: Check "You're done when..." sections
3. **Run all examples**: Don't skip code execution
4. **Use provided code**: Copy-paste to avoid typos
5. **Check expected output**: Verify results match
6. **Troubleshoot early**: Don't skip error checks
7. **Ask questions**: Reference architecture docs for deep dives

## Getting Help

If you're stuck:

1. Check the guide's **Troubleshooting** section
2. Review **Expected output** sections
3. Consult related **Architecture** documents
4. Review **Reference** documentation for APIs
5. Check **Decisions** for context on choices

## Contributing

When adding new guides:

1. Follow the standard structure
2. Include copy-paste code examples
3. Show expected outputs
4. Add verification steps
5. Include troubleshooting section
6. Link to related documents
7. Update this INDEX.md
8. Test all code examples work

## Naming Convention

```
guide-{topic}-YYYY-MM-DD.md
```

Examples:
- `guide-phase-0-foundation-setup-2025-01-16.md`
- `guide-using-subagents-2025-01-16.md`
- `guide-tdd-workflow-2025-01-16.md`

---

*These guides are designed to be beginner-friendly while maintaining professional depth. Complete them in order for the best learning experience.*

================
File: plans/INDEX.md
================
# Plans Documentation

> Last updated: 2025-01-16

## Overview

This directory contains implementation plans, task breakdowns, and roadmaps for the Global Context Network MVP. All plans follow a subagent-driven development approach with Claude-powered testing.

## Master Plans

| Date | Document | Status | Description |
|------|----------|--------|-------------|
| 2025-01-16 | [plan-global-context-network-mvp-2025-01-16.md](./plan-global-context-network-mvp-2025-01-16.md) | Active | Complete MVP implementation plan overview |
| 2025-01-16 | [plan-implementation-roadmap-2025-01-16.md](./plan-implementation-roadmap-2025-01-16.md) | Active | 7-phase roadmap with timeline and dependencies |
| 2025-01-16 | [plan-subagent-workflow-2025-01-16.md](./plan-subagent-workflow-2025-01-16.md) | Active | How specialized subagents work together |
| 2025-01-16 | [plan-original-user-vision-2025-01-16.md](./plan-original-user-vision-2025-01-16.md) | Active | User's original concept and requirements |

## Phase-Specific Task Plans

| Phase | Focus | Duration | Document | Status |
|-------|-------|----------|----------|--------|
| 0 | Foundation | 2-3 days | [plan-phase-0-tasks-2025-01-16.md](./plan-phase-0-tasks-2025-01-16.md) | Planned |
| 1 | Event Capture | 3-4 days | [plan-phase-1-tasks-2025-01-16.md](./plan-phase-1-tasks-2025-01-16.md) | Planned |
| 2 | Sanitization | 7-10 days | [plan-phase-2-tasks-2025-01-16.md](./plan-phase-2-tasks-2025-01-16.md) | Planned |
| 3 | Database | 2-3 days | [plan-phase-3-tasks-2025-01-16.md](./plan-phase-3-tasks-2025-01-16.md) | Planned |
| 4 | Async Processing | 5-7 days | [plan-phase-4-tasks-2025-01-16.md](./plan-phase-4-tasks-2025-01-16.md) | Planned |
| 5 | Learning Extraction | 6-8 days | [plan-phase-5-tasks-2025-01-16.md](./plan-phase-5-tasks-2025-01-16.md) | Planned |
| 6 | MCP Server | 3-4 days | [plan-phase-6-tasks-2025-01-16.md](./plan-phase-6-tasks-2025-01-16.md) | Planned |
| 7 | Mining & Upload | 4-10 days | [plan-phase-7-tasks-2025-01-16.md](./plan-phase-7-tasks-2025-01-16.md) | MVP+ |

## Total Plan Documents

**Count**: 11 documents (4 master plans + 7 phase plans)

## Key Implementation Principles

### Subagent-Driven Development
- All implementation delegated to specialized subagents
- Implementation, test generation, and validation subagents
- Parallel execution where possible
- Quality gates enforced automatically

### Test-Driven Development (TDD)
- Tests generated first (Red phase)
- Minimal implementation (Green phase)
- Refactor for quality (Refactor phase)
- Automated quality gates

### Privacy-First Architecture
- Pre-sanitize in hooks before any persistence
- Full sanitization before final storage
- Gold dataset with precision/recall metrics
- Zero plaintext raw data on disk
- Chain-of-thought excluded

### Quality Gates
- ≥ 85% test coverage
- Precision ≥ 98% per PII category
- Recall ≥ 95% per PII category
- Performance SLOs met (hooks < 100ms, queries < 100ms, MCP < 200ms)
- Security scan clean
- Lint + type-check passing

## Timeline Summary

**Total Duration**: 7-9 weeks (with 15-20% buffer)

### Week 1
- Phase 0: Foundation (days 1-3)
- Phase 1: Event Capture (days 4-7)

### Week 2-3
- Phase 2: Sanitization Pipeline (7-10 days)

### Week 3
- Phase 3: Database & Storage (2-3 days)

### Week 4
- Phase 4: Async Processing (5-7 days)

### Weeks 4-5
- Phase 5: Learning Extraction (6-8 days)

### Weeks 5-6
- Phase 6: MCP Server (3-4 days)

### Weeks 6-9 (MVP+)
- Phase 7: Mining & Upload (4-10 days, optional for MVP)

## Phase Dependencies

```
Phase 0 (Foundation)
    ↓
Phase 1 (Event Capture)
    ↓
Phase 2 (Sanitization)
    ↓
Phase 3 (Database)
    ↓
Phase 4 (Async Processing)
    ↓
Phase 5 (Learning Extraction)
    ↓
Phase 6 (MCP Server)
    ↓
Phase 7 (Mining & Upload) [MVP+]
```

## Critical Milestones

1. **Local Capture** (End of Week 1): Hooks working, events captured
2. **Privacy Guarantee** (End of Week 3): PII sanitization validated
3. **Persistent Learnings** (End of Week 5): Learnings extracted and stored
4. **Query Interface** (End of Week 6): MCP server accessible to agents
5. **Global Network** (Week 7-9): IPFS + blockchain integration [MVP+]

## MVP vs MVP+ Scope

### Core MVP (Weeks 1-6)
- ✅ Event capture via hooks
- ✅ PII sanitization with metrics
- ✅ Database storage
- ✅ Async job processing
- ✅ Learning extraction
- ✅ MCP query interface
- ✅ Local cross-project sharing

**Value**: Privacy-first learning capture and local sharing

### MVP+ (Weeks 7-9)
- ✅ IPFS upload
- ✅ Blockchain integration
- ✅ Token reward tracking
- ✅ Global network sharing

**Value**: Global sharing with incentives

## GPT-5 Review Feedback Incorporated

This implementation plan incorporates comprehensive feedback from GPT-5 review on:

### Critical Issues Addressed
1. **Privacy Contradiction Resolved**: Pre-sanitization in hooks before any persistence
2. **Gold Dataset**: 1000+ labeled PII examples with precision/recall thresholds per category
3. **Chain-of-Thought Exclusion**: Never stored, even sanitized
4. **Timeline Adjusted**: 7-10 days for sanitization (was 4-5), Phase 7 marked as MVP+
5. **Acceptance Criteria Clarified**: Measurable, automated, per-category metrics

### Enhanced Task Breakdowns
1. **Phase 1**: Added event schema, correlation IDs, idempotency, backpressure, cross-platform support
2. **Phase 2**: Enumerated exact PII categories, redaction formats, AI prompt templates, adversarial tests
3. **Phase 3**: Added migration versioning, data retention, purge policies, vacuum schedule
4. **Phase 4**: Added locking strategy, idempotency design, checkpoint/resume, chaos tests
5. **Phase 5**: Specified extraction approach, dedup strategy, negative set, human review process
6. **Phase 6**: Added auth model, pagination, rate limiting, input validation
7. **Phase 7**: Clarified smart contract vs simple registry, key management, user controls

### New Testing Requirements
1. **Performance**: p95/p99 latencies under load with concurrent clients
2. **Reliability**: Crash recovery, DB locked, disk full, concurrent writers
3. **Security**: Adversarial PII tests, prompt injection, SQLi prevention, log redaction
4. **Metrics**: Per-category precision/recall, F1 scores, gold dataset scoring

## Related Categories

- [Architecture](../architecture/INDEX.md) - System design and components
- [Decisions](../decisions/INDEX.md) - Architecture Decision Records
- [Guides](../guides/INDEX.md) - How-to documentation
- [Reference](../reference/INDEX.md) - Technical specifications

## Using These Plans

### For Implementation
1. Start with [MVP Plan](./plan-global-context-network-mvp-2025-01-16.md) for overview
2. Review [Implementation Roadmap](./plan-implementation-roadmap-2025-01-16.md) for timeline
3. Understand [Subagent Workflow](./plan-subagent-workflow-2025-01-16.md) for process
4. Execute phase-specific task plans in order

### For Understanding Scope
1. Read [Original User Vision](./plan-original-user-vision-2025-01-16.md) for context
2. Review phase plans to understand effort required
3. Check timeline and dependencies for scheduling

### For Quality Assurance
1. Follow TDD workflow in [Subagent Workflow](./plan-subagent-workflow-2025-01-16.md)
2. Enforce quality gates documented in each phase plan
3. Use acceptance criteria to validate completeness

---

*All plans follow the subagent-driven development model with Claude-powered testing harness. Each phase includes detailed tasks, success criteria, testing strategy, and clear dependencies.*

================
File: plans/plan-global-context-network-mvp-2025-01-16.md
================
# Global Context Network MVP - Complete Implementation Plan

> Comprehensive plan for building the Global Context Network using Claude Agent SDK and subagent-driven development

---
title: Global Context Network MVP Implementation Plan
category: plan
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [mvp, implementation, roadmap, blockchain, learning-network]
---

## Goal

Build a production-ready MVP that captures Claude Code conversations, sanitizes PII, extracts learnings, and uploads them to a global network with token rewards - all using subagent-driven development and Claude-powered testing.

## Background

The Global Context Network addresses a critical problem: valuable learnings from AI-assisted development are lost to individual conversations. This MVP creates a privacy-first system that:

1. Captures all Claude Code interactions via hooks
2. Sanitizes PII before any storage
3. Extracts valuable, reusable learnings
4. Shares learnings globally via IPFS + blockchain
5. Rewards quality contributions with tokens
6. Enables agents to query learnings via MCP

**Unique Innovation**: "Mining through learning" - users earn tokens by contributing quality learnings, not computational work.

## Approach

### Development Philosophy

**Subagent-Driven Development**: ALL implementation delegated to specialized Claude agents
- Implementation subagents build features
- Test subagents generate and validate tests
- Quality gate subagents enforce standards
- Integration subagents verify workflows

**Claude Testing Harness**: Self-validating system using Claude Agent SDK
- Tests generated first (TDD)
- Implementation validated automatically
- Quality gates enforced at every step
- No manual testing required

**Privacy-First Architecture**: Zero-trust PII handling
- Sanitize BEFORE database storage
- Hybrid approach (rules + AI)
- Audit all redactions
- Never store raw data

### Technology Stack

| Layer | Technology | Rationale |
|-------|-----------|-----------|
| Runtime | Node.js + TypeScript | Type safety, async-first |
| Database | SQLite | Simple, embedded, ACID |
| Testing | Vitest | Fast, modern, TypeScript-first |
| Sanitization | Regex + Claude API | Hybrid approach |
| MCP Server | @modelcontextprotocol/sdk | Standard protocol |
| Blockchain | TBD (Ethereum/Celestia) | EVM compatibility |
| Storage | IPFS | Decentralized, content-addressed |
| Queue | SQLite-based | Simple, persistent |

## Implementation Phases

### Phase 0: Foundation (Week 1)
**Goal**: TypeScript project, database schema, test infrastructure

- [ ] TypeScript project setup with strict mode
- [ ] Vitest testing framework configuration
- [ ] ESLint + Prettier setup
- [ ] Database schema design and migrations
- [ ] Test utilities and helpers
- [ ] CI/CD pipeline configuration

**Success Criteria**:
- TypeScript compiles with no errors
- Vitest runs and reports correctly
- Database migrations work bidirectionally
- All code passes linting

**Duration**: 2-3 days

### Phase 1: Event Capture (Week 1-2)
**Goal**: Hook into Claude Code and capture conversations

- [ ] UserPromptSubmit hook implementation
- [ ] Stop hook implementation
- [ ] Event collector to aggregate events
- [ ] Persistent event queue (SQLite-based)
- [ ] Hook performance monitoring (< 100ms)
- [ ] Error handling (never block user)

**Success Criteria**:
- Hooks execute in < 100ms
- Events persisted across restarts
- Zero user-blocking errors
- Complete conversation capture

**Duration**: 3-4 days

### Phase 2: Sanitization Pipeline (Week 2-3)
**Goal**: Remove ALL PII before database storage

- [ ] Rule-based PII detector (regex patterns)
- [ ] AI-powered sanitizer (Claude API)
- [ ] Hybrid validation pipeline
- [ ] Sanitization audit logger
- [ ] Test suite with 1000+ PII cases
- [ ] Performance optimization (< 2s per conversation)

**Success Criteria**:
- Zero PII leaks in test suite
- < 1% false positive rate (rules)
- < 5% false negative rate (AI)
- All redactions audited

**Duration**: 4-5 days

### Phase 3: Database & Storage (Week 3)
**Goal**: Persist sanitized data with ACID guarantees

- [ ] Repository pattern implementation
- [ ] Conversation table with indexes
- [ ] Messages table with relationships
- [ ] Learnings table with scoring
- [ ] Job queue table
- [ ] Query optimization (< 100ms)

**Success Criteria**:
- All queries < 100ms
- ACID compliance verified
- Migrations reversible
- Proper indexing

**Duration**: 2-3 days

### Phase 4: Async Processing (Week 4)
**Goal**: Background job processing without blocking

- [ ] Job queue implementation
- [ ] Worker process architecture
- [ ] Retry logic with exponential backoff
- [ ] Dead letter queue for failures
- [ ] Job status tracking
- [ ] Graceful shutdown handling

**Success Criteria**:
- Jobs never lost
- Proper retry on failures
- Workers scale independently
- Clean shutdown/restart

**Duration**: 3-4 days

### Phase 5: Learning Extraction (Week 4-5)
**Goal**: Extract valuable, reusable learnings

- [ ] Conversation analyzer (value detection)
- [ ] Category-specific extractors
- [ ] Quality scoring algorithm
- [ ] Deduplication logic
- [ ] Learning categorization
- [ ] Confidence threshold tuning

**Success Criteria**:
- Confidence scores ≥ 0.6
- Proper categorization
- No duplicate learnings
- Valuable insights extracted

**Duration**: 4-5 days

### Phase 6: MCP Server (Week 5-6)
**Goal**: Enable agents to query learnings

- [ ] MCP protocol server setup
- [ ] search_learnings tool implementation
- [ ] get_learning_by_id tool
- [ ] get_learning_context tool
- [ ] Resource endpoints (recent, top-rated)
- [ ] Query performance (< 200ms)

**Success Criteria**:
- MCP protocol compliant
- All queries < 200ms
- Proper error handling
- Claude Code integration

**Duration**: 3-4 days

### Phase 7: Mining & Upload (Week 6-7)
**Goal**: Upload to global network with rewards

- [ ] IPFS client integration
- [ ] Content upload to IPFS
- [ ] CID generation and tracking
- [ ] Blockchain integration
- [ ] Token reward calculation
- [ ] Upload status tracking

**Success Criteria**:
- Successful IPFS uploads
- CIDs properly stored
- Blockchain transactions confirmed
- Token rewards tracked

**Duration**: 4-5 days

## Testing Strategy

### Test Pyramid

- **70% Unit Tests**: Isolated component testing
- **20% Integration Tests**: Component interactions
- **10% E2E Tests**: Full system workflows

### Critical Coverage Areas

1. **Sanitization**: 1000+ PII test cases, zero leaks
2. **Hooks**: Non-blocking, error handling, performance
3. **Queue**: No job loss, proper ordering, retry logic
4. **Database**: ACID compliance, concurrency, migrations
5. **MCP**: Protocol compliance, performance, error handling

### Quality Gates

**Before ANY commit**:
- [ ] All tests pass
- [ ] Lint passes
- [ ] Type check passes
- [ ] Coverage ≥ 85%
- [ ] No security vulnerabilities

## Risks & Mitigations

### High-Priority Risks

**Risk**: PII leakage
- **Impact**: Critical - destroys user trust
- **Mitigation**: Sanitize before storage, 1000+ test cases, audit logging
- **Validation**: GPT-5 review of sanitization logic

**Risk**: Hook performance blocking user
- **Impact**: High - ruins UX
- **Mitigation**: < 100ms requirement, performance monitoring, fail-silent
- **Validation**: Load testing with realistic conversations

**Risk**: Job queue failures losing data
- **Impact**: High - learnings lost
- **Mitigation**: Persistent queue, retry logic, dead letter queue
- **Validation**: Chaos testing (kill workers, simulate failures)

### Medium-Priority Risks

**Risk**: Learning quality too low
- **Impact**: Medium - network value diminished
- **Mitigation**: Quality scoring, confidence thresholds, test data validation
- **Validation**: Manual review of extracted learnings

**Risk**: MCP server performance
- **Impact**: Medium - poor agent experience
- **Mitigation**: Query optimization, indexing, caching
- **Validation**: Load testing with concurrent queries

**Risk**: Blockchain integration complexity
- **Impact**: Medium - delays MVP
- **Mitigation**: Use established libraries, testnet first, defer if needed
- **Validation**: Incremental integration with fallback

## Success Criteria

### Functional Requirements

- ✅ **Event Capture**: All conversations captured via hooks
- ✅ **Privacy**: Zero PII leaks (validated by test suite)
- ✅ **Storage**: Sanitized data persisted in SQLite
- ✅ **Learning Extraction**: Quality learnings extracted
- ✅ **Query Interface**: MCP server accessible from Claude Code
- ✅ **Network Upload**: Learnings uploaded to IPFS/blockchain
- ✅ **Token Rewards**: Rewards tracked and distributed

### Performance Requirements

- ✅ Hook execution: < 100ms
- ✅ Event queueing: < 50ms
- ✅ Sanitization: < 2s per conversation
- ✅ Database queries: < 100ms
- ✅ MCP queries: < 200ms
- ✅ Learning extraction: < 5s per conversation

### Quality Requirements

- ✅ Test coverage: ≥ 85%
- ✅ TypeScript strict mode: 100% compliance
- ✅ PII test suite: 1000+ cases, zero leaks
- ✅ Documentation: All components documented
- ✅ Error handling: Graceful degradation everywhere

### User Experience Requirements

- ✅ Transparent to workflow (no blocking)
- ✅ Easy to query learnings via MCP
- ✅ Trust in privacy guarantees
- ✅ Learnings actually useful
- ✅ No performance impact on Claude Code

## Timeline

### Week 1
- Days 1-3: Phase 0 (Foundation)
- Days 4-7: Phase 1 (Event Capture)

### Week 2
- Days 1-4: Phase 1 completion
- Days 5-7: Phase 2 (Sanitization) start

### Week 3
- Days 1-2: Phase 2 completion
- Days 3-5: Phase 3 (Database)

### Week 4
- Days 1-4: Phase 4 (Async Processing)
- Days 5-7: Phase 5 (Learning Extraction) start

### Week 5
- Days 1-2: Phase 5 completion
- Days 3-7: Phase 6 (MCP Server)

### Week 6
- Days 1-2: Phase 6 completion
- Days 3-7: Phase 7 (Mining & Upload)

### Week 7
- Days 1-2: Phase 7 completion
- Days 3-5: Integration testing
- Days 6-7: Documentation and polish

**Total**: 7 weeks

## Dependencies

### External Dependencies
- Claude Code (hooks support)
- Claude API (sanitization)
- IPFS node/gateway
- Blockchain network (testnet initially)

### Internal Dependencies
- Phase 0 → All other phases (foundation)
- Phase 1 → Phase 2 (events to sanitize)
- Phase 2 → Phase 3 (sanitized data to store)
- Phase 3 → Phase 4 (storage for jobs)
- Phase 4 → Phase 5 (async processing for extraction)
- Phase 5 → Phase 6 (learnings to query)
- Phase 6 → Phase 7 (MCP for status)

## Post-MVP Enhancements

### Near-Term (Months 1-3)
- Semantic search for learnings
- Learning recommendations
- User feedback on learning quality
- Enhanced categorization

### Medium-Term (Months 3-6)
- Validator network (multi-agent validation)
- Quorum-based consensus
- Advanced token economics
- Multi-user support

### Long-Term (Months 6+)
- Distributed storage
- Advanced analytics
- Trend analysis
- Community curation tools

## Related Documents

### Architecture
- [Global Context Network Architecture](../architecture/architecture-global-context-network-2025-01-16.md)
- [Subagent System Architecture](../architecture/architecture-subagent-system-2025-01-16.md)
- [Testing Harness Architecture](../architecture/architecture-testing-harness-2025-01-16.md)

### Plans
- [Implementation Roadmap](./plan-implementation-roadmap-2025-01-16.md)
- [Subagent Workflow](./plan-subagent-workflow-2025-01-16.md)
- [Phase-Specific Plans](./plan-phase-0-tasks-2025-01-16.md)

### Decisions
- [ADR: Subagent-Driven Development](../decisions/decision-subagent-driven-development-2025-01-16.md)
- [ADR: Claude Testing Harness](../decisions/decision-claude-testing-harness-2025-01-16.md)
- [ADR: Sanitize Before Storage](../decisions/decision-sanitize-before-storage-2025-01-16.md)

### Guides
- [Using Subagents](../guides/guide-using-subagents-2025-01-16.md)
- [TDD Workflow](../guides/guide-tdd-workflow-2025-01-16.md)
- [Testing Harness Usage](../guides/guide-testing-harness-usage-2025-01-16.md)

---

*This plan serves as the master implementation roadmap for the Global Context Network MVP. All phase-specific plans reference and detail this high-level overview.*

================
File: plans/plan-implementation-roadmap-2025-01-16.md
================
# Implementation Roadmap - Global Context Network MVP

> 7-phase implementation roadmap with timeline and dependencies

---
title: Global Context Network Implementation Roadmap
category: plan
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [roadmap, timeline, phases, dependencies]
---

## Overview

This document provides the complete implementation roadmap for the Global Context Network MVP, broken down into 7 phases with clear dependencies, deliverables, and success criteria.

**Total Duration**: 7-9 weeks (with 15-20% buffer for integration and testing)

**Development Approach**: Subagent-driven development with Claude-powered testing harness

## Roadmap Summary

| Phase | Focus | Duration | Deliverables | Status |
|-------|-------|----------|--------------|--------|
| 0 | Foundation | 2-3 days | TypeScript setup, DB schema, test infrastructure | Planned |
| 1 | Event Capture | 3-4 days | Hooks, event queue, correlation IDs | Planned |
| 2 | Sanitization | 7-10 days | Rule + AI sanitizer, gold dataset, metrics | Planned |
| 3 | Database & Storage | 2-3 days | Repository pattern, migrations, indexes | Planned |
| 4 | Async Processing | 5-7 days | Job queue, workers, idempotency | Planned |
| 5 | Learning Extraction | 6-8 days | Extractors, dedup, quality scoring | Planned |
| 6 | MCP Server | 3-4 days | MCP protocol, query tools, resources | Planned |
| 7 | Mining & Upload | 4-10 days | IPFS upload, blockchain integration | MVP+ |

## Phase Dependencies

```
Phase 0 (Foundation)
    ↓
Phase 1 (Event Capture)  ←  Requires: Project setup, DB schema
    ↓
Phase 2 (Sanitization)   ←  Requires: Events to sanitize
    ↓
Phase 3 (Database)       ←  Requires: Sanitized data to store
    ↓
Phase 4 (Async Queue)    ←  Requires: Storage for jobs
    ↓
Phase 5 (Learning)       ←  Requires: Async processing
    ↓
Phase 6 (MCP Server)     ←  Requires: Learnings to query
    ↓
Phase 7 (Upload)         ←  Requires: Quality learnings
```

## Critical Path

**Week 1**: Phase 0 + Phase 1
**Weeks 2-3**: Phase 2 (Sanitization - critical for privacy)
**Week 3**: Phase 3 (Database)
**Week 4**: Phase 4 (Async Processing)
**Weeks 4-5**: Phase 5 (Learning Extraction)
**Weeks 5-6**: Phase 6 (MCP Server)
**Weeks 6-7+**: Phase 7 (Network Upload - MVP+)

## Key Milestones

### Milestone 1: Local Capture (End of Week 1)
- ✅ Hooks working and non-blocking
- ✅ Events persisted to queue
- ✅ TypeScript + Vitest running
- **Value**: Can capture conversations

### Milestone 2: Privacy Guarantee (End of Week 3)
- ✅ PII sanitization working
- ✅ Gold dataset with precision/recall metrics
- ✅ Zero plaintext raw data on disk
- **Value**: Trust in privacy

### Milestone 3: Persistent Learnings (End of Week 5)
- ✅ Learnings extracted and scored
- ✅ Database storing sanitized data
- ✅ Deduplication working
- **Value**: Learnings saved locally

### Milestone 4: Query Interface (End of Week 6)
- ✅ MCP server running
- ✅ Agents can query learnings
- ✅ Performance < 200ms
- **Value**: Cross-project sharing

### Milestone 5: Global Network (Week 7-9) - MVP+
- ✅ IPFS uploads working
- ✅ Blockchain integration
- ✅ Token tracking
- **Value**: Global sharing + rewards

## Timeline Details

### Week 1: Foundation + Event Capture

**Days 1-3: Phase 0**
- TypeScript project with strict mode
- Vitest configuration
- Database schema design
- Migration system
- Test utilities

**Days 4-7: Phase 1**
- UserPromptSubmit hook
- Stop hook
- Event collector
- Persistent queue (with pre-sanitization for privacy)
- Performance monitoring

**Deliverables**:
- `tsconfig.json` with strict settings
- `vitest.config.ts` configured
- Database migrations 001-004
- Hook scripts in `.claude/hooks/`
- Event queue implementation

**Acceptance Criteria**:
- TypeScript compiles with no errors
- All tests pass
- Hooks execute < 100ms (p95)
- Events persisted with correlation IDs

### Week 2-3: Sanitization Pipeline

**Days 1-3: Rule-Based Detector**
- PII regex patterns (emails, phones, IPs, paths, keys, URLs)
- Per-category unit tests
- Redaction format conventions
- Performance optimization

**Days 4-7: AI Sanitizer**
- Claude API integration
- Context-aware detection
- Prompt templates (temp=0 for determinism)
- Fallback to rules-only

**Days 8-10: Gold Dataset & Metrics**
- Build/adopt labeled PII dataset
- Precision/recall scoring harness
- Per-category thresholds (precision ≥ 98%, recall ≥ 95%)
- Adversarial test suite

**Deliverables**:
- Rule-based sanitizer with 20+ PII patterns
- AI sanitizer with prompt templates
- Gold dataset with 1000+ labeled examples
- Scoring harness with per-category metrics
- Audit logging system

**Acceptance Criteria**:
- Precision ≥ 98% per PII category
- Recall ≥ 95% per PII category
- No plaintext raw data on disk
- Sanitization < 2s per conversation
- Chain-of-thought excluded from storage

### Week 3: Database & Storage

**Days 1-2: Repository Pattern**
- Conversation repository
- Messages repository
- Learnings repository
- Job queue repository

**Days 3: Query Optimization**
- Indexes for common queries
- WAL mode enabled
- Foreign key constraints
- Concurrent writer tests

**Deliverables**:
- Repository implementations
- Migration scripts with versioning
- Query optimization indexes
- ACID compliance tests

**Acceptance Criteria**:
- All queries < 100ms
- No orphan messages (FK constraints enforced)
- Migrations reversible
- Concurrent writes don't corrupt data

### Week 4: Async Processing

**Days 1-3: Job Queue**
- SQLite-based queue
- Priority handling
- Job status tracking
- Advisory locks for concurrency

**Days 4-5: Workers**
- Worker process architecture
- Job idempotency (dedupe keys)
- Graceful shutdown
- Checkpoint/resume

**Days 6-7: Reliability**
- Exponential backoff retry
- Dead letter queue
- Crash recovery tests
- Chaos testing (DB locked, disk full)

**Deliverables**:
- Job queue implementation
- Worker processes for 3 job types
- Retry logic with backoff
- Monitoring and metrics

**Acceptance Criteria**:
- Jobs never lost
- Idempotent processing verified
- Graceful shutdown within 30s
- Crash recovery E2E tests pass

### Week 4-5: Learning Extraction

**Days 1-2: Conversation Analyzer**
- Value detection (is conversation worth learning from?)
- Category identification
- Quality pre-filtering

**Days 3-5: Extractors**
- Rule-based + LLM approach
- Category-specific extractors
- Metadata schema (tags, provenance, version)
- Prompt templates

**Days 6-8: Quality & Dedup**
- Confidence scoring (≥ 0.6 threshold)
- Deduplication (cosine similarity < 0.85)
- Negative set to prevent trivial learnings
- Human-in-the-loop sample review

**Deliverables**:
- Conversation analyzer
- 8 category extractors
- Quality scoring algorithm
- Deduplication system
- Sample review process

**Acceptance Criteria**:
- 90% of sample rated "useful" by reviewer
- No duplicate learnings (verified by similarity)
- Confidence scores calibrated
- Metadata complete with provenance

### Week 5-6: MCP Server

**Days 1-2: Protocol Setup**
- MCP SDK integration
- Server configuration
- Loopback binding (127.0.0.1)
- Optional API key auth

**Days 3-4: Tools Implementation**
- `search_learnings` with filters
- `get_learning_by_id`
- `get_learning_context`
- Input validation and bounds

**Days 5: Resources & Performance**
- Resource endpoints (recent, top-rated, stats)
- Query optimization
- Pagination and sorting
- Rate limiting

**Deliverables**:
- MCP server implementation
- 3 tools + 3 resources
- Authentication layer
- Performance tests

**Acceptance Criteria**:
- MCP protocol conformance tests pass
- All queries < 200ms
- Invalid queries rejected gracefully
- No data leaks via MCP

### Week 6-9: Mining & Upload (MVP+)

**Days 1-3: IPFS Integration**
- IPFS client setup (pinning provider vs self-hosted)
- Content upload implementation
- CID generation and tracking
- Retry logic

**Days 4-7: Blockchain Integration**
- Choose network (testnet first)
- Wallet generation and key management
- CID anchoring (simple registry or contract)
- Transaction confirmation

**Days 8-10: Token System (if time)**
- Reward calculation
- Upload status tracking
- User controls (opt-in, manual approval)
- License metadata

**Deliverables**:
- IPFS upload working
- Blockchain integration
- Key management system
- User controls

**Acceptance Criteria**:
- CID retrievable via 2+ gateways
- N confirmed blocks for on-chain record
- Keys stored securely (OS keychain)
- Manual approval gate before upload

## Risk Management

### Critical Risks

**PII Leakage** (Impact: Critical)
- Mitigation: Pre-sanitize in hook, gold dataset, audit logging
- Gates: Zero leaks in test suite, precision/recall thresholds

**Hook Performance** (Impact: High)
- Mitigation: < 100ms requirement, fast pre-sanitizer, monitoring
- Gates: p95/p99 latency tests, load testing

**Data Loss** (Impact: High)
- Mitigation: Idempotent jobs, persistent queue, crash recovery
- Gates: Chaos tests, concurrent writer tests

### Deferred Risks (Post-MVP)

- Validator network attacks
- Multi-user access control
- International PII patterns
- IP/licensing compliance

## Quality Gates

**Before Phase Completion**:
- [ ] All unit tests pass
- [ ] Integration tests pass
- [ ] Lint + type-check clean
- [ ] Coverage ≥ 85%
- [ ] Performance SLOs met
- [ ] Security scan clean
- [ ] Documentation updated

**Before MVP Release**:
- [ ] E2E tests pass
- [ ] Privacy audit complete (zero PII leaks)
- [ ] Performance benchmarks met
- [ ] User controls working (opt-in, delete)
- [ ] Installation guide complete
- [ ] Monitoring/logging working

## Parallel Work Opportunities

### Week 1
- Phase 0 foundation (sequential)
- Phase 1 hooks can be prototyped in parallel

### Week 2-3
- Rule-based sanitizer (parallel track 1)
- AI sanitizer (parallel track 2)
- Gold dataset creation (parallel track 3)

### Week 4
- Job queue (parallel track 1)
- Workers (parallel track 2, depends on queue)

### Week 5-6
- Learning extraction refinement
- MCP server implementation (can start earlier)

## Post-MVP Roadmap

### Months 1-3
- Semantic search for learnings
- Enhanced categorization
- User feedback loops
- Analytics dashboard

### Months 3-6
- Validator network (multi-agent)
- Quorum-based consensus
- Advanced token economics
- Multi-user support

### Months 6+
- Distributed storage
- Trend analysis
- Community curation
- Mobile support

## Related Documents

- [MVP Plan](./plan-global-context-network-mvp-2025-01-16.md)
- [Subagent Workflow](./plan-subagent-workflow-2025-01-16.md)
- [Phase 0 Tasks](./plan-phase-0-tasks-2025-01-16.md)
- [Phase 1 Tasks](./plan-phase-1-tasks-2025-01-16.md)
- [Phase 2 Tasks](./plan-phase-2-tasks-2025-01-16.md)
- [Phase 3 Tasks](./plan-phase-3-tasks-2025-01-16.md)
- [Phase 4 Tasks](./plan-phase-4-tasks-2025-01-16.md)
- [Phase 5 Tasks](./plan-phase-5-tasks-2025-01-16.md)
- [Phase 6 Tasks](./plan-phase-6-tasks-2025-01-16.md)
- [Phase 7 Tasks](./plan-phase-7-tasks-2025-01-16.md)

================
File: plans/plan-original-user-vision-2025-01-16.md
================
# Original User Vision - Global Context Network

> Capturing the user's original concept and requirements

---
title: Original User Vision for Global Context Network
category: plan
date: 2025-01-16
status: active
authors: Dennison (User) + Claude
tags: [vision, requirements, original-concept, blockchain, learning-network]
---

## User's Original Request

**Date**: 2025-01-16

### The Core Idea

*"I'm thinking about building a global context network for AI agents to learn from one another. Basically right now when I work through a project like when I'm doing a TypeScript development project there will be some sort of problem that I have to end up solving and working through with the agent. The learnings from this tend to just be lost to this specific project but I think it would be really interesting if these learnings could be shared with my other projects but also globally with everyone."*

### Unique Approach

*"It would be to use Claude Code hooks so to start with Claude Code so that before every prompt or before the LLM takes action we write to database my prompt and then when the LLM finishes action you know we write to the database everything that the LLM said and you know ideally all of their thinking processes and we do that for the entire conversation."*

### Privacy-First Design

*"There's a second step where another LLM takes out all the personally identifiable information so that's like API keys directories you know specific names of things so that we aren't leaking information and that could actually happen in the step before writing to the database just in case so we never have to worry about leaking data."*

### Decentralized Storage

*"Then we put that data on chain or we put it into IPFS and put a hash a pin of hash of it into the blockchain or we could put it into something like Celestia for example so it goes from the agent itself working through sanitation for private information into a database and then from a database into a global pool that's available for everyone."*

### Mining Through Learning

*"The process of providing it to this global pool would be sort of like a new-age version of cryptocurrency mining so by providing context to the pool you are effectively mining but you don't get the payout immediately because you could just stream junk from an LLM into this."*

### Validator Network

*"What we would have is validators there'd be a validator network which would be other agents who basically read this sort of context thread read this complete summary to digest learnings from it and decide whether or not this is a valid addition to the context pool."*

### Data Processing Pipeline

*"You have an agent that sanitizes the personal information before it goes into the database and then you have another agent that asynchronously summarizes the learnings of the process and then we store the learnings of the process into the global pool or maybe we store both."*

*"Then we have a validator network of agents which validate that this submission is good or you know contains good information or it seems valid basically it's like a eval running evals on this submitted data. You would need sort of like a quorum of agents to decide that it is valid and if it's valid then we distribute tokens out to the agent that provided it."*

### Query Interface

*"Now that information gets stored into the sort of global context database and we have a model context protocol server that agents can use when they start a process project where they can check this global database for learnings."*

*"So if you're familiar with context 7 which is basically database around docs this would essentially be like a database around learnings so we could share these learnings and effectively by doing that you are mining so you're providing learnings to the network and then the network is rewarding with tokens."*

## MVP Scope (User-Defined)

*"I would like to build an MVP of this and what I'm thinking of is hooks for Claude code that take both every prompt end prompt and then you know any context in between runs it through sanitization in a sub-agent probably with Claude code then stores it directly into a SQLite database."*

*"Then kicks off another async process so there's sort of like a queue of analyzing each chunk that comes in and you know updating an idea of the learnings that are going so that you know you don't have to remember you know you can close the window without losing all the learnings but each time you know you update there's some new learnings the learnings are stored in the database as well."*

*"And then after that it goes into another process async like a mining process it may be this like a miner that's running at the same time or just runs in the background because you were running in the first place and then that uploads it to the context Network."*

*"Then you have model context protocol which allows the ages to query that network and maybe potentially you know generate a key pair to collect funds."*

## Key Requirements Identified

### 1. Capture Layer
- ✅ Use Claude Code hooks
- ✅ Capture every user prompt (UserPromptSubmit)
- ✅ Capture every agent response (Stop)
- ✅ Include thinking processes if available
- ✅ Never block the user

### 2. Privacy Layer
- ✅ Sanitize BEFORE database storage
- ✅ Remove API keys
- ✅ Remove directory paths
- ✅ Remove specific names
- ✅ Use another agent for sanitization
- ✅ Never leak PII

### 3. Storage Layer
- ✅ SQLite database
- ✅ Store sanitized conversations
- ✅ Store extracted learnings
- ✅ Persist across window closes
- ✅ Queue-based processing

### 4. Learning Extraction
- ✅ Async processing
- ✅ Summarize learnings continuously
- ✅ Update as new chunks arrive
- ✅ Store learnings in database

### 5. Mining/Upload
- ✅ Background process
- ✅ Async upload to network
- ✅ IPFS or blockchain storage
- ✅ Token reward tracking

### 6. Query Interface
- ✅ Model Context Protocol server
- ✅ Allow agents to query learnings
- ✅ Key pair for fund collection
- ✅ Similar to Context7 for docs

### 7. Validator Network (Future)
- 🔮 Agent validators
- 🔮 Quality evaluation
- 🔮 Quorum-based validation
- 🔮 Token distribution on validation

## Design Principles Extracted

### Privacy-First
*"Sanitization happens before writing to database just in case so we never have to worry about leaking data."*

**Implementation**: Zero-trust PII handling with sanitization before storage.

### Async Everything
*"Kicks off another async process... a mining process... running in the background."*

**Implementation**: Job queue system with async workers for all processing.

### Never Lose Data
*"You can close the window without losing all the learnings."*

**Implementation**: Persistent queue and continuous learning extraction.

### Quality Through Validation
*"Validators... decide whether or not this is a valid addition."*

**Implementation**: Quality scoring and validator network (future).

### Incentive Alignment
*"By providing learnings to the network... the network is rewarding with tokens."*

**Implementation**: Token rewards for quality contributions.

## Evolution from Original Vision to MVP Plan

### What Stayed the Same
1. ✅ Claude Code hooks for capture
2. ✅ Sanitization before storage
3. ✅ SQLite database
4. ✅ Async processing
5. ✅ Learning extraction
6. ✅ MCP server interface
7. ✅ IPFS/blockchain upload

### What Was Enhanced
1. **Subagent-Driven Development**: All implementation via specialized subagents
2. **Claude Testing Harness**: Self-validating system using Claude Agent SDK
3. **Hybrid Sanitization**: Rule-based + AI for better accuracy
4. **Detailed Architecture**: 7-phase implementation plan with testable components
5. **Quality Gates**: Automated validation at every step

### What Was Deferred to Post-MVP
1. Validator network (quorum-based validation)
2. Multi-user support
3. Distributed storage
4. Complex token economics
5. Smart contract deployment

## Success Metrics (From User Intent)

### Functional Success
- ✅ Learnings captured from every conversation
- ✅ Zero PII leaks
- ✅ Learnings queryable via MCP
- ✅ Works across different projects
- ✅ Async processing doesn't block workflow

### User Experience Success
- ✅ Transparent to normal workflow
- ✅ No performance impact on Claude Code
- ✅ Easy to query learnings
- ✅ Learnings actually useful
- ✅ Trust in privacy guarantees

### Network Success (Future)
- 🔮 High-quality learnings contributed
- 🔮 Learnings validated by community
- 🔮 Token rewards distributed fairly
- 🔮 Network grows organically
- 🔮 Agents actively query network

## User's Vision for Impact

### Individual Developer Level
- Learn from own past experiences
- Share learnings across projects
- Build personal knowledge base
- Improve over time automatically

### Team Level
- Share learnings within organization
- Onboard new developers faster
- Standardize best practices
- Collective intelligence growth

### Global Level
- AI agents learn from each other
- Best practices emerge organically
- Problems solved once, shared globally
- Accelerate software development
- Democratize expert knowledge

## Key Insights from User

### Problem Statement
*"The learnings from this tend to just be lost to this specific project."*

**Solution**: Persistent storage and global sharing of learnings.

### Value Proposition
*"It would be really interesting if these learnings could be shared with my other projects but also globally with everyone."*

**Implementation**: MCP server for cross-project queries + global network for sharing.

### Trust Requirement
*"We never have to worry about leaking data."*

**Guarantee**: Sanitize BEFORE storage, never trust raw data.

### Quality Control
*"You could just stream junk from an LLM into this."*

**Solution**: Quality scoring + validator network + token incentives.

## Alignment with Claude Code Philosophy

The user's vision aligns perfectly with Claude Code's capabilities:

1. **Hooks System**: Native support for capturing events
2. **Subagent Support**: Built-in task delegation
3. **MCP Integration**: Standard protocol for tools
4. **File Access**: Can read/write for learning storage
5. **Bash Access**: Can run background processes

## Implementation Strategy

### Phase-Based Rollout

**Phases 0-3 (Weeks 1-3)**: Core Infrastructure
- Foundation, event capture, sanitization, storage
- **User Value**: Learnings saved locally, queryable

**Phases 4-6 (Weeks 4-6)**: Intelligence Layer
- Async processing, learning extraction, MCP server
- **User Value**: Quality learnings, cross-project queries

**Phase 7 (Week 6-7)**: Global Network
- IPFS upload, blockchain integration
- **User Value**: Share globally, earn rewards

### Post-MVP Enhancements

**Validator Network**:
- Multi-agent quality validation
- Quorum-based consensus
- Token distribution on validation

**Advanced Features**:
- Semantic search
- Learning recommendations
- Trend analysis
- Community curation

## Related Documents

### Architecture
- [Global Context Network Architecture](../architecture/architecture-global-context-network-2025-01-16.md)
- [Subagent System](../architecture/architecture-subagent-system-2025-01-16.md)
- [Sanitization Pipeline](../architecture/architecture-sanitization-pipeline-2025-01-16.md)

### Plans
- [Implementation Roadmap](./plan-implementation-roadmap-2025-01-16.md)
- [Global Context Network MVP](./plan-global-context-network-mvp-2025-01-16.md)

### Decisions
- [ADR: Use Claude Hooks](../decisions/decision-use-claude-hooks-2025-01-16.md)
- [ADR: Sanitize Before Storage](../decisions/decision-sanitize-before-storage-2025-01-16.md)

---

*This document preserves the user's original vision and requirements to ensure the implementation stays aligned with the core intent.*

================
File: plans/plan-phase-0-tasks-2025-01-16.md
================
# Phase 0: Foundation Tasks

> TypeScript project setup, database schema, and test infrastructure

---
title: Phase 0 Foundation Tasks
category: plan
date: 2025-01-16
status: active
tags: [phase-0, foundation, typescript, database, testing]
---

## Goal

Establish project foundation with TypeScript, database schema, and test infrastructure to support all subsequent phases.

## Duration

2-3 days

## Tasks

### TypeScript Project Setup
- [ ] Initialize Node.js project with npm/pnpm
- [ ] Configure TypeScript with strict mode enabled
- [ ] Set up tsconfig.json with paths, outDir, strict settings
- [ ] Configure package.json scripts (build, dev, test, lint)
- [ ] Install core dependencies (@types/node, tsx, etc.)

**Subagent**: `foundation-setup-agent`

**Acceptance**: TypeScript compiles with no errors, strict mode enabled

### ESLint + Prettier Setup
- [ ] Install ESLint with TypeScript plugin
- [ ] Configure .eslintrc.json with strict rules
- [ ] Install Prettier
- [ ] Configure .prettierrc with consistent settings
- [ ] Add lint and format scripts to package.json

**Acceptance**: Lint and format scripts run successfully

### Vitest Testing Framework
- [ ] Install Vitest and related packages
- [ ] Configure vitest.config.ts
- [ ] Set up coverage reporting (c8 or v8)
- [ ] Create test utilities directory
- [ ] Add sample test to verify setup

**Subagent**: `test-infrastructure-agent`

**Acceptance**: `npm test` runs and reports correctly

### Database Schema Design
- [ ] Design conversations table schema
- [ ] Design messages table schema
- [ ] Design learnings table schema
- [ ] Design job_queue table schema
- [ ] Design sanitization_log table schema
- [ ] Design uploads table schema

**Subagent**: `database-schema-agent`

**Acceptance**: Schema documented with all tables, columns, indexes, foreign keys

### Migration System
- [ ] Install migration library (kysely or knex)
- [ ] Create migration runner
- [ ] Implement up/down migration functions
- [ ] Create initial migration (001_create_tables.ts)
- [ ] Test migrations are reversible

**Acceptance**: Migrations run forward and backward successfully

### Test Utilities
- [ ] Create test database factory
- [ ] Create test data builders
- [ ] Create assertion helpers
- [ ] Create mock factories
- [ ] Document test utilities

**Acceptance**: Test utilities available and documented

## Dependencies

None (this is the foundation phase)

## Deliverables

1. `tsconfig.json` with strict settings
2. `vitest.config.ts` configured
3. `.eslintrc.json` and `.prettierrc`
4. Database schema documentation
5. Migration system with initial migration
6. Test utilities in `/tests/utils/`

## Success Criteria

- ✅ TypeScript compiles with no errors
- ✅ Vitest runs and reports coverage
- ✅ ESLint passes with strict rules
- ✅ Database migrations work bidirectionally
- ✅ Test utilities ready for use
- ✅ Documentation complete

## Testing Strategy

- Unit tests for migration runner
- Integration tests for database setup
- Test coverage for utilities

## Related Documents

- [Implementation Roadmap](./plan-implementation-roadmap-2025-01-16.md)
- [Database Schema Architecture](../architecture/architecture-database-schema-2025-01-16.md)

================
File: plans/plan-phase-1-tasks-2025-01-16.md
================
# Phase 1: Event Capture Tasks

> Hook implementation, event collection, and persistent queue

---
title: Phase 1 Event Capture Tasks
category: plan
date: 2025-01-16
status: active
tags: [phase-1, hooks, events, queue]
---

## Goal

Capture all Claude Code interactions via hooks without blocking the user, with fast pre-sanitization before persistence.

## Duration

3-4 days

## Tasks

### Event Schema Design
- [ ] Define event payload schema (correlation IDs, timestamps, versioning)
- [ ] Define message ordering strategy
- [ ] Define idempotency keys (dedupe strategy)
- [ ] Design event versioning for future compatibility
- [ ] Document schema with TypeScript types

**Acceptance**: Schema documented and typed

### UserPromptSubmit Hook
- [ ] Create `.claude/hooks/userPromptSubmit.sh` script
- [ ] Implement fast pre-sanitizer (< 50ms, removes obvious PII)
- [ ] Capture user prompt with correlation ID
- [ ] Implement error handling (never block user)
- [ ] Add performance monitoring
- [ ] Test hook execution time < 100ms (p95)

**Subagent**: `hook-developer-agent`

**Acceptance**: Hook runs < 100ms, captures prompts, never blocks UI

### Stop Hook
- [ ] Create `.claude/hooks/stop.sh` script
- [ ] Implement fast pre-sanitizer
- [ ] Capture agent response with correlation ID
- [ ] Handle partial responses and tool calls
- [ ] Add error handling
- [ ] Test hook execution time < 100ms (p95)

**Acceptance**: Hook runs < 100ms, captures responses, never blocks UI

### Fast Pre-Sanitizer
- [ ] Implement rule-based PII removal (API keys, obvious paths, emails)
- [ ] Ensure < 50ms execution for typical payloads
- [ ] Redact with [REDACTED_TYPE] format
- [ ] Log what was pre-sanitized (audit trail)
- [ ] Unit test with common PII patterns

**Acceptance**: Pre-sanitization < 50ms, removes obvious PII before persistence

### Event Collector
- [ ] Aggregate events into conversation sessions
- [ ] Implement correlation ID tracking
- [ ] Handle out-of-order messages
- [ ] Deduplicate events by idempotency key
- [ ] Handle conversation boundaries

**Subagent**: `event-collector-agent`

**Acceptance**: Events properly grouped into conversations

### Persistent Queue
- [ ] Implement SQLite-based event queue
- [ ] Store pre-sanitized events only (no raw data persisted)
- [ ] Implement queue operations (enqueue, dequeue, peek)
- [ ] Add backpressure handling (disk full, DB unavailable)
- [ ] Implement graceful degradation (in-memory fallback)
- [ ] Test persistence across restarts

**Subagent**: `queue-system-agent`

**Acceptance**: Queue persists pre-sanitized events, handles backpressure

### Cross-Platform Support
- [ ] Test hooks on macOS
- [ ] Test hooks on Linux (if applicable)
- [ ] Test hooks on Windows (if applicable)
- [ ] Document installation steps per OS
- [ ] Handle permission requirements

**Acceptance**: Hooks work on primary development OS

### Hook Failure Modes
- [ ] Implement circuit-breaker for persistent failures
- [ ] Add silent retry for transient errors
- [ ] Create offline mode (queue in memory until reconnected)
- [ ] Log failures without blocking
- [ ] Test failure scenarios

**Acceptance**: Failures handled gracefully, never block user

## Dependencies

- Phase 0: Database schema, TypeScript setup

## Deliverables

1. `.claude/hooks/userPromptSubmit.sh`
2. `.claude/hooks/stop.sh`
3. Fast pre-sanitizer implementation
4. Event collector implementation
5. Persistent queue implementation
6. Hook performance benchmarks
7. Installation guide for hooks

## Success Criteria

- ✅ Hooks execute < 100ms (p95)
- ✅ Pre-sanitization removes obvious PII < 50ms
- ✅ Events persisted with correlation IDs
- ✅ No user-blocking errors
- ✅ Complete conversation capture
- ✅ Queue handles backpressure
- ✅ Idempotent event processing (no duplicates)
- ✅ No plaintext raw data persisted on disk

## Testing Strategy

- Unit tests for event collector
- Unit tests for queue operations
- Performance tests for hooks (p95, p99 latency)
- Integration tests for end-to-end flow
- Chaos tests (kill process mid-write)

## Related Documents

- [Hooks & Event Capture Architecture](../architecture/architecture-hooks-event-capture-2025-01-16.md)
- [Implementation Roadmap](./plan-implementation-roadmap-2025-01-16.md)

================
File: plans/plan-phase-2-tasks-2025-01-16.md
================
# Phase 2: Sanitization Pipeline Tasks

> PII detection and removal with rule-based + AI hybrid approach

---
title: Phase 2 Sanitization Pipeline Tasks
category: plan
date: 2025-01-16
status: active
tags: [phase-2, sanitization, pii, privacy, security]
---

## Goal

Remove ALL PII before final database storage using hybrid sanitization (rules + AI) with measurable precision/recall metrics.

## Duration

7-10 days (includes gold dataset creation)

## Tasks

### Gold Dataset Creation
- [ ] Build or adopt labeled PII dataset (1000+ examples)
- [ ] Include categories: email, phone, IP, path, key, URL, JWT, name
- [ ] Cover multiple OS path patterns (macOS, Linux, Windows)
- [ ] Include international formats (phone, addresses)
- [ ] Include adversarial examples (bypass attempts)
- [ ] Label each example with PII type

**Subagent**: `dataset-builder-agent`

**Acceptance**: 1000+ labeled examples across 8+ PII categories

### Rule-Based PII Detector
- [ ] Implement regex patterns for emails
- [ ] Implement regex for phone numbers (multiple formats)
- [ ] Implement regex for IPv4 and IPv6 addresses
- [ ] Implement regex for file paths (OS-specific patterns)
- [ ] Implement regex for API keys (AWS, GCP, OpenAI, GitHub, Slack)
- [ ] Implement regex for JWTs and URL tokens
- [ ] Implement regex for common environment variable patterns
- [ ] Define redaction format: [REDACTED_EMAIL], [REDACTED_PATH], etc.
- [ ] Optimize for < 10ms execution

**Subagent**: `rule-sanitizer-agent`

**Acceptance**:
- Precision ≥ 98% per category on gold dataset
- Execution < 10ms for typical payloads

### AI-Powered Sanitizer
- [ ] Integrate Claude API for context-aware sanitization
- [ ] Define prompt templates (temperature=0 for determinism)
- [ ] Implement fallback to rules-only if API unavailable
- [ ] Distinguish names from variable names
- [ ] Handle company-specific terminology
- [ ] Set max tokens and timeout limits
- [ ] Cache API responses for identical inputs

**Subagent**: `ai-sanitizer-agent`

**Acceptance**:
- Recall ≥ 95% per category on gold dataset
- Handles context ambiguity
- Fallback working

### Hybrid Validation Pipeline
- [ ] Combine rule-based + AI results
- [ ] Implement consensus logic (union of redactions)
- [ ] Create audit log of all redactions
- [ ] Track which method detected each PII item
- [ ] Implement override mechanism for false positives
- [ ] Ensure deterministic output

**Subagent**: `sanitization-pipeline-agent`

**Acceptance**: Combined precision ≥ 98%, recall ≥ 95%

### Scoring Harness
- [ ] Implement precision calculation per PII category
- [ ] Implement recall calculation per PII category
- [ ] Implement F1 score per category
- [ ] Generate per-category reports
- [ ] Set acceptance thresholds per category
- [ ] Create continuous evaluation suite

**Acceptance**: Automated scoring against gold dataset

### Chain-of-Thought Exclusion
- [ ] Identify and exclude chain-of-thought from all storage
- [ ] Document policy: never store thinking processes
- [ ] Implement detection of thinking tags
- [ ] Test exclusion is complete
- [ ] Update schema to not include thinking fields

**Acceptance**: Zero chain-of-thought stored

### Adversarial Testing
- [ ] Create adversarial test suite (prompt injection, evasion)
- [ ] Test obfuscated PII (base64, hex, URL-encoded)
- [ ] Test context manipulation attempts
- [ ] Test delimiter confusion
- [ ] Document vulnerabilities found

**Acceptance**: Adversarial suite passes, vulnerabilities documented

### Logging Redaction
- [ ] Implement log redaction middleware
- [ ] Ensure no PII in debug/error logs
- [ ] Test log output for PII leaks
- [ ] Document safe logging practices

**Acceptance**: No PII in any log outputs

## Dependencies

- Phase 1: Events to sanitize

## Deliverables

1. Gold PII dataset (1000+ labeled examples)
2. Rule-based sanitizer with 20+ patterns
3. AI-powered sanitizer with prompt templates
4. Hybrid pipeline orchestrator
5. Scoring harness with per-category metrics
6. Adversarial test suite
7. Audit logging system

## Success Criteria

- ✅ Precision ≥ 98% per PII category
- ✅ Recall ≥ 95% per PII category
- ✅ Sanitization < 2s per conversation
- ✅ No plaintext raw data on disk (pre-sanitized before persistence)
- ✅ Chain-of-thought excluded from all storage
- ✅ Audit log tracking all redactions
- ✅ Adversarial test suite passes
- ✅ No PII in logs

## PII Categories Covered

1. **Emails**: Standard formats, obfuscated variants
2. **Phone Numbers**: US, international, with/without formatting
3. **IP Addresses**: IPv4, IPv6, with ports
4. **File Paths**: Absolute paths with usernames (all OSes)
5. **API Keys**: AWS, GCP, OpenAI, GitHub, Slack, generic patterns
6. **URLs with Tokens**: Query params, bearer tokens, JWTs
7. **Environment Variables**: With secret values
8. **Names**: Person names (context-aware, not variable names)

## Testing Strategy

- Unit tests for each regex pattern
- Unit tests for AI sanitizer with mocked API
- Integration tests for hybrid pipeline
- Performance tests (< 2s per conversation)
- Precision/recall tests against gold dataset
- Adversarial tests for evasion attempts
- Chaos tests (API unavailable, rate limited)

## Related Documents

- [Sanitization Pipeline Architecture](../architecture/architecture-sanitization-pipeline-2025-01-16.md)
- [Implementation Roadmap](./plan-implementation-roadmap-2025-01-16.md)
- [Privacy ADR](../decisions/decision-sanitize-before-storage-2025-01-16.md)

================
File: plans/plan-phase-3-tasks-2025-01-16.md
================
# Phase 3: Database & Storage Tasks

> Repository pattern, query optimization, and data persistence

---
title: Phase 3 Database & Storage Tasks
category: plan
date: 2025-01-16
status: active
tags: [phase-3, database, storage, sqlite, migrations]
---

## Goal

Persist sanitized data with ACID guarantees, fast queries, and reversible migrations.

## Duration

2-3 days

## Tasks

### Repository Pattern Implementation
- [ ] Create ConversationRepository
- [ ] Create MessageRepository
- [ ] Create LearningRepository
- [ ] Create JobQueueRepository
- [ ] Create UploadRepository
- [ ] Implement common CRUD operations
- [ ] Add transaction support

**Subagent**: `repository-agent`

**Acceptance**: All repositories implemented with typed interfaces

### Conversation Table
- [ ] Implement create conversation
- [ ] Implement find conversation by ID
- [ ] Implement list conversations with pagination
- [ ] Implement update conversation metadata
- [ ] Implement soft delete (if needed)
- [ ] Add indexes for common queries

**Acceptance**: All operations < 100ms

### Messages Table
- [ ] Implement create message
- [ ] Implement find messages by conversation ID
- [ ] Implement message ordering (by timestamp)
- [ ] Implement foreign key constraints to conversations
- [ ] Add indexes for conversation_id, timestamp

**Acceptance**: Foreign keys enforced, queries < 100ms

### Learnings Table
- [ ] Implement create learning
- [ ] Implement find learning by ID
- [ ] Implement search learnings (text, category, tags)
- [ ] Implement quality scoring filter (confidence ≥ threshold)
- [ ] Add full-text search indexes
- [ ] Add category and tag indexes

**Acceptance**: Search queries < 100ms

### Job Queue Table
- [ ] Implement enqueue job
- [ ] Implement dequeue job (with locking)
- [ ] Implement update job status
- [ ] Implement retry tracking
- [ ] Add indexes for status, priority, created_at

**Acceptance**: Queue operations atomic and < 50ms

### Migration Versioning
- [ ] Implement migration version tracking table
- [ ] Create migration 001: initial tables
- [ ] Create migration 002: indexes
- [ ] Create migration 003: audit tables
- [ ] Test rollback for each migration
- [ ] Document migration process

**Acceptance**: Migrations reversible, version tracked

### Query Optimization
- [ ] Enable WAL mode for SQLite
- [ ] Create indexes for all foreign keys
- [ ] Create indexes for common filters (status, category, created_at)
- [ ] Add full-text search index for learnings
- [ ] Test query performance with realistic dataset (10k+ rows)
- [ ] Benchmark and document query times

**Subagent**: `query-optimization-agent`

**Acceptance**: All queries < 100ms on 10k+ dataset

### ACID Compliance Testing
- [ ] Test concurrent writers don't corrupt data
- [ ] Test foreign key constraints enforced
- [ ] Test transactions rollback on error
- [ ] Test no orphan messages after conversation delete
- [ ] Test isolation levels

**Acceptance**: All ACID tests pass

### Data Retention Policies
- [ ] Implement purge old conversations (configurable retention)
- [ ] Implement delete conversation with cascade
- [ ] Implement right-to-delete support
- [ ] Implement vacuum schedule for SQLite
- [ ] Document retention policies

**Acceptance**: Deletion works correctly, vacuum reduces DB size

## Dependencies

- Phase 0: Database schema
- Phase 2: Sanitized data to store

## Deliverables

1. Repository implementations for all tables
2. Migration scripts (001-003+)
3. Query optimization indexes
4. ACID compliance test suite
5. Data retention utilities
6. Performance benchmark results

## Success Criteria

- ✅ All queries < 100ms
- ✅ ACID compliance verified (concurrent writes, FK constraints)
- ✅ Migrations reversible
- ✅ WAL mode enabled
- ✅ No orphan records
- ✅ Full-text search working for learnings

## Testing Strategy

- Unit tests for each repository method
- Integration tests for cross-table operations
- Concurrent writer tests
- Foreign key constraint tests
- Performance tests with 10k+ rows
- Migration rollback tests

## Related Documents

- [Database Schema Architecture](../architecture/architecture-database-schema-2025-01-16.md)
- [Implementation Roadmap](./plan-implementation-roadmap-2025-01-16.md)

================
File: plans/plan-phase-4-tasks-2025-01-16.md
================
# Phase 4: Async Processing Tasks

> Job queue, workers, idempotency, and crash recovery

---
title: Phase 4 Async Processing Tasks
category: plan
date: 2025-01-16
status: active
tags: [phase-4, async, queue, workers, reliability]
---

## Goal

Implement reliable async processing with idempotent jobs, retry logic, and crash recovery.

## Duration

5-7 days

## Tasks

### Job Queue Implementation
- [ ] Implement SQLite-based job queue
- [ ] Add job types (sanitize, extract_learning, mine_upload)
- [ ] Implement priority levels
- [ ] Add job status tracking (pending, in_progress, completed, failed)
- [ ] Implement advisory locks for job claiming
- [ ] Add job visibility timeout

**Subagent**: `job-queue-agent`

**Acceptance**: Jobs enqueued atomically, no duplicate processing

### Job Idempotency
- [ ] Design dedupe key strategy (conversation_id + job_type)
- [ ] Implement idempotency checks before execution
- [ ] Test duplicate job submissions are ignored
- [ ] Implement outbox pattern for uploads
- [ ] Document idempotency guarantees

**Acceptance**: Duplicate jobs don't execute twice

### Worker Process Architecture
- [ ] Create worker process framework
- [ ] Implement graceful startup
- [ ] Implement graceful shutdown (wait for in-flight jobs)
- [ ] Add job checkpoint/resume on shutdown
- [ ] Implement worker heartbeat
- [ ] Support multiple worker instances

**Subagent**: `worker-agent`

**Acceptance**: Workers start/stop cleanly, no job loss

### Retry Logic
- [ ] Implement exponential backoff (1s, 2s, 4s, 8s, ...)
- [ ] Set max retry count (3 attempts)
- [ ] Add jitter to prevent retry storms
- [ ] Track retry count per job
- [ ] Implement retry cap per time window

**Acceptance**: Failed jobs retry with backoff, max 3 attempts

### Dead Letter Queue
- [ ] Implement DLQ for permanently failed jobs
- [ ] Add failure reason tracking
- [ ] Implement manual review workflow
- [ ] Add re-queue from DLQ capability
- [ ] Monitor DLQ size

**Acceptance**: Failed jobs moved to DLQ after max retries

### Crash Recovery
- [ ] Test worker crash mid-job
- [ ] Implement job timeout and re-queue
- [ ] Test DB locked scenario
- [ ] Test disk full scenario
- [ ] Test power loss scenario (via simulation)
- [ ] Verify no data loss on crash

**Acceptance**: All crash scenarios recover gracefully

### Concurrency Control
- [ ] Implement advisory locks in SQLite
- [ ] Test concurrent workers don't claim same job
- [ ] Implement worker registration/deregistration
- [ ] Add worker health checks
- [ ] Test scaling to N workers

**Acceptance**: Concurrent workers safe, no double-processing

### Job Monitoring
- [ ] Track jobs in each status
- [ ] Track average job duration by type
- [ ] Track retry rate
- [ ] Track DLQ size
- [ ] Expose metrics endpoint (simple JSON)

**Acceptance**: Metrics available for monitoring

## Dependencies

- Phase 3: Database for job storage

## Deliverables

1. Job queue implementation
2. Worker process framework
3. Retry logic with backoff
4. Dead letter queue
5. Crash recovery tests
6. Concurrency control system
7. Monitoring/metrics

## Success Criteria

- ✅ Jobs never lost (even on crash)
- ✅ Idempotent processing verified
- ✅ Graceful shutdown within 30s
- ✅ Exponential backoff working
- ✅ DLQ captures failed jobs
- ✅ Concurrent workers safe
- ✅ Crash recovery E2E tests pass

## Job Types

### sanitize_conversation
- Input: conversation_id, raw_events
- Output: sanitized_conversation_id
- Retry: Yes (max 3)
- Timeout: 30s

### extract_learning
- Input: sanitized_conversation_id
- Output: learning_ids[]
- Retry: Yes (max 3)
- Timeout: 60s

### mine_upload
- Input: learning_id
- Output: ipfs_cid, blockchain_tx_id
- Retry: Yes (max 3)
- Timeout: 120s

## Testing Strategy

- Unit tests for queue operations
- Unit tests for retry logic
- Integration tests for worker lifecycle
- Chaos tests (kill worker, DB unavailable, disk full)
- Concurrency tests (multiple workers)
- Idempotency tests (duplicate submissions)
- Load tests (1000+ jobs)

## Related Documents

- [Global Context Network Architecture](../architecture/architecture-global-context-network-2025-01-16.md)
- [Implementation Roadmap](./plan-implementation-roadmap-2025-01-16.md)

================
File: plans/plan-phase-5-tasks-2025-01-16.md
================
# Phase 5: Learning Extraction Tasks

> Extract valuable learnings with quality scoring and deduplication

---
title: Phase 5 Learning Extraction Tasks
category: plan
date: 2025-01-16
status: active
tags: [phase-5, learning, extraction, quality, dedup]
---

## Goal

Extract high-quality, reusable learnings from sanitized conversations with automated quality scoring and deduplication.

## Duration

6-8 days

## Tasks

### Conversation Analyzer
- [ ] Implement value detection (is conversation worth extracting from?)
- [ ] Analyze conversation length, complexity
- [ ] Detect problem-solving patterns
- [ ] Identify code implementations
- [ ] Filter trivial conversations
- [ ] Score conversation value (0-1)

**Subagent**: `learning-extractor-agent`

**Acceptance**: Accurate filtering of trivial vs valuable conversations

### Extraction Approach Design
- [ ] Design hybrid approach (rules + LLM + embeddings)
- [ ] Create extraction prompt templates
- [ ] Define metadata schema (tags, category, provenance, version)
- [ ] Set temperature=0 for deterministic extraction
- [ ] Implement chunking for long conversations

**Acceptance**: Extraction approach documented and implemented

### Category Extractors
- [ ] Implement pattern extractor (code patterns, architectures)
- [ ] Implement best_practice extractor
- [ ] Implement anti_pattern extractor
- [ ] Implement bug_fix extractor
- [ ] Implement optimization extractor
- [ ] Implement tool_usage extractor
- [ ] Implement workflow extractor
- [ ] Implement decision extractor

**Acceptance**: All 8 category extractors working

### Quality Scoring Algorithm
- [ ] Implement confidence scoring (0-1 scale)
- [ ] Define minimum information gain metric
- [ ] Filter learnings below confidence threshold (≥ 0.6)
- [ ] Ensure learning length ≥ 100 characters
- [ ] Validate learning has actionable content
- [ ] Score uniqueness vs existing learnings

**Subagent**: `quality-filter-agent`

**Acceptance**: 90% of high-scoring learnings rated "useful" by human reviewer

### Deduplication System
- [ ] Implement lexical similarity check
- [ ] Implement embedding-based similarity (cosine)
- [ ] Set similarity threshold (< 0.85 to keep)
- [ ] Implement windowed comparison (recent N learnings)
- [ ] Provide rejection reasons (duplicate of learning_id X)
- [ ] Test edge cases (near-duplicates, rephrasing)

**Acceptance**: No duplicate learnings (verified by similarity tests)

### Metadata & Provenance
- [ ] Capture conversation_id source
- [ ] Record timestamp of extraction
- [ ] Record sanitizer_version used
- [ ] Record extractor_version used
- [ ] Capture tags (auto-generated + manual)
- [ ] Record category

**Acceptance**: All metadata fields populated

### Negative Set (Anti-Patterns)
- [ ] Define examples of trivial learnings to reject
- [ ] Build negative test dataset
- [ ] Test extractor rejects trivial/generic content
- [ ] Document criteria for rejection
- [ ] Calibrate confidence threshold using negative set

**Acceptance**: Trivial learnings filtered out

### Human-in-the-Loop Review
- [ ] Create sample review interface (CLI or simple UI)
- [ ] Review random sample of extracted learnings (N=50)
- [ ] Rate each learning as useful/not useful
- [ ] Calculate approval rate (target ≥ 90%)
- [ ] Use feedback to tune thresholds

**Acceptance**: ≥ 90% approval rate on random sample

## Dependencies

- Phase 4: Async processing to run extraction jobs

## Deliverables

1. Conversation analyzer
2. 8 category-specific extractors
3. Quality scoring algorithm
4. Deduplication system
5. Metadata schema implementation
6. Negative test dataset
7. Human review process and results

## Success Criteria

- ✅ Confidence scores ≥ 0.6 for all extracted learnings
- ✅ No duplicate learnings (similarity < 0.85)
- ✅ Proper categorization (8 categories)
- ✅ Complete metadata (provenance, version, tags)
- ✅ 90% human approval rate on sample
- ✅ Trivial learnings filtered out
- ✅ Extraction < 5s per conversation

## Learning Categories

1. **pattern**: Code patterns, architectures, design patterns
2. **best_practice**: Recommended approaches, standards
3. **anti_pattern**: What to avoid, known pitfalls
4. **bug_fix**: Problem-solving strategies, debugging
5. **optimization**: Performance improvements, efficiency
6. **tool_usage**: How to use libraries, frameworks, tools
7. **workflow**: Development workflows, processes
8. **decision**: Architecture decisions, trade-offs

## Testing Strategy

- Unit tests for each category extractor
- Integration tests for end-to-end extraction
- Quality tests with known good/bad examples
- Deduplication tests with similar content
- Performance tests (< 5s per conversation)
- Human review on random sample (N=50)

## Related Documents

- [Learning Extraction Architecture](../architecture/architecture-learning-extraction-2025-01-16.md)
- [Implementation Roadmap](./plan-implementation-roadmap-2025-01-16.md)

================
File: plans/plan-phase-6-tasks-2025-01-16.md
================
# Phase 6: MCP Server Tasks

> Model Context Protocol server for agent queries

---
title: Phase 6 MCP Server Tasks
category: plan
date: 2025-01-16
status: active
tags: [phase-6, mcp, server, query-interface]
---

## Goal

Implement MCP protocol server enabling Claude Code and other agents to query learnings with < 200ms latency.

## Duration

3-4 days

## Tasks

### MCP SDK Integration
- [ ] Install @modelcontextprotocol/sdk
- [ ] Create server configuration
- [ ] Implement server initialization
- [ ] Configure loopback binding (127.0.0.1 only)
- [ ] Add optional API key authentication
- [ ] Test server starts and responds to ping

**Subagent**: `mcp-protocol-agent`

**Acceptance**: MCP server starts and Claude Code can connect

### search_learnings Tool
- [ ] Implement text search across learning content
- [ ] Add category filter (pattern, best_practice, etc.)
- [ ] Add tag filter (multiple tags support)
- [ ] Add confidence threshold filter
- [ ] Implement pagination (limit, offset)
- [ ] Implement sorting (by date, confidence, relevance)
- [ ] Validate input parameters and bounds

**Acceptance**: Search returns relevant learnings < 200ms

### get_learning_by_id Tool
- [ ] Implement fetch learning by ID
- [ ] Return full learning with metadata
- [ ] Handle not found errors gracefully
- [ ] Validate ID format

**Acceptance**: Fetch by ID < 50ms

### get_learning_context Tool
- [ ] Fetch full conversation for a learning
- [ ] Return sanitized conversation messages
- [ ] Include provenance information
- [ ] Handle privacy (only sanitized data)

**Acceptance**: Context retrieval < 200ms

### Resource Endpoints
- [ ] Implement `context://learnings/recent` (latest N learnings)
- [ ] Implement `context://learnings/top-rated` (highest confidence)
- [ ] Implement `context://stats` (total learnings, categories, etc.)
- [ ] Add caching for resource endpoints
- [ ] Document resource schemas

**Acceptance**: Resources load < 100ms

### Authentication & Authorization
- [ ] Implement optional API key authentication
- [ ] Default to localhost-only binding (no auth needed)
- [ ] Add config for enabling auth
- [ ] Reject requests without valid auth (if enabled)
- [ ] Document security model

**Acceptance**: Auth enforced when enabled, bypassed on localhost

### Input Validation
- [ ] Validate all tool parameters
- [ ] Enforce bounds (max limit, offset ranges)
- [ ] Sanitize search queries (prevent injection)
- [ ] Reject malformed requests
- [ ] Return clear error messages

**Acceptance**: Invalid requests rejected gracefully

### Rate Limiting
- [ ] Implement simple rate limiter (N requests per minute)
- [ ] Prevent local DoS scenarios
- [ ] Return 429 Too Many Requests when exceeded
- [ ] Make limits configurable

**Acceptance**: Rate limiting prevents abuse

### Query Optimization
- [ ] Use database indexes for filters
- [ ] Implement result caching for common queries
- [ ] Optimize full-text search queries
- [ ] Test performance with 10k+ learnings
- [ ] Profile slow queries

**Subagent**: `query-optimization-agent`

**Acceptance**: All queries < 200ms on 10k+ dataset

### MCP Protocol Conformance
- [ ] Test against MCP SDK examples
- [ ] Verify tool schemas are valid
- [ ] Verify resource schemas are valid
- [ ] Test error handling conforms to spec
- [ ] Test streaming responses (if applicable)

**Acceptance**: MCP conformance tests pass

## Dependencies

- Phase 5: Learnings to query

## Deliverables

1. MCP server implementation
2. Three query tools (search, get by ID, get context)
3. Three resource endpoints (recent, top-rated, stats)
4. Authentication layer (optional)
5. Rate limiting system
6. Performance benchmarks

## Success Criteria

- ✅ MCP protocol conformance tests pass
- ✅ All queries < 200ms
- ✅ Invalid queries rejected gracefully
- ✅ Auth enforced when enabled
- ✅ Rate limiting prevents abuse
- ✅ Claude Code integration working
- ✅ No data leaks via MCP

## MCP Tools

### search_learnings
```typescript
{
  name: "search_learnings",
  description: "Search for learnings by text, category, or tags",
  inputSchema: {
    query: "string (optional)",
    category: "string (optional)",
    tags: "string[] (optional)",
    minConfidence: "number (optional, default 0.6)",
    limit: "number (optional, default 10, max 100)",
    offset: "number (optional, default 0)"
  }
}
```

### get_learning_by_id
```typescript
{
  name: "get_learning_by_id",
  description: "Fetch a specific learning by ID",
  inputSchema: {
    id: "string (required)"
  }
}
```

### get_learning_context
```typescript
{
  name: "get_learning_context",
  description: "Get full conversation context for a learning",
  inputSchema: {
    learningId: "string (required)"
  }
}
```

## MCP Resources

- `context://learnings/recent`: Latest 50 learnings
- `context://learnings/top-rated`: Top 50 by confidence
- `context://stats`: Network statistics (total, categories, etc.)

## Testing Strategy

- Unit tests for each tool
- Integration tests for MCP protocol
- Performance tests (concurrent queries)
- Security tests (injection, auth bypass)
- Load tests (N concurrent clients)
- Conformance tests against MCP spec

## Related Documents

- [MCP Server Architecture](../architecture/architecture-mcp-server-2025-01-16.md)
- [Implementation Roadmap](./plan-implementation-roadmap-2025-01-16.md)

================
File: plans/plan-phase-7-tasks-2025-01-16.md
================
# Phase 7: Mining & Upload Tasks (MVP+)

> IPFS upload and blockchain integration with token tracking

---
title: Phase 7 Mining & Upload Tasks (MVP+)
category: plan
date: 2025-01-16
status: active
tags: [phase-7, ipfs, blockchain, mining, upload, mvp-plus]
---

## Goal

Upload quality learnings to IPFS and anchor CIDs on blockchain with token reward tracking.

## Duration

4-10 days (depending on blockchain complexity)

**Note**: This phase is marked as MVP+ and can be deferred or simplified for initial MVP release.

## Tasks

### IPFS Integration Decision
- [ ] Choose: self-hosted IPFS node vs pinning provider
- [ ] If provider: select service (Pinata, web3.storage, etc.)
- [ ] If self-hosted: set up IPFS node
- [ ] Configure pinning strategy and SLA
- [ ] Test IPFS node connectivity
- [ ] Document IPFS setup

**Acceptance**: IPFS endpoint available and tested

### IPFS Client Implementation
- [ ] Install IPFS client library
- [ ] Implement content upload function
- [ ] Implement CID generation
- [ ] Implement content retrieval (verify upload)
- [ ] Add retry logic for failed uploads
- [ ] Test upload/retrieval flow

**Subagent**: `ipfs-integration-agent`

**Acceptance**: Content uploads to IPFS and is retrievable

### Content Preparation
- [ ] Format learning for IPFS (JSON structure)
- [ ] Include metadata (category, tags, confidence, timestamp)
- [ ] Exclude any remaining sensitive data
- [ ] Add license information
- [ ] Add provenance data (sanitizer version, etc.)
- [ ] Compress content if needed

**Acceptance**: Content properly formatted for public sharing

### Blockchain Network Selection
- [ ] Choose blockchain (Ethereum testnet, Celestia, etc.)
- [ ] Set up RPC provider access
- [ ] Get testnet tokens from faucet
- [ ] Document network choice and rationale

**Acceptance**: Blockchain network decided and access configured

### Wallet & Key Management
- [ ] Implement local wallet generation
- [ ] Store keys securely (OS keychain)
- [ ] Implement backup/export functionality
- [ ] Add passphrase protection
- [ ] Document key management security
- [ ] Require explicit user action to enable

**Subagent**: `blockchain-agent`

**Acceptance**: Keys generated, stored securely, backupable

### CID Anchoring Strategy
- [ ] Decide: simple CID registry vs full smart contract
- [ ] If registry: implement off-chain registry with on-chain hashes
- [ ] If contract: design contract, deploy to testnet
- [ ] Implement transaction submission
- [ ] Implement confirmation polling
- [ ] Add gas estimation

**Acceptance**: CIDs anchored on-chain with confirmation

### Smart Contract (Optional - if time permits)
- [ ] Design learning registry contract
- [ ] Implement reward calculation logic
- [ ] Add quality score submission
- [ ] Deploy to testnet
- [ ] Audit contract (basic security review)
- [ ] Document contract interface

**Acceptance**: Contract deployed, tested, and documented

### Token Reward Tracking
- [ ] Implement reward calculation (placeholder or actual)
- [ ] Track upload status (pending, confirmed, rewarded)
- [ ] Store transaction IDs
- [ ] Query reward balance
- [ ] Document tokenomics (even if simplified)

**Acceptance**: Rewards tracked in database

### User Controls
- [ ] Implement opt-in for uploads (default off)
- [ ] Add manual approval gate before each upload
- [ ] Implement "local-only" mode
- [ ] Add upload pause/resume
- [ ] Document user privacy controls

**Acceptance**: User has full control over uploads

### Upload Verification
- [ ] Verify CID retrievable via 2+ IPFS gateways
- [ ] Verify on-chain record exists
- [ ] Verify N confirmed blocks
- [ ] Implement status monitoring
- [ ] Add failure alerts

**Acceptance**: Uploads verified across infrastructure

### Retry & Error Handling
- [ ] Implement retry for IPFS failures
- [ ] Implement retry for blockchain failures
- [ ] Handle insufficient gas scenarios
- [ ] Handle rate limiting
- [ ] Add exponential backoff
- [ ] Move to DLQ after max retries

**Acceptance**: Failures handled gracefully with retries

## Dependencies

- Phase 5: Quality learnings to upload

## Deliverables

1. IPFS client integration
2. Blockchain integration
3. Wallet/key management system
4. CID anchoring implementation
5. Token reward tracking
6. User control interface
7. Upload verification system

## Success Criteria

- ✅ Content uploads to IPFS successfully
- ✅ CID retrievable via 2+ gateways
- ✅ On-chain record confirmed (N blocks)
- ✅ Keys stored securely (OS keychain)
- ✅ Manual approval gate working
- ✅ User controls for opt-in/out
- ✅ Retry logic handles failures

## MVP Simplification Options

If timeline is tight, simplify Phase 7 to:

### Minimal MVP+
- IPFS upload only (via pinning provider)
- Off-chain CID registry (no blockchain)
- Placeholder token tracking
- Defer smart contracts to post-MVP

### Core MVP (No Phase 7)
- Skip network upload entirely
- Focus on local capture, sanitization, learning extraction, MCP
- Add Phase 7 in Month 2

## Testing Strategy

- Integration tests for IPFS upload/retrieval
- Integration tests for blockchain transactions
- Security tests for key management
- Chaos tests (IPFS unavailable, blockchain RPC down)
- Manual approval flow tests
- Retry logic tests

## Related Documents

- [Global Context Network Architecture](../architecture/architecture-global-context-network-2025-01-16.md)
- [Implementation Roadmap](./plan-implementation-roadmap-2025-01-16.md)
- [Original User Vision](./plan-original-user-vision-2025-01-16.md)

================
File: plans/plan-subagent-workflow-2025-01-16.md
================
# Subagent Workflow - How Subagents Work Together

> Detailed workflow for using specialized subagents to implement the Global Context Network

---
title: Subagent-Driven Development Workflow
category: plan
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [subagents, workflow, tdd, development-process]
---

## Overview

This document describes how specialized subagents collaborate to implement features using Test-Driven Development (TDD) and automated quality gates.

**Core Principle**: Never implement directly - always delegate to specialized subagents.

## Subagent Roles

### Implementation Subagents
Build features and components following TDD
- Read requirements from plans
- Write tests first (Red phase)
- Implement minimal code (Green phase)
- Refactor for quality (Refactor phase)

### Test Generation Subagents
Create comprehensive test suites
- Generate unit tests (70% coverage target)
- Generate integration tests (20% coverage target)
- Generate E2E tests (10% coverage target)
- Validate test quality

### Validation Subagents
Enforce quality gates
- Test quality validator
- Coverage validator
- Implementation validator
- Code quality validator
- Security validator
- Performance validator

## TDD Workflow with Subagents

### Step 1: Test Generation (RED Phase)

**Subagent**: `unit-test-generator`

**Inputs**:
- Feature requirements
- Interface/API design
- Edge cases to cover

**Outputs**:
- Failing test suite
- Test quality score

**Process**:
```typescript
// Main orchestrator delegates to test generator
const testResult = await runSubagent("unit-test-generator", {
  feature: "Event sanitization",
  requirements: phaseRequirements,
  coverage: "edges, errors, boundaries"
});

// Validate test quality
const qualityCheck = await runSubagent("test-quality-validator", {
  tests: testResult.tests
});

// Require quality score ≥ 0.8
if (qualityCheck.score < 0.8) {
  throw new Error("Test quality insufficient");
}

// Run tests - confirm they FAIL
const testRun = await runTests(testResult.tests);
if (!testRun.allFailed) {
  throw new Error("Tests should fail before implementation");
}
```

### Step 2: Implementation (GREEN Phase)

**Subagent**: `implementation-agent` (phase-specific)

**Inputs**:
- Failing tests
- Requirements
- Architecture guidelines

**Outputs**:
- Implementation code
- All tests passing

**Process**:
```typescript
// Main orchestrator delegates to implementation agent
const implResult = await runSubagent("hook-developer-agent", {
  tests: testResult.tests,
  requirements: phaseRequirements,
  constraints: "< 100ms execution time"
});

// Run tests - confirm they PASS
const testRun = await runTests(testResult.tests);
if (!testRun.allPassed) {
  throw new Error("Implementation must pass all tests");
}

// Validate implementation
const implCheck = await runSubagent("implementation-validator", {
  code: implResult.code,
  tests: testResult.tests
});
```

### Step 3: Refactor (REFACTOR Phase)

**Subagent**: `refactor-agent`

**Inputs**:
- Working implementation
- Passing tests
- Code quality standards

**Outputs**:
- Refactored code
- Still passing tests
- Improved quality scores

**Process**:
```typescript
// Main orchestrator delegates to refactor agent
const refactorResult = await runSubagent("refactor-agent", {
  code: implResult.code,
  tests: testResult.tests,
  focus: "DRY, clear naming, SOLID principles"
});

// Run tests - confirm still PASS
const testRun = await runTests(testResult.tests);
if (!testRun.allPassed) {
  throw new Error("Refactoring broke tests");
}
```

### Step 4: Quality Gates (VALIDATION Phase)

**Subagents**: Multiple validators in parallel

**Process**:
```typescript
// Run all validators in parallel
const [coverageCheck, codeQualityCheck, securityCheck, perfCheck] = await Promise.all([
  runSubagent("coverage-validator", { tests: testResult.tests }),
  runSubagent("code-quality-validator", { code: refactorResult.code }),
  runSubagent("security-validator", { code: refactorResult.code }),
  runSubagent("performance-validator", { code: refactorResult.code })
]);

// All gates must pass
const allGatesPassed =
  coverageCheck.coverage >= 0.85 &&
  codeQualityCheck.passed &&
  securityCheck.issues.length === 0 &&
  perfCheck.acceptable;

if (!allGatesPassed) {
  throw new Error("Quality gates failed");
}
```

## Phase-Specific Workflows

### Phase 0: Foundation

**Subagents**:
- `foundation-setup-agent`: TypeScript + Vitest setup
- `database-schema-agent`: Schema design
- `test-infrastructure-agent`: Test utilities

**Workflow**:
1. Foundation agent sets up project
2. Database agent creates schema
3. Test infrastructure agent creates helpers
4. All work in parallel (independent)

**Coordination**:
```typescript
// Parallel execution
const [foundation, database, testInfra] = await Promise.all([
  runSubagent("foundation-setup-agent", {...}),
  runSubagent("database-schema-agent", {...}),
  runSubagent("test-infrastructure-agent", {...})
]);
```

### Phase 1: Event Capture

**Subagents**:
- `hook-developer-agent`: Hook implementations
- `event-collector-agent`: Event aggregation
- `queue-system-agent`: Persistent queue

**Workflow**:
1. Test generator creates hook tests
2. Hook developer implements hooks
3. Event collector aggregates events
4. Queue system persists events
5. Integration testing validates flow

**Coordination**:
```typescript
// Sequential with dependencies
const hookTests = await runSubagent("unit-test-generator", { feature: "hooks" });
const hooks = await runSubagent("hook-developer-agent", { tests: hookTests });

// Event collector needs hooks
const collectorTests = await runSubagent("unit-test-generator", { feature: "event-collector" });
const collector = await runSubagent("event-collector-agent", {
  tests: collectorTests,
  hooks: hooks
});

// Queue system needs collector schema
const queueTests = await runSubagent("unit-test-generator", { feature: "queue" });
const queue = await runSubagent("queue-system-agent", {
  tests: queueTests,
  schema: collector.eventSchema
});
```

### Phase 2: Sanitization

**Subagents**:
- `rule-sanitizer-agent`: Regex patterns
- `ai-sanitizer-agent`: LLM sanitization
- `sanitization-pipeline-agent`: Orchestration

**Workflow**:
1. Build gold dataset first
2. Rule sanitizer in parallel with AI sanitizer
3. Pipeline orchestrator combines both
4. Validation with precision/recall metrics

**Coordination**:
```typescript
// Create gold dataset first
const goldDataset = await runSubagent("dataset-builder-agent", {
  categories: ["email", "phone", "ip", "path", "key", "url"],
  size: 1000
});

// Parallel sanitizer development
const [ruleTests, aiTests] = await Promise.all([
  runSubagent("unit-test-generator", { feature: "rule-sanitizer", dataset: goldDataset }),
  runSubagent("unit-test-generator", { feature: "ai-sanitizer", dataset: goldDataset })
]);

const [ruleSanitizer, aiSanitizer] = await Promise.all([
  runSubagent("rule-sanitizer-agent", { tests: ruleTests, dataset: goldDataset }),
  runSubagent("ai-sanitizer-agent", { tests: aiTests, dataset: goldDataset })
]);

// Pipeline combines both
const pipelineTests = await runSubagent("integration-test-generator", { feature: "sanitization-pipeline" });
const pipeline = await runSubagent("sanitization-pipeline-agent", {
  tests: pipelineTests,
  ruleSanitizer,
  aiSanitizer,
  dataset: goldDataset
});
```

## Quality Gate Details

### Coverage Gate

**Validator**: `coverage-validator`

**Requirements**:
- Line coverage ≥ 85%
- Statement coverage ≥ 85%
- Function coverage ≥ 85%
- Branch coverage ≥ 80%

**Process**:
```bash
vitest run --coverage
```

**Gate**:
```typescript
if (coverage.lines < 0.85 || coverage.statements < 0.85 ||
    coverage.functions < 0.85 || coverage.branches < 0.80) {
  throw new Error(`Coverage insufficient: ${JSON.stringify(coverage)}`);
}
```

### Code Quality Gate

**Validator**: `code-quality-validator`

**Requirements**:
- ESLint clean
- Prettier formatted
- TypeScript strict mode compliant
- No `any` types
- Clear naming conventions

**Process**:
```bash
npm run lint
npm run type-check
```

**Gate**: All checks must pass

### Security Gate

**Validator**: `security-validator`

**Requirements**:
- No SQL injection vectors
- No command injection
- No path traversal
- No hardcoded secrets
- No insecure dependencies

**Process**:
```bash
npm audit
grep -r "apiKey.*=" src/  # Example check
```

**Gate**: Zero critical issues

### Performance Gate

**Validator**: `performance-validator`

**Requirements**:
- Hooks < 100ms (p95)
- DB queries < 100ms
- MCP queries < 200ms
- Sanitization < 2s per conversation

**Process**: Benchmark tests with realistic data

**Gate**: All SLOs met

## Error Handling in Workflows

### Subagent Failure

**Strategy**: Retry with exponential backoff

```typescript
async function runWithRetry(agentName: string, input: any, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await runSubagent(agentName, input);
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await sleep(2 ** i * 1000);
    }
  }
}
```

### Quality Gate Failure

**Strategy**: Block and report

```typescript
if (!qualityGatePassed) {
  // Log detailed failure reasons
  console.error("Quality gate failed:", {
    coverage: coverageCheck,
    codeQuality: codeQualityCheck,
    security: securityCheck,
    performance: perfCheck
  });

  // Block merge/commit
  throw new Error("Quality gates must pass before proceeding");
}
```

### Test Flakiness

**Strategy**: Deterministic tests only

- Pin LLM model/version
- Use temperature=0 for AI calls
- Snapshot test outputs
- Avoid time-dependent assertions
- Mock external dependencies

## Monitoring Subagent Performance

### Metrics to Track

- Subagent invocation count
- Success rate per subagent
- Average execution time
- Error types and frequency
- Quality gate pass rate

### Dashboard (Future)

```typescript
{
  "unit-test-generator": {
    "invocations": 150,
    "successRate": 0.98,
    "avgDuration": "45s",
    "qualityScore": 0.87
  },
  "hook-developer-agent": {
    "invocations": 12,
    "successRate": 1.0,
    "avgDuration": "3m 20s",
    "testsPass": true
  }
}
```

## Related Documents

- [Subagent System Architecture](../architecture/architecture-subagent-system-2025-01-16.md)
- [Implementation Roadmap](./plan-implementation-roadmap-2025-01-16.md)
- [TDD Workflow Guide](../guides/guide-tdd-workflow-2025-01-16.md)
- [Using Subagents Guide](../guides/guide-using-subagents-2025-01-16.md)

================
File: reference/INDEX.md
================
# Reference Documentation

> Last updated: 2025-01-16

## Overview

This directory contains technical reference materials, API documentation, schemas, and specifications for the Global Context Network MVP. Reference docs are designed for quick lookup during implementation.

## Documents

### Active Documents

| Date | Document | Description |
|------|----------|-------------|
| 2025-01-16 | [reference-testing-strategy-2025-01-16.md](./reference-testing-strategy-2025-01-16.md) | Complete testing strategy with TDD, coverage requirements, and test organization |
| 2025-01-16 | [reference-subagent-types-2025-01-16.md](./reference-subagent-types-2025-01-16.md) | Catalog of all 22 subagent types with configurations and prompts |
| 2025-01-16 | [reference-database-schema-2025-01-16.md](./reference-database-schema-2025-01-16.md) | Complete SQLite schema with tables, indexes, migrations, and query patterns |
| 2025-01-16 | [reference-claude-agent-sdk-api-2025-01-16.md](./reference-claude-agent-sdk-api-2025-01-16.md) | Claude Agent SDK API reference with subagent patterns and MCP integration |

## Quick Reference

### Testing Strategy

**Coverage Requirements**:
- Global: ≥85% lines, ≥70% branches
- Critical path: 100% lines, 90% branches
- Test pyramid: 70% unit, 20% integration, 10% E2E

**Key Commands**:
```bash
pnpm test:unit           # Unit tests
pnpm test:integration    # Integration tests
pnpm test:e2e           # End-to-end tests
pnpm test:coverage      # Coverage report
pnpm test:watch         # Watch mode
```

**TDD Cycle**: Red (failing test) → Green (minimal implementation) → Refactor (improve quality)

### Subagent Types

**Total**: 22 subagents
- **14 Implementation**: foundation-setup, database-schema, hook-developer, etc.
- **3 Test Generation**: unit-test-generator, integration-test-generator, e2e-test-generator
- **3 Test Validation**: test-quality-validator, coverage-validator, implementation-validator
- **3 Quality Gates**: code-quality-validator, security-validator, performance-validator

**Model Selection**:
- **Sonnet**: Complex reasoning, code generation, validation
- **Haiku**: Simple tasks, quick validations, high-volume operations

### Database Schema

**Tables**: 6 core tables
- `conversations` - Sanitized conversation metadata
- `messages` - Individual sanitized messages
- `learnings` - Extracted insights with FTS5
- `job_queue` - Async job processing
- `uploads` - Network upload tracking
- `sanitization_log` - PII detection audit trail

**Critical**: NEVER store unsanitized data. `sanitized` column always = 1.

**Required PRAGMAs**:
```sql
PRAGMA foreign_keys = ON;
PRAGMA journal_mode = WAL;
PRAGMA synchronous = FULL;
```

### Claude Agent SDK API

**Main Function**: `query(options: QueryOptions)`

**Agent Definition**:
```typescript
{
  description: string;
  model: 'sonnet' | 'haiku';
  tools: string[];
  prompt: string;
  output_schema?: JSONSchema;
  timeout_ms?: number;
}
```

**Execution Patterns**:
- **Parallel**: Independent subagents run simultaneously
- **Sequential**: Dependent subagents run in order
- **Fan-out/Fan-in**: Multiple validators, merge results

## Document Usage

### By Role

**For Developers**:
1. Start with Testing Strategy for TDD workflow
2. Reference Database Schema for queries and repositories
3. Use Claude Agent SDK API for subagent integration
4. Consult Subagent Types for specific agent configs

**For Testing**:
1. Testing Strategy for coverage requirements
2. Subagent Types for test generator configs
3. Database Schema for test database setup
4. Claude Agent SDK API for mocking

**For Architecture Review**:
1. Database Schema for data model validation
2. Subagent Types for agent responsibilities
3. Claude Agent SDK API for integration patterns
4. Testing Strategy for quality gates

### By Phase

**Phase 0 (Foundation)**:
- Testing Strategy: Vitest configuration
- Database Schema: Initial migration
- Subagent Types: foundation-setup, database-schema, test-infrastructure

**Phase 1 (Event Capture)**:
- Subagent Types: hook-developer, event-collector, queue-system
- Database Schema: conversations, messages, job_queue tables
- Testing Strategy: Hook performance tests

**Phase 2 (Sanitization)**:
- Subagent Types: rule-sanitizer, ai-sanitizer, sanitization-pipeline
- Database Schema: sanitization_log table
- Testing Strategy: Security testing, PII corpus

**Phase 3-7 (Later Phases)**:
- Refer to respective subagents
- Database Schema: learnings, uploads tables
- Testing Strategy: Integration and E2E tests

## Cross-References

### Related Categories

- **[Architecture](../architecture/INDEX.md)**: System design and component architecture
- **[Guides](../guides/INDEX.md)**: Step-by-step how-to guides
- **[Decisions](../decisions/INDEX.md)**: ADRs explaining technical choices
- **[Plans](../plans/INDEX.md)**: Implementation roadmaps and task breakdowns

### Key Cross-Links

**Testing Strategy** ↔ **Subagent Types**:
- Test generator subagents (unit, integration, E2E)
- Validation subagents (quality, coverage, implementation)

**Database Schema** ↔ **Testing Strategy**:
- In-memory test database setup
- Fixture factories
- Repository testing patterns

**Claude Agent SDK API** ↔ **Subagent Types**:
- Agent configuration examples
- Orchestration patterns
- MCP integration

**All References** ↔ **Architecture**:
- Architecture provides context
- References provide implementation details

## Version Information

### Schema Version
- **Database**: 1.0.0
- **Sanitization**: 1.0.0
- **API**: Claude Agent SDK 1.x

### Applies To
- **SQLite**: 3.40+
- **Node.js**: 20+
- **TypeScript**: 5.x
- **Vitest**: 1.x
- **Claude Models**: Sonnet 4.5, Haiku 3.5

## Quick Lookup Tables

### Coverage Thresholds

| Scope | Lines | Statements | Branches | Functions |
|-------|-------|------------|----------|-----------|
| Global | 85% | 85% | 70% | 85% |
| Critical Path | 100% | 100% | 90% | 100% |
| Infrastructure | 50% | 50% | 30% | 50% |

### Performance SLAs

| Component | P50 | P95 | P99 | Max |
|-----------|-----|-----|-----|-----|
| Hooks | <50ms | <100ms | <150ms | 200ms |
| Sanitization | <1s | <2s | <3s | 5s |
| DB Queries | <50ms | <100ms | <200ms | 500ms |
| MCP Queries | <100ms | <200ms | <500ms | 1s |

### Subagent Models

| Task Type | Model | Rationale |
|-----------|-------|-----------|
| Complex reasoning | Sonnet | Better quality |
| Code generation | Sonnet | Type-safe code |
| Simple validation | Haiku | Fast, cost-effective |
| High-volume ops | Haiku | Throughput |

### Database Indexes

| Table | Index | Purpose |
|-------|-------|---------|
| conversations | idx_conversations_session | Session queries |
| conversations | idx_conversations_created | Recent conversations |
| messages | idx_messages_conversation | Conversation messages |
| learnings | idx_learnings_category | Category filtering |
| learnings_fts | FTS5 | Full-text search |
| job_queue | idx_job_queue_dequeue | Worker queries |

## Maintenance

### Updating References

When updating reference docs:

1. **Update version metadata** in frontmatter
2. **Add changelog entry** if schema/API changes
3. **Update this INDEX** with changes
4. **Cross-link** with related architecture docs
5. **Verify code examples** still work

### Schema Evolution

When database schema changes:

1. Create new migration file
2. Update reference-database-schema with new DDL
3. Update repository examples
4. Note breaking changes in changelog
5. Bump schema version

### API Changes

When Claude Agent SDK API changes:

1. Update reference-claude-agent-sdk-api
2. Update code examples
3. Test against new SDK version
4. Update "applies_to" metadata
5. Note deprecations

## Contributing

### Reference Doc Template

```markdown
# [Topic] Reference

> Brief description

---
title: [Topic] Reference
category: reference
date: YYYY-MM-DD
status: active
authors: Claude + Dennison
tags: [relevant, tags]
applies_to: Versions/Tools
---

## Overview
[What this reference covers]

## [Section 1]
[Technical details, code examples, tables]

## [Section 2]
[More technical content]

## Related Documents
[Cross-links to architecture, guides, etc.]
```

### Quality Checklist

- ✅ Clear, concise descriptions
- ✅ Complete code examples (runnable)
- ✅ Type signatures and schemas
- ✅ Performance characteristics noted
- ✅ Common pitfalls documented
- ✅ Cross-references complete
- ✅ Version information current
- ✅ Tables formatted consistently

---

*This index provides quick access to all technical reference materials for the Global Context Network MVP.*

================
File: reference/reference-claude-agent-sdk-api-2025-01-16.md
================
# Claude Agent SDK API Reference

> Complete API reference for Claude Agent SDK with subagent patterns and MCP integration

---
title: Claude Agent SDK API Reference
category: reference
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [claude-agent-sdk, api, subagents, mcp, typescript]
applies_to: Claude Agent SDK 1.x, Sonnet 4.5, Haiku 3.5
---

## Overview

The Claude Agent SDK enables building AI agents with specialized subagents, MCP tool integration, and structured workflows. This document provides complete API reference and best practices.

**Package**: `@anthropic-ai/claude-agent-sdk` (verify actual package name)
**Models**: `claude-sonnet-4-5-20250929`, `claude-haiku-3-5-20250318`

---

## Core API

### query()

Main entry point for delegating tasks to subagents.

**Signature**:
```typescript
function query(options: QueryOptions): AsyncIterable<Message>;

interface QueryOptions {
  prompt: string;
  options?: {
    model?: string;
    agents?: Record<string, AgentDefinition>;
    mcpServers?: Record<string, MCPServerConfig>;
    maxTokens?: number;
    temperature?: number;
    abortSignal?: AbortSignal;
  };
}
```

**Parameters**:
- `prompt` (required): Main task description
- `options.model`: Model ID (default: `claude-sonnet-4-5-20250929`)
- `options.agents`: Subagent definitions (see AgentDefinition)
- `options.mcpServers`: MCP server configurations
- `options.maxTokens`: Token budget (default: 4096)
- `options.temperature`: Randomness 0-1 (default: 1.0)
- `options.abortSignal`: Cancellation signal

**Returns**: Async iterable of messages

**Example**:
```typescript
import { query } from '@anthropic-ai/claude-agent-sdk';

const response = query({
  prompt: 'Implement user authentication',
  options: {
    model: 'claude-sonnet-4-5-20250929',
    agents: {
      'implementation-agent': {
        description: 'Implements authentication logic',
        model: 'sonnet',
        tools: ['Write', 'Read', 'Bash'],
        prompt: 'You are an authentication expert...'
      }
    }
  }
});

for await (const message of response) {
  if (message.type === 'text') {
    console.log(message.content);
  }
}
```

---

### Message Types

**Event Stream Format**:
```typescript
type Message =
  | TextMessage
  | ToolCallMessage
  | ToolResultMessage
  | SubagentStartMessage
  | SubagentProgressMessage
  | SubagentEndMessage
  | ErrorMessage
  | LogMessage;

interface TextMessage {
  type: 'text';
  content: string;
  role: 'user' | 'assistant';
  correlation_id?: string;
}

interface ToolCallMessage {
  type: 'tool_call';
  tool_name: string;
  tool_input: any;
  tool_call_id: string;
  correlation_id?: string;
}

interface ToolResultMessage {
  type: 'tool_result';
  tool_call_id: string;
  result: any;
  error?: string;
  correlation_id?: string;
}

interface SubagentStartMessage {
  type: 'system';
  subtype: 'subagent_start';
  agent_name: string;
  agent_description: string;
  correlation_id: string;
  timestamp: string;
}

interface SubagentProgressMessage {
  type: 'system';
  subtype: 'subagent_progress';
  agent_name: string;
  progress: number; // 0-1
  message: string;
  correlation_id: string;
  timestamp: string;
}

interface SubagentEndMessage {
  type: 'system';
  subtype: 'subagent_end';
  agent_name: string;
  result: any;
  success: boolean;
  error?: string;
  correlation_id: string;
  timestamp: string;
  duration_ms: number;
}

interface ErrorMessage {
  type: 'error';
  error_type: string; // 'api_error' | 'tool_error' | 'timeout' | 'rate_limit'
  error_message: string;
  error_code?: string;
  correlation_id?: string;
  retry_after_ms?: number; // For rate limits
}

interface LogMessage {
  type: 'log';
  level: 'debug' | 'info' | 'warn' | 'error';
  message: string;
  correlation_id?: string;
  metadata?: any;
}
```

---

## Subagent Configuration

### AgentDefinition

```typescript
interface AgentDefinition {
  name?: string; // Auto-set from key if not provided
  description: string; // What this agent does
  model: 'sonnet' | 'haiku' | string; // Model selection
  tools: string[]; // Available tool names
  resources?: string[]; // MCP resources
  prompt: string; // System prompt for agent
  output_schema?: JSONSchema; // Expected output format
  temperature?: number; // 0-1, default 1.0
  max_tokens?: number; // Token budget
  stop_sequences?: string[]; // Stop generation at these
  timeout_ms?: number; // Max execution time
  retry_policy?: RetryPolicy;
  metadata?: any; // Custom metadata
}

interface RetryPolicy {
  max_retries: number; // Default 3
  initial_delay_ms: number; // Default 1000
  max_delay_ms: number; // Default 60000
  backoff_multiplier: number; // Default 2 (exponential)
}

interface JSONSchema {
  type: 'object' | 'array' | 'string' | 'number' | 'boolean';
  properties?: Record<string, JSONSchema>;
  items?: JSONSchema;
  required?: string[];
  enum?: any[];
  // ... standard JSON Schema fields
}
```

**Example: Implementation Agent**:
```typescript
const implementationAgent: AgentDefinition = {
  description: 'Implements TypeScript functions following TDD',
  model: 'sonnet',
  tools: ['Write', 'Read', 'Bash'],
  prompt: `You are a TypeScript implementation expert.

REQUIREMENTS:
- Write type-safe code with strict mode
- Never use "any" types
- Follow TDD: tests exist before implementation
- Handle errors gracefully
- Add JSDoc comments

OUTPUT FORMAT:
Return JSON with:
- files_created: string[]
- tests_passing: boolean
- coverage_percentage: number
`,
  output_schema: {
    type: 'object',
    properties: {
      files_created: { type: 'array', items: { type: 'string' } },
      tests_passing: { type: 'boolean' },
      coverage_percentage: { type: 'number' }
    },
    required: ['files_created', 'tests_passing']
  },
  temperature: 0.7, // Slightly more focused
  max_tokens: 8192,
  timeout_ms: 120000, // 2 minutes
  retry_policy: {
    max_retries: 3,
    initial_delay_ms: 1000,
    max_delay_ms: 30000,
    backoff_multiplier: 2
  }
};
```

**Example: Test Generator**:
```typescript
const testGenerator: AgentDefinition = {
  description: 'Generates comprehensive unit tests',
  model: 'sonnet',
  tools: ['Write', 'Read', 'mcp__test-runner__run_unit_tests'],
  prompt: `You are a test generation expert.

Generate unit tests with:
- Arrange-Act-Assert pattern
- Edge cases (null, undefined, empty, boundary values)
- Error conditions
- Clear test names
- Proper mocking

TARGET: >85% coverage with high-quality tests
`,
  output_schema: {
    type: 'object',
    properties: {
      test_files: { type: 'array', items: { type: 'string' } },
      coverage: { type: 'number' },
      test_count: { type: 'number' }
    },
    required: ['test_files', 'coverage']
  },
  max_tokens: 16384, // More for comprehensive tests
  timeout_ms: 180000 // 3 minutes
};
```

---

## MCP Integration

### MCPServerConfig

```typescript
interface MCPServerConfig {
  name: string;
  command: string; // Executable path
  args?: string[]; // Command arguments
  env?: Record<string, string>; // Environment variables
  capabilities?: {
    tools?: boolean;
    resources?: boolean;
    prompts?: boolean;
  };
  timeout_ms?: number;
}
```

**Example: Test Runner MCP Server**:
```typescript
const testRunnerServer: MCPServerConfig = {
  name: 'test-runner',
  command: 'node',
  args: ['./mcp-servers/test-runner/index.js'],
  env: {
    NODE_ENV: 'test'
  },
  capabilities: {
    tools: true,
    resources: true
  },
  timeout_ms: 30000
};

// Use in query
const response = query({
  prompt: 'Run unit tests',
  options: {
    mcpServers: {
      'test-runner': testRunnerServer
    }
  }
});
```

### MCP Tool Definition

```typescript
// In your MCP server (test-runner/index.js)
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';

const server = new Server({
  name: 'test-runner',
  version: '1.0.0'
}, {
  capabilities: {
    tools: {},
    resources: {}
  }
});

// Define tools
server.setRequestHandler('tools/list', async () => {
  return {
    tools: [
      {
        name: 'run_unit_tests',
        description: 'Runs unit tests and returns results',
        inputSchema: {
          type: 'object',
          properties: {
            test_pattern: {
              type: 'string',
              description: 'Test file pattern (e.g., "**/*.test.ts")'
            },
            watch: {
              type: 'boolean',
              description: 'Run in watch mode',
              default: false
            }
          }
        }
      },
      {
        name: 'get_coverage_report',
        description: 'Returns coverage report',
        inputSchema: {
          type: 'object',
          properties: {}
        }
      }
    ]
  };
});

// Implement tool calls
server.setRequestHandler('tools/call', async (request) => {
  const { name, arguments: args } = request.params;

  if (name === 'run_unit_tests') {
    const { test_pattern = '**/*.test.ts', watch = false } = args;

    // Run tests
    const result = await runVitest({ pattern: test_pattern, watch });

    return {
      content: [
        {
          type: 'text',
          text: JSON.stringify({
            total: result.total,
            passed: result.passed,
            failed: result.failed,
            duration_ms: result.duration,
            coverage: result.coverage
          }, null, 2)
        }
      ]
    };
  }

  throw new Error(`Unknown tool: ${name}`);
});

// Start server
const transport = new StdioServerTransport();
await server.connect(transport);
```

### MCP Resource Definition

```typescript
// Define resources
server.setRequestHandler('resources/list', async () => {
  return {
    resources: [
      {
        uri: 'test://coverage/summary',
        name: 'Coverage Summary',
        description: 'Current test coverage summary',
        mimeType: 'application/json'
      },
      {
        uri: 'test://results/latest',
        name: 'Latest Test Results',
        description: 'Most recent test run results',
        mimeType: 'application/json'
      }
    ]
  };
});

// Implement resource reads
server.setRequestHandler('resources/read', async (request) => {
  const { uri } = request.params;

  if (uri === 'test://coverage/summary') {
    const coverage = await getCoverageSummary();

    return {
      contents: [
        {
          uri,
          mimeType: 'application/json',
          text: JSON.stringify(coverage, null, 2)
        }
      ]
    };
  }

  throw new Error(`Unknown resource: ${uri}`);
});
```

---

## Execution Patterns

### Parallel Execution

When subagents have no dependencies, run them in parallel:

```typescript
const response = query({
  prompt: 'Implement Phase 0 Foundation',
  options: {
    agents: {
      'foundation-setup': foundationSetupAgent,
      'database-schema': databaseSchemaAgent,
      'test-infrastructure': testInfraAgent
    }
  }
});

const results: Record<string, any> = {};

for await (const message of response) {
  if (message.type === 'system' && message.subtype === 'subagent_end') {
    results[message.agent_name] = message.result;
    console.log(`✅ ${message.agent_name} completed in ${message.duration_ms}ms`);
  }
}

// All three agents ran in parallel
console.log('All agents complete:', results);
```

### Sequential with Dependencies

When subagents depend on each other's outputs:

```typescript
// Step 1: Generate tests
const testResult = await runSubagent('test-generator', {
  function_name: 'detectAPIKeys',
  requirements: 'Detect AWS, OpenAI, GitHub API keys'
});

// Step 2: Implement (needs test output)
const implResult = await runSubagent('implementation-agent', {
  tests: testResult.test_files,
  requirements: 'Implement to pass tests'
});

// Step 3: Validate (needs both)
const validationResult = await runSubagent('implementation-validator', {
  implementation: implResult.files_created,
  tests: testResult.test_files
});

// Helper function
async function runSubagent(agentName: string, input: any): Promise<any> {
  const response = query({
    prompt: JSON.stringify(input),
    options: {
      agents: {
        [agentName]: agentConfigs[agentName]
      }
    }
  });

  let result: any = null;

  for await (const message of response) {
    if (message.type === 'system' && message.subtype === 'subagent_end') {
      result = message.result;
    }
  }

  return result;
}
```

### Fan-Out / Fan-In

Run multiple subagents, then merge results:

```typescript
async function runValidators(code: string): Promise<ValidationReport> {
  const response = query({
    prompt: `Validate this code:\n${code}`,
    options: {
      agents: {
        'code-quality': codeQualityValidator,
        'security': securityValidator,
        'performance': performanceValidator
      }
    }
  });

  const validationResults: Record<string, any> = {};

  for await (const message of response) {
    if (message.type === 'system' && message.subtype === 'subagent_end') {
      validationResults[message.agent_name] = message.result;
    }
  }

  // Merge results
  return {
    code_quality: validationResults['code-quality'],
    security: validationResults['security'],
    performance: validationResults['performance'],
    overall_pass: Object.values(validationResults).every(r => r.passed)
  };
}
```

---

## Error Handling

### Error Types

```typescript
class APIError extends Error {
  constructor(
    message: string,
    public code: string,
    public status?: number
  ) {
    super(message);
    this.name = 'APIError';
  }
}

class ToolError extends Error {
  constructor(
    message: string,
    public tool_name: string,
    public tool_input: any
  ) {
    super(message);
    this.name = 'ToolError';
  }
}

class TimeoutError extends Error {
  constructor(
    message: string,
    public timeout_ms: number
  ) {
    super(message);
    this.name = 'TimeoutError';
  }
}

class RateLimitError extends Error {
  constructor(
    message: string,
    public retry_after_ms: number
  ) {
    super(message);
    this.name = 'RateLimitError';
  }
}
```

### Retry Logic

```typescript
async function queryWithRetry(
  options: QueryOptions,
  maxRetries = 3
): Promise<any> {
  let lastError: Error | null = null;

  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      const response = query(options);
      let result: any = null;

      for await (const message of response) {
        if (message.type === 'error') {
          throw new APIError(
            message.error_message,
            message.error_code || 'unknown',
            message.retry_after_ms
          );
        }

        if (message.type === 'system' && message.subtype === 'subagent_end') {
          if (!message.success) {
            throw new Error(message.error || 'Subagent failed');
          }
          result = message.result;
        }
      }

      return result;

    } catch (error) {
      lastError = error as Error;

      // Don't retry on validation errors
      if (error instanceof Error && error.message.includes('validation')) {
        throw error;
      }

      // Rate limit: wait before retry
      if (error instanceof RateLimitError) {
        await sleep(error.retry_after_ms);
        continue;
      }

      // Exponential backoff
      const backoffMs = Math.min(1000 * Math.pow(2, attempt), 60000);
      await sleep(backoffMs);
    }
  }

  throw lastError || new Error('Max retries exceeded');
}

function sleep(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms));
}
```

### Graceful Degradation

```typescript
async function sanitizeWithFallback(content: string): Promise<string> {
  try {
    // Try AI sanitization first
    const result = await runSubagent('ai-sanitizer', { content });
    return result.sanitized_content;

  } catch (error) {
    console.warn('AI sanitization failed, falling back to rules:', error);

    // Fallback to rule-based
    const result = await runSubagent('rule-sanitizer', { content });
    return result.sanitized_content;
  }
}
```

---

## Best Practices

### When to Use Subagents

**✅ Use subagents for**:
- Complex, multi-step tasks
- Tasks requiring specialized expertise
- Tasks that can run in parallel
- Tasks requiring different model sizes (Sonnet vs Haiku)
- Tasks needing different tool sets

**❌ Don't use subagents for**:
- Simple, single-step operations
- Tasks where delegation overhead > task complexity
- Tightly coupled operations better done in one context

### Model Selection

**Sonnet (claude-sonnet-4-5)**:
- Complex reasoning
- Code generation
- Architecture decisions
- Creative tasks
- Quality validation

**Haiku (claude-haiku-3-5)**:
- Simple transformations
- Format conversions
- Quick validations
- High-volume operations
- Cost-sensitive tasks

**Example**:
```typescript
const agents = {
  // Sonnet for complex implementation
  'implementation': {
    model: 'claude-sonnet-4-5-20250929',
    description: 'Implements complex authentication logic',
    // ...
  },

  // Haiku for simple validation
  'coverage-checker': {
    model: 'claude-haiku-3-5-20250318',
    description: 'Checks if coverage >= 85%',
    // ...
  }
};
```

### Output Schema Validation

Always validate subagent outputs:

```typescript
import Ajv from 'ajv';

const ajv = new Ajv();

async function runSubagentWithValidation(
  agentName: string,
  input: any,
  expectedSchema: JSONSchema
): Promise<any> {
  const result = await runSubagent(agentName, input);

  const validate = ajv.compile(expectedSchema);
  if (!validate(result)) {
    throw new Error(`Invalid output from ${agentName}: ${JSON.stringify(validate.errors)}`);
  }

  return result;
}

// Usage
const result = await runSubagentWithValidation(
  'implementation-agent',
  { function: 'detectAPIKeys' },
  {
    type: 'object',
    properties: {
      files_created: { type: 'array', items: { type: 'string' } },
      tests_passing: { type: 'boolean' }
    },
    required: ['files_created', 'tests_passing']
  }
);
```

### Correlation IDs

Track execution across subagents:

```typescript
import { randomUUID } from 'crypto';

async function runWithCorrelation(taskName: string, fn: () => Promise<any>): Promise<any> {
  const correlationId = randomUUID();

  console.log(`[${correlationId}] Starting: ${taskName}`);

  try {
    const result = await fn();
    console.log(`[${correlationId}] Success: ${taskName}`);
    return result;
  } catch (error) {
    console.error(`[${correlationId}] Failed: ${taskName}`, error);
    throw error;
  }
}
```

### Cost Tracking

Monitor token usage and costs:

```typescript
interface UsageStats {
  total_tokens: number;
  input_tokens: number;
  output_tokens: number;
  cost_usd: number;
}

const PRICING = {
  'claude-sonnet-4-5': {
    input: 0.003 / 1000,  // $3 per 1M input tokens
    output: 0.015 / 1000  // $15 per 1M output tokens
  },
  'claude-haiku-3-5': {
    input: 0.00025 / 1000,  // $0.25 per 1M input tokens
    output: 0.00125 / 1000  // $1.25 per 1M output tokens
  }
};

function calculateCost(usage: UsageStats, model: string): number {
  const pricing = PRICING[model as keyof typeof PRICING];
  if (!pricing) return 0;

  return (
    usage.input_tokens * pricing.input +
    usage.output_tokens * pricing.output
  );
}

async function runWithCostTracking(options: QueryOptions): Promise<{ result: any; cost: number }> {
  let totalInputTokens = 0;
  let totalOutputTokens = 0;

  const response = query(options);
  let result: any = null;

  for await (const message of response) {
    // Track usage from messages
    if ('usage' in message) {
      totalInputTokens += message.usage?.input_tokens || 0;
      totalOutputTokens += message.usage?.output_tokens || 0;
    }

    if (message.type === 'system' && message.subtype === 'subagent_end') {
      result = message.result;
    }
  }

  const cost = calculateCost(
    {
      total_tokens: totalInputTokens + totalOutputTokens,
      input_tokens: totalInputTokens,
      output_tokens: totalOutputTokens,
      cost_usd: 0
    },
    options.options?.model || 'claude-sonnet-4-5-20250929'
  );

  return { result, cost };
}
```

---

## Testing with SDK

### Mocking the SDK

```typescript
import { vi } from 'vitest';

export function mockQuery(responses: Array<Message[]>) {
  let callCount = 0;

  return vi.fn((options: QueryOptions) => {
    const messages = responses[callCount] || [];
    callCount++;

    return (async function* () {
      for (const message of messages) {
        yield message;
      }
    })();
  });
}

// Usage in tests
it('should handle subagent success', async () => {
  const mockQueryFn = mockQuery([
    [
      {
        type: 'system',
        subtype: 'subagent_start',
        agent_name: 'test-agent',
        correlation_id: '123',
        timestamp: new Date().toISOString()
      },
      {
        type: 'system',
        subtype: 'subagent_end',
        agent_name: 'test-agent',
        result: { files_created: ['test.ts'] },
        success: true,
        correlation_id: '123',
        timestamp: new Date().toISOString(),
        duration_ms: 1000
      }
    ]
  ]);

  // Test your function that uses query()
  const result = await myFunction(mockQueryFn);

  expect(result).toEqual({ files_created: ['test.ts'] });
});
```

### Testing MCP Servers

```typescript
import { createMockMCPServer } from '../helpers/mock-mcp-server';

it('should call MCP tool correctly', async () => {
  const mockServer = createMockMCPServer();

  mockServer.addTool('run_unit_tests', async (args) => {
    return {
      total: 10,
      passed: 10,
      failed: 0
    };
  });

  const response = query({
    prompt: 'Run tests',
    options: {
      mcpServers: {
        'test-runner': mockServer.config
      }
    }
  });

  // Assert tool was called
  expect(mockServer.toolCalls['run_unit_tests']).toHaveLength(1);
});
```

---

## Complete Example

### TDD Workflow with Subagents

```typescript
import { query } from '@anthropic-ai/claude-agent-sdk';

interface TDDResult {
  tests_created: string[];
  implementation_created: string[];
  all_tests_passing: boolean;
  coverage: number;
}

async function implementFeatureTDD(
  featureName: string,
  requirements: string
): Promise<TDDResult> {
  console.log(`\n🔴 RED: Generating failing tests for ${featureName}...`);

  // Step 1: Generate tests
  const testGenResult = await runSubagent('test-generator', {
    feature: featureName,
    requirements
  });

  console.log(`✅ Tests created: ${testGenResult.test_files.join(', ')}`);

  console.log(`\n🟢 GREEN: Implementing ${featureName}...`);

  // Step 2: Implement
  const implResult = await runSubagent('implementation-agent', {
    feature: featureName,
    requirements,
    tests: testGenResult.test_files
  });

  console.log(`✅ Implementation created: ${implResult.files_created.join(', ')}`);

  console.log(`\n🔵 REFACTOR: Validating quality...`);

  // Step 3: Validate quality (parallel)
  const validationResponse = query({
    prompt: `Validate ${featureName} implementation`,
    options: {
      agents: {
        'code-quality': codeQualityValidator,
        'security': securityValidator,
        'coverage': coverageValidator
      }
    }
  });

  const validations: Record<string, any> = {};

  for await (const message of validationResponse) {
    if (message.type === 'system' && message.subtype === 'subagent_end') {
      validations[message.agent_name] = message.result;

      if (!message.success) {
        throw new Error(`${message.agent_name} failed: ${message.error}`);
      }
    }
  }

  console.log(`\n✅ All quality gates passed!`);

  return {
    tests_created: testGenResult.test_files,
    implementation_created: implResult.files_created,
    all_tests_passing: implResult.tests_passing,
    coverage: validations['coverage'].percentage
  };
}

// Agent configurations
const testGenerator = {
  description: 'Generates comprehensive unit tests',
  model: 'sonnet',
  tools: ['Write', 'Read'],
  prompt: `Generate unit tests following TDD best practices...`,
  output_schema: {
    type: 'object',
    properties: {
      test_files: { type: 'array', items: { type: 'string' } },
      test_count: { type: 'number' }
    },
    required: ['test_files']
  }
};

const implementationAgent = {
  description: 'Implements features to pass tests',
  model: 'sonnet',
  tools: ['Write', 'Read', 'Bash'],
  prompt: `Implement features following TDD...`,
  output_schema: {
    type: 'object',
    properties: {
      files_created: { type: 'array', items: { type: 'string' } },
      tests_passing: { type: 'boolean' }
    },
    required: ['files_created', 'tests_passing']
  }
};

const codeQualityValidator = {
  description: 'Validates code quality',
  model: 'sonnet',
  tools: ['Read', 'Bash'],
  prompt: `Check code quality standards...`
};

const securityValidator = {
  description: 'Scans for security issues',
  model: 'sonnet',
  tools: ['Read', 'Bash'],
  prompt: `Scan for security vulnerabilities...`
};

const coverageValidator = {
  description: 'Checks test coverage',
  model: 'haiku', // Simple task
  tools: ['Bash', 'Read'],
  prompt: `Calculate test coverage percentage...`
};

// Usage
const result = await implementFeatureTDD(
  'API Key Detection',
  'Detect AWS, OpenAI, and GitHub API keys in content'
);

console.log(JSON.stringify(result, null, 2));
```

---

## Related Documents

### Architecture
- [Subagent System Architecture](../architecture/architecture-subagent-system-2025-01-16.md)
- [Global Context Network](../architecture/architecture-global-context-network-2025-01-16.md)

### Reference
- [Subagent Types](./reference-subagent-types-2025-01-16.md)
- [Testing Strategy](./reference-testing-strategy-2025-01-16.md)

### Guides
- [Using Subagents](../guides/guide-using-subagents-2025-01-16.md)
- [TDD Workflow](../guides/guide-tdd-workflow-2025-01-16.md)

================
File: reference/reference-database-schema-2025-01-16.md
================
# Database Schema Reference

> Complete SQLite database schema with tables, indexes, migrations, and query patterns

---
title: Database Schema Reference
category: reference
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [database, sqlite, schema, migrations, sql]
applies_to: SQLite 3.40+, better-sqlite3 9.x
schema_version: 1.0.0
---

## Overview

The Global Context Network uses SQLite with WAL mode for local persistence. All data MUST be sanitized before insertion - there are NO raw content columns.

**Core Principle**: Never store unsanitized data. Sanitization happens BEFORE database insertion.

### Database Configuration

```sql
-- Required PRAGMAs (set on every connection)
PRAGMA foreign_keys = ON;
PRAGMA journal_mode = WAL;
PRAGMA synchronous = FULL;
PRAGMA busy_timeout = 5000;
PRAGMA page_size = 8192;
```

### Connection Setup

```typescript
import Database from 'better-sqlite3';

export function createDatabase(path: string): Database.Database {
  const db = new Database(path);

  // Enable required PRAGMAs
  db.pragma('foreign_keys = ON');
  db.pragma('journal_mode = WAL');
  db.pragma('synchronous = FULL');
  db.pragma('busy_timeout = 5000');

  return db;
}
```

---

## Tables

### conversations

Stores sanitized conversation metadata.

```sql
CREATE TABLE IF NOT EXISTS conversations (
  id TEXT PRIMARY KEY, -- ULID or UUID
  session_id TEXT NOT NULL, -- Claude Code session identifier
  correlation_id TEXT NOT NULL UNIQUE, -- For tracking conversation flow
  created_at TEXT NOT NULL DEFAULT (datetime('now')), -- ISO 8601
  updated_at TEXT NOT NULL DEFAULT (datetime('now')), -- ISO 8601
  completed_at TEXT, -- When conversation ended
  sanitized BOOLEAN NOT NULL DEFAULT 1 CHECK (sanitized = 1), -- ALWAYS true
  sanitization_version TEXT NOT NULL, -- e.g., "1.0.0"
  message_count INTEGER NOT NULL DEFAULT 0,
  metadata JSON -- Additional context (project path, user settings, etc.)
);

-- Indexes
CREATE INDEX idx_conversations_session ON conversations(session_id);
CREATE INDEX idx_conversations_created ON conversations(created_at DESC);
CREATE INDEX idx_conversations_correlation ON conversations(correlation_id);

-- Triggers for updated_at
CREATE TRIGGER conversations_updated_at
AFTER UPDATE ON conversations
FOR EACH ROW
BEGIN
  UPDATE conversations SET updated_at = datetime('now') WHERE id = NEW.id;
END;
```

**Column Descriptions**:
- `id`: Unique conversation identifier (ULID recommended for sortability)
- `session_id`: Claude Code session ID for grouping
- `correlation_id`: Unique ID for tracking across systems
- `created_at`: When conversation started (auto-set)
- `updated_at`: Last modification (auto-updated via trigger)
- `completed_at`: When conversation ended (NULL if ongoing)
- `sanitized`: MUST always be 1 (enforced by CHECK constraint)
- `sanitization_version`: Version of sanitization rules applied
- `message_count`: Cached count (updated via trigger)
- `metadata`: JSON for flexible additional data

**Performance Considerations**:
- `session_id` index for session queries
- `created_at DESC` index for recent conversations
- `correlation_id` unique index for lookups

---

### messages

Stores individual sanitized messages within conversations.

```sql
CREATE TABLE IF NOT EXISTS messages (
  id TEXT PRIMARY KEY, -- ULID or UUID
  conversation_id TEXT NOT NULL,
  role TEXT NOT NULL CHECK (role IN ('user', 'assistant', 'system')),
  content TEXT NOT NULL, -- SANITIZED content only
  content_hash TEXT NOT NULL, -- SHA-256 hash for deduplication
  sequence INTEGER NOT NULL, -- Order within conversation (0, 1, 2, ...)
  created_at TEXT NOT NULL DEFAULT (datetime('now')), -- ISO 8601
  token_count INTEGER, -- Approximate token count
  metadata JSON, -- Thinking, tool calls, etc.

  FOREIGN KEY (conversation_id) REFERENCES conversations(id) ON DELETE CASCADE,
  UNIQUE (conversation_id, sequence)
);

-- Indexes
CREATE INDEX idx_messages_conversation ON messages(conversation_id, sequence);
CREATE INDEX idx_messages_created ON messages(created_at DESC);
CREATE INDEX idx_messages_hash ON messages(content_hash);

-- Trigger to update conversation.message_count
CREATE TRIGGER messages_after_insert
AFTER INSERT ON messages
FOR EACH ROW
BEGIN
  UPDATE conversations
  SET message_count = message_count + 1
  WHERE id = NEW.conversation_id;
END;

CREATE TRIGGER messages_after_delete
AFTER DELETE ON messages
FOR EACH ROW
BEGIN
  UPDATE conversations
  SET message_count = message_count - 1
  WHERE id = OLD.conversation_id;
END;
```

**Column Descriptions**:
- `id`: Unique message identifier
- `conversation_id`: Parent conversation (CASCADE delete)
- `role`: Message sender (user/assistant/system)
- `content`: SANITIZED message content (NO PII)
- `content_hash`: For detecting duplicate messages
- `sequence`: Order within conversation (0-indexed)
- `created_at`: When message was created
- `token_count`: Approximate tokens (for cost tracking)
- `metadata`: JSON for thinking, tool calls, attachments

**CRITICAL**: This table has NO `raw_content` or `unsanitized_content` column. Sanitization MUST happen before insertion.

---

### learnings

Stores extracted learnings with full-text search.

```sql
CREATE TABLE IF NOT EXISTS learnings (
  id TEXT PRIMARY KEY, -- ULID or UUID
  conversation_id TEXT NOT NULL,
  source_message_ids JSON NOT NULL, -- Array of message IDs that produced this learning
  category TEXT NOT NULL CHECK (
    category IN (
      'pattern',
      'best_practice',
      'anti_pattern',
      'bug_fix',
      'optimization',
      'tool_usage',
      'workflow',
      'decision'
    )
  ),
  title TEXT NOT NULL, -- Short summary
  content TEXT NOT NULL, -- Detailed learning (SANITIZED)
  confidence REAL NOT NULL CHECK (confidence >= 0.0 AND confidence <= 1.0),
  tags JSON NOT NULL DEFAULT '[]', -- Array of strings
  dedupe_hash TEXT NOT NULL UNIQUE, -- For preventing duplicates
  created_at TEXT NOT NULL DEFAULT (datetime('now')), -- ISO 8601
  metadata JSON, -- Additional context

  FOREIGN KEY (conversation_id) REFERENCES conversations(id) ON DELETE CASCADE
);

-- Indexes
CREATE INDEX idx_learnings_conversation ON learnings(conversation_id);
CREATE INDEX idx_learnings_category ON learnings(category, confidence DESC);
CREATE INDEX idx_learnings_confidence ON learnings(confidence DESC);
CREATE INDEX idx_learnings_created ON learnings(created_at DESC);
CREATE INDEX idx_learnings_dedupe ON learnings(dedupe_hash);

-- Full-text search (FTS5)
CREATE VIRTUAL TABLE learnings_fts USING fts5(
  learning_id UNINDEXED,
  title,
  content,
  tags,
  content='learnings',
  content_rowid='rowid'
);

-- Triggers to keep FTS in sync
CREATE TRIGGER learnings_fts_insert
AFTER INSERT ON learnings
BEGIN
  INSERT INTO learnings_fts(rowid, learning_id, title, content, tags)
  VALUES (NEW.rowid, NEW.id, NEW.title, NEW.content, NEW.tags);
END;

CREATE TRIGGER learnings_fts_delete
AFTER DELETE ON learnings
BEGIN
  DELETE FROM learnings_fts WHERE rowid = OLD.rowid;
END;

CREATE TRIGGER learnings_fts_update
AFTER UPDATE ON learnings
BEGIN
  DELETE FROM learnings_fts WHERE rowid = OLD.rowid;
  INSERT INTO learnings_fts(rowid, learning_id, title, content, tags)
  VALUES (NEW.rowid, NEW.id, NEW.title, NEW.content, NEW.tags);
END;
```

**Column Descriptions**:
- `id`: Unique learning identifier
- `conversation_id`: Source conversation
- `source_message_ids`: JSON array of message IDs
- `category`: Type of learning (CHECK constraint enforced)
- `title`: Short summary (used in lists)
- `content`: Detailed learning text
- `confidence`: Quality score 0.0-1.0
- `tags`: JSON array of topic tags
- `dedupe_hash`: Prevents duplicate learnings
- `created_at`: When learning was extracted
- `metadata`: Additional context

**FTS5 Full-Text Search**:
- Searches across `title`, `content`, and `tags`
- BM25 ranking
- Supports phrase queries, AND/OR, NEAR

---

### job_queue

Persistent queue for async job processing.

```sql
CREATE TABLE IF NOT EXISTS job_queue (
  id TEXT PRIMARY KEY, -- ULID (sortable)
  type TEXT NOT NULL, -- 'sanitize', 'extract_learning', 'upload'
  status TEXT NOT NULL DEFAULT 'queued' CHECK (
    status IN ('queued', 'running', 'succeeded', 'failed', 'quarantined')
  ),
  priority INTEGER NOT NULL DEFAULT 5 CHECK (priority >= 1 AND priority <= 10), -- 1=highest
  run_at TEXT NOT NULL DEFAULT (datetime('now')), -- When to run (for delayed jobs)
  locked_at TEXT, -- When job was claimed by worker
  locked_by TEXT, -- Worker ID that claimed job
  payload JSON NOT NULL, -- Job-specific data
  attempts INTEGER NOT NULL DEFAULT 0,
  max_retries INTEGER NOT NULL DEFAULT 3,
  last_error TEXT, -- Error message from last failure
  created_at TEXT NOT NULL DEFAULT (datetime('now')), -- ISO 8601
  updated_at TEXT NOT NULL DEFAULT (datetime('now')), -- ISO 8601
  completed_at TEXT -- When job finished (success or quarantine)
);

-- Indexes for worker queries
CREATE INDEX idx_job_queue_dequeue ON job_queue(status, priority, run_at)
  WHERE status = 'queued';
CREATE INDEX idx_job_queue_type ON job_queue(type, status);
CREATE INDEX idx_job_queue_created ON job_queue(created_at DESC);

-- Trigger for updated_at
CREATE TRIGGER job_queue_updated_at
AFTER UPDATE ON job_queue
FOR EACH ROW
BEGIN
  UPDATE job_queue SET updated_at = datetime('now') WHERE id = NEW.id;
END;
```

**Column Descriptions**:
- `id`: ULID for time-sortable IDs
- `type`: Job type for worker routing
- `status`: Current state (queued/running/succeeded/failed/quarantined)
- `priority`: 1-10, where 1 is highest priority
- `run_at`: Delayed job support (run after this time)
- `locked_at`: Optimistic locking timestamp
- `locked_by`: Worker identifier (hostname + PID)
- `payload`: JSON with job-specific parameters
- `attempts`: Retry counter
- `max_retries`: Max attempts before quarantine
- `last_error`: Last failure reason
- `completed_at`: When job finished

**Worker Query Pattern** (Optimistic Locking):
```sql
UPDATE job_queue
SET
  status = 'running',
  locked_at = datetime('now'),
  locked_by = :worker_id,
  attempts = attempts + 1
WHERE id = (
  SELECT id
  FROM job_queue
  WHERE status = 'queued'
    AND run_at <= datetime('now')
  ORDER BY priority ASC, run_at ASC
  LIMIT 1
)
RETURNING *;
```

---

### uploads

Tracks uploads to global network (IPFS + blockchain).

```sql
CREATE TABLE IF NOT EXISTS uploads (
  id TEXT PRIMARY KEY, -- ULID or UUID
  learning_id TEXT NOT NULL UNIQUE,
  ipfs_cid TEXT UNIQUE, -- Content Identifier from IPFS
  chain_tx_hash TEXT UNIQUE, -- Blockchain transaction hash
  status TEXT NOT NULL DEFAULT 'pending' CHECK (
    status IN ('pending', 'ipfs_uploaded', 'tx_submitted', 'confirmed', 'failed')
  ),
  retries INTEGER NOT NULL DEFAULT 0,
  max_retries INTEGER NOT NULL DEFAULT 5,
  last_error TEXT, -- Error from last attempt
  tokens_earned REAL, -- Reward amount (if confirmed)
  created_at TEXT NOT NULL DEFAULT (datetime('now')), -- ISO 8601
  updated_at TEXT NOT NULL DEFAULT (datetime('now')), -- ISO 8601
  uploaded_at TEXT, -- When IPFS upload succeeded
  confirmed_at TEXT, -- When blockchain tx confirmed

  FOREIGN KEY (learning_id) REFERENCES learnings(id) ON DELETE CASCADE
);

-- Indexes
CREATE INDEX idx_uploads_learning ON uploads(learning_id);
CREATE INDEX idx_uploads_status ON uploads(status);
CREATE INDEX idx_uploads_created ON uploads(created_at DESC);
CREATE UNIQUE INDEX idx_uploads_ipfs_cid ON uploads(ipfs_cid) WHERE ipfs_cid IS NOT NULL;
CREATE UNIQUE INDEX idx_uploads_tx_hash ON uploads(chain_tx_hash) WHERE chain_tx_hash IS NOT NULL;

-- Trigger for updated_at
CREATE TRIGGER uploads_updated_at
AFTER UPDATE ON uploads
FOR EACH ROW
BEGIN
  UPDATE uploads SET updated_at = datetime('now') WHERE id = NEW.id;
END;
```

**Column Descriptions**:
- `id`: Unique upload identifier
- `learning_id`: Source learning (UNIQUE - one upload per learning)
- `ipfs_cid`: Content identifier from IPFS
- `chain_tx_hash`: Blockchain transaction hash
- `status`: Upload lifecycle state
- `retries`: Attempt counter
- `max_retries`: Max attempts before giving up
- `last_error`: Last failure reason
- `tokens_earned`: Reward if confirmed
- `uploaded_at`: IPFS upload timestamp
- `confirmed_at`: Blockchain confirmation timestamp

**Upload States**:
1. `pending` → Initial state
2. `ipfs_uploaded` → Content in IPFS, have CID
3. `tx_submitted` → Blockchain tx sent
4. `confirmed` → Tx confirmed, tokens earned
5. `failed` → Max retries exceeded

---

### sanitization_log

Audit trail of all PII detections and redactions.

```sql
CREATE TABLE IF NOT EXISTS sanitization_log (
  id TEXT PRIMARY KEY, -- ULID for time ordering
  conversation_id TEXT NOT NULL,
  message_id TEXT, -- NULL if conversation-level sanitization
  category TEXT NOT NULL, -- PII type (api_key, email, file_path, etc.)
  rule_id TEXT, -- Which rule detected it (for rule-based)
  original_snippet_hash TEXT NOT NULL, -- SHA-256 of original text
  replacement TEXT NOT NULL, -- What it was replaced with
  detector TEXT NOT NULL CHECK (detector IN ('rule', 'ai', 'hybrid')),
  confidence REAL NOT NULL CHECK (confidence >= 0.0 AND confidence <= 1.0),
  created_at TEXT NOT NULL DEFAULT (datetime('now')), -- ISO 8601
  metadata JSON, -- Additional context

  FOREIGN KEY (conversation_id) REFERENCES conversations(id) ON DELETE CASCADE,
  FOREIGN KEY (message_id) REFERENCES messages(id) ON DELETE CASCADE
);

-- Indexes
CREATE INDEX idx_sanitization_log_conversation ON sanitization_log(conversation_id);
CREATE INDEX idx_sanitization_log_message ON sanitization_log(message_id);
CREATE INDEX idx_sanitization_log_category ON sanitization_log(category);
CREATE INDEX idx_sanitization_log_created ON sanitization_log(created_at DESC);
```

**Column Descriptions**:
- `id`: ULID for time-ordered audit trail
- `conversation_id`: Parent conversation
- `message_id`: Specific message (NULL for conversation-wide)
- `category`: Type of PII detected
- `rule_id`: Identifier of detection rule
- `original_snippet_hash`: Hash of PII (NEVER store actual PII)
- `replacement`: Replacement text used
- `detector`: Which system detected it
- `confidence`: Detection confidence score
- `created_at`: When detection occurred
- `metadata`: Additional context (position, surrounding text hash)

**CRITICAL**: NEVER store actual PII in this table. Use `original_snippet_hash` only.

---

## Migrations

### Migration System

```typescript
// src/database/migrations/runner.ts
import Database from 'better-sqlite3';
import fs from 'fs';
import path from 'path';

interface Migration {
  version: number;
  name: string;
  up: string;
  down: string;
}

// Migrations table
function createMigrationsTable(db: Database.Database): void {
  db.exec(`
    CREATE TABLE IF NOT EXISTS _migrations (
      version INTEGER PRIMARY KEY,
      name TEXT NOT NULL,
      applied_at TEXT NOT NULL DEFAULT (datetime('now'))
    );
  `);
}

// Get current version
function getCurrentVersion(db: Database.Database): number {
  const row = db.prepare('SELECT MAX(version) as version FROM _migrations').get() as { version: number | null };
  return row.version ?? 0;
}

// Load migration files
function loadMigrations(dir: string): Migration[] {
  const files = fs.readdirSync(dir).sort();
  const migrations: Migration[] = [];

  for (const file of files) {
    if (!file.endsWith('.sql')) continue;

    const match = file.match(/^(\d+)_(.+)\.sql$/);
    if (!match) continue;

    const version = parseInt(match[1], 10);
    const name = match[2];
    const content = fs.readFileSync(path.join(dir, file), 'utf8');

    // Split on -- UP / -- DOWN markers
    const [up, down] = content.split(/--\s*DOWN/i);
    const upSql = up.replace(/--\s*UP/i, '').trim();
    const downSql = down?.trim() || '';

    migrations.push({ version, name, up: upSql, down: downSql });
  }

  return migrations;
}

// Run migrations
export function runMigrations(db: Database.Database, targetVersion?: number): void {
  createMigrationsTable(db);

  const currentVersion = getCurrentVersion(db);
  const migrations = loadMigrations(path.join(__dirname, 'sql'));

  const toApply = migrations.filter(m =>
    m.version > currentVersion && (!targetVersion || m.version <= targetVersion)
  );

  if (toApply.length === 0) {
    console.log('No migrations to apply');
    return;
  }

  for (const migration of toApply) {
    console.log(`Applying migration ${migration.version}: ${migration.name}`);

    const applyMigration = db.transaction(() => {
      db.exec(migration.up);
      db.prepare('INSERT INTO _migrations (version, name) VALUES (?, ?)').run(migration.version, migration.name);
    });

    applyMigration();
  }

  console.log(`Migrated to version ${toApply[toApply.length - 1].version}`);
}

// Rollback migrations
export function rollbackMigrations(db: Database.Database, targetVersion: number): void {
  const currentVersion = getCurrentVersion(db);
  const migrations = loadMigrations(path.join(__dirname, 'sql'));

  const toRollback = migrations
    .filter(m => m.version > targetVersion && m.version <= currentVersion)
    .reverse();

  if (toRollback.length === 0) {
    console.log('No migrations to rollback');
    return;
  }

  for (const migration of toRollback) {
    console.log(`Rolling back migration ${migration.version}: ${migration.name}`);

    const rollback = db.transaction(() => {
      db.exec(migration.down);
      db.prepare('DELETE FROM _migrations WHERE version = ?').run(migration.version);
    });

    rollback();
  }

  console.log(`Rolled back to version ${targetVersion}`);
}
```

### Example Migration File

```sql
-- migrations/001_initial.sql

-- UP
CREATE TABLE IF NOT EXISTS conversations (
  id TEXT PRIMARY KEY,
  session_id TEXT NOT NULL,
  correlation_id TEXT NOT NULL UNIQUE,
  created_at TEXT NOT NULL DEFAULT (datetime('now')),
  updated_at TEXT NOT NULL DEFAULT (datetime('now')),
  completed_at TEXT,
  sanitized BOOLEAN NOT NULL DEFAULT 1 CHECK (sanitized = 1),
  sanitization_version TEXT NOT NULL,
  message_count INTEGER NOT NULL DEFAULT 0,
  metadata JSON
);

CREATE INDEX idx_conversations_session ON conversations(session_id);
CREATE INDEX idx_conversations_created ON conversations(created_at DESC);

CREATE TRIGGER conversations_updated_at
AFTER UPDATE ON conversations
FOR EACH ROW
BEGIN
  UPDATE conversations SET updated_at = datetime('now') WHERE id = NEW.id;
END;

-- DOWN
DROP TRIGGER IF EXISTS conversations_updated_at;
DROP INDEX IF EXISTS idx_conversations_created;
DROP INDEX IF EXISTS idx_conversations_session;
DROP TABLE IF EXISTS conversations;
```

---

## Query Patterns

### Repository Base Class

```typescript
// src/database/repositories/base-repository.ts
import Database from 'better-sqlite3';

export abstract class BaseRepository<T> {
  constructor(protected db: Database.Database) {}

  protected transaction<R>(fn: () => R): R {
    const trans = this.db.transaction(fn);
    return trans();
  }

  protected prepare(sql: string): Database.Statement {
    return this.db.prepare(sql);
  }

  abstract create(data: Partial<T>): T;
  abstract findById(id: string): T | null;
  abstract update(id: string, data: Partial<T>): T;
  abstract delete(id: string): void;
}
```

### Conversation Repository

```typescript
// src/database/repositories/conversation-repository.ts
import { BaseRepository } from './base-repository';
import { ulid } from 'ulid';

export interface Conversation {
  id: string;
  session_id: string;
  correlation_id: string;
  created_at: string;
  updated_at: string;
  completed_at: string | null;
  sanitized: boolean;
  sanitization_version: string;
  message_count: number;
  metadata: any;
}

export class ConversationRepository extends BaseRepository<Conversation> {
  create(data: Partial<Conversation>): Conversation {
    const id = data.id || ulid();
    const correlation_id = data.correlation_id || ulid();
    const sanitization_version = data.sanitization_version || '1.0.0';

    this.prepare(`
      INSERT INTO conversations (id, session_id, correlation_id, sanitization_version, metadata)
      VALUES (?, ?, ?, ?, ?)
    `).run(
      id,
      data.session_id,
      correlation_id,
      sanitization_version,
      JSON.stringify(data.metadata || {})
    );

    return this.findById(id)!;
  }

  findById(id: string): Conversation | null {
    const row = this.prepare('SELECT * FROM conversations WHERE id = ?').get(id);
    return row ? this.deserialize(row as any) : null;
  }

  findByCorrelationId(correlationId: string): Conversation | null {
    const row = this.prepare('SELECT * FROM conversations WHERE correlation_id = ?').get(correlationId);
    return row ? this.deserialize(row as any) : null;
  }

  findBySession(sessionId: string, limit = 10): Conversation[] {
    const rows = this.prepare(`
      SELECT * FROM conversations
      WHERE session_id = ?
      ORDER BY created_at DESC
      LIMIT ?
    `).all(sessionId, limit);

    return rows.map(r => this.deserialize(r as any));
  }

  update(id: string, data: Partial<Conversation>): Conversation {
    const updates: string[] = [];
    const values: any[] = [];

    if (data.completed_at !== undefined) {
      updates.push('completed_at = ?');
      values.push(data.completed_at);
    }
    if (data.metadata !== undefined) {
      updates.push('metadata = ?');
      values.push(JSON.stringify(data.metadata));
    }

    if (updates.length === 0) {
      return this.findById(id)!;
    }

    values.push(id);

    this.prepare(`
      UPDATE conversations
      SET ${updates.join(', ')}
      WHERE id = ?
    `).run(...values);

    return this.findById(id)!;
  }

  delete(id: string): void {
    this.prepare('DELETE FROM conversations WHERE id = ?').run(id);
  }

  private deserialize(row: any): Conversation {
    return {
      ...row,
      sanitized: Boolean(row.sanitized),
      metadata: row.metadata ? JSON.parse(row.metadata) : {}
    };
  }
}
```

### Learning Repository with FTS

```typescript
// src/database/repositories/learning-repository.ts
import { BaseRepository } from './base-repository';
import { ulid } from 'ulid';
import crypto from 'crypto';

export interface Learning {
  id: string;
  conversation_id: string;
  source_message_ids: string[];
  category: string;
  title: string;
  content: string;
  confidence: number;
  tags: string[];
  dedupe_hash: string;
  created_at: string;
  metadata: any;
}

export class LearningRepository extends BaseRepository<Learning> {
  create(data: Partial<Learning>): Learning {
    const id = data.id || ulid();
    const dedupe_hash = this.generateDedupeHash(data.content!, data.category!);

    this.prepare(`
      INSERT INTO learnings (
        id, conversation_id, source_message_ids, category, title,
        content, confidence, tags, dedupe_hash, metadata
      )
      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    `).run(
      id,
      data.conversation_id,
      JSON.stringify(data.source_message_ids || []),
      data.category,
      data.title,
      data.content,
      data.confidence,
      JSON.stringify(data.tags || []),
      dedupe_hash,
      JSON.stringify(data.metadata || {})
    );

    return this.findById(id)!;
  }

  findById(id: string): Learning | null {
    const row = this.prepare('SELECT * FROM learnings WHERE id = ?').get(id);
    return row ? this.deserialize(row as any) : null;
  }

  search(query: string, options: {
    category?: string;
    minConfidence?: number;
    limit?: number;
  } = {}): Learning[] {
    const limit = options.limit || 10;
    const minConfidence = options.minConfidence || 0.0;

    let sql = `
      SELECT l.*
      FROM learnings l
      JOIN learnings_fts fts ON l.rowid = fts.rowid
      WHERE fts MATCH ?
        AND l.confidence >= ?
    `;

    const params: any[] = [query, minConfidence];

    if (options.category) {
      sql += ' AND l.category = ?';
      params.push(options.category);
    }

    sql += ' ORDER BY bm25(fts), l.confidence DESC LIMIT ?';
    params.push(limit);

    const rows = this.prepare(sql).all(...params);
    return rows.map(r => this.deserialize(r as any));
  }

  findByCategory(category: string, limit = 10): Learning[] {
    const rows = this.prepare(`
      SELECT * FROM learnings
      WHERE category = ?
      ORDER BY confidence DESC, created_at DESC
      LIMIT ?
    `).all(category, limit);

    return rows.map(r => this.deserialize(r as any));
  }

  findRecent(limit = 10): Learning[] {
    const rows = this.prepare(`
      SELECT * FROM learnings
      ORDER BY created_at DESC
      LIMIT ?
    `).all(limit);

    return rows.map(r => this.deserialize(r as any));
  }

  findTopRated(limit = 10): Learning[] {
    const rows = this.prepare(`
      SELECT * FROM learnings
      ORDER BY confidence DESC, created_at DESC
      LIMIT ?
    `).all(limit);

    return rows.map(r => this.deserialize(r as any));
  }

  update(id: string, data: Partial<Learning>): Learning {
    // Learnings are generally immutable, but allow confidence updates
    if (data.confidence !== undefined) {
      this.prepare('UPDATE learnings SET confidence = ? WHERE id = ?').run(data.confidence, id);
    }
    return this.findById(id)!;
  }

  delete(id: string): void {
    this.prepare('DELETE FROM learnings WHERE id = ?').run(id);
  }

  private generateDedupeHash(content: string, category: string): string {
    return crypto.createHash('sha256').update(`${category}:${content}`).digest('hex');
  }

  private deserialize(row: any): Learning {
    return {
      ...row,
      source_message_ids: JSON.parse(row.source_message_ids),
      tags: JSON.parse(row.tags),
      metadata: row.metadata ? JSON.parse(row.metadata) : {}
    };
  }
}
```

### Job Queue Repository

```typescript
// src/database/repositories/job-queue-repository.ts
import { BaseRepository } from './base-repository';
import { ulid } from 'ulid';
import os from 'os';

export interface Job {
  id: string;
  type: string;
  status: 'queued' | 'running' | 'succeeded' | 'failed' | 'quarantined';
  priority: number;
  run_at: string;
  locked_at: string | null;
  locked_by: string | null;
  payload: any;
  attempts: number;
  max_retries: number;
  last_error: string | null;
  created_at: string;
  updated_at: string;
  completed_at: string | null;
}

export class JobQueueRepository extends BaseRepository<Job> {
  private workerId = `${os.hostname()}-${process.pid}`;

  create(data: Partial<Job>): Job {
    const id = data.id || ulid();
    const priority = data.priority || 5;
    const max_retries = data.max_retries || 3;
    const run_at = data.run_at || new Date().toISOString();

    this.prepare(`
      INSERT INTO job_queue (id, type, priority, run_at, payload, max_retries)
      VALUES (?, ?, ?, ?, ?, ?)
    `).run(
      id,
      data.type,
      priority,
      run_at,
      JSON.stringify(data.payload || {}),
      max_retries
    );

    return this.findById(id)!;
  }

  // Optimistic locking: claim next job
  dequeue(): Job | null {
    const updated = this.prepare(`
      UPDATE job_queue
      SET
        status = 'running',
        locked_at = datetime('now'),
        locked_by = ?,
        attempts = attempts + 1
      WHERE id = (
        SELECT id
        FROM job_queue
        WHERE status = 'queued'
          AND run_at <= datetime('now')
        ORDER BY priority ASC, run_at ASC
        LIMIT 1
      )
      RETURNING *
    `).get(this.workerId);

    return updated ? this.deserialize(updated as any) : null;
  }

  markSucceeded(id: string): void {
    this.prepare(`
      UPDATE job_queue
      SET status = 'succeeded', completed_at = datetime('now')
      WHERE id = ?
    `).run(id);
  }

  markFailed(id: string, error: string): void {
    const job = this.findById(id);
    if (!job) return;

    if (job.attempts >= job.max_retries) {
      // Quarantine
      this.prepare(`
        UPDATE job_queue
        SET status = 'quarantined', last_error = ?, completed_at = datetime('now')
        WHERE id = ?
      `).run(error, id);
    } else {
      // Requeue with backoff
      const backoffMs = Math.pow(2, job.attempts) * 1000;
      const runAt = new Date(Date.now() + backoffMs).toISOString();

      this.prepare(`
        UPDATE job_queue
        SET status = 'queued', last_error = ?, run_at = ?, locked_at = NULL, locked_by = NULL
        WHERE id = ?
      `).run(error, runAt, id);
    }
  }

  findById(id: string): Job | null {
    const row = this.prepare('SELECT * FROM job_queue WHERE id = ?').get(id);
    return row ? this.deserialize(row as any) : null;
  }

  // Clean up stale locks (workers that crashed)
  releaseStaleJobs(timeout_ms = 300000): number {
    const staleTime = new Date(Date.now() - timeout_ms).toISOString();

    const result = this.prepare(`
      UPDATE job_queue
      SET status = 'queued', locked_at = NULL, locked_by = NULL
      WHERE status = 'running'
        AND locked_at < ?
    `).run(staleTime);

    return result.changes;
  }

  update(id: string, data: Partial<Job>): Job {
    throw new Error('Use specific methods (markSucceeded, markFailed)');
  }

  delete(id: string): void {
    this.prepare('DELETE FROM job_queue WHERE id = ?').run(id);
  }

  private deserialize(row: any): Job {
    return {
      ...row,
      payload: JSON.parse(row.payload)
    };
  }
}
```

---

## Performance Optimization

### Query Performance Tips

1. **Always use indexes for foreign keys**
2. **Add covering indexes for frequent queries**
3. **Use EXPLAIN QUERY PLAN to verify index usage**
4. **Keep transactions short**
5. **Use prepared statements (auto-cached)**

### EXPLAIN Example

```sql
EXPLAIN QUERY PLAN
SELECT l.*
FROM learnings l
JOIN learnings_fts fts ON l.rowid = fts.rowid
WHERE fts MATCH 'typescript testing'
  AND l.category = 'pattern'
ORDER BY bm25(fts), l.confidence DESC
LIMIT 10;

-- Should use:
-- - FTS index for MATCH
-- - idx_learnings_category for category filter
```

### Maintenance

```typescript
// Run periodically
export function optimizeDatabase(db: Database.Database): void {
  // Rebuild FTS index
  db.exec('INSERT INTO learnings_fts(learnings_fts) VALUES("rebuild")');

  // Update statistics
  db.exec('ANALYZE');

  // Vacuum (compact database)
  db.exec('VACUUM');
}
```

---

## Backup & Restore

### Backup

```typescript
import Database from 'better-sqlite3';

export async function backupDatabase(sourceDb: Database.Database, destPath: string): Promise<void> {
  return new Promise((resolve, reject) => {
    const backup = sourceDb.backup(destPath);

    const doBackup = () => {
      const remaining = backup.step(100); // Pages per step
      if (remaining === 0) {
        backup.close();
        resolve();
      } else {
        setImmediate(doBackup);
      }
    };

    try {
      doBackup();
    } catch (error) {
      backup.close();
      reject(error);
    }
  });
}
```

### Restore

```typescript
export async function restoreDatabase(sourceDb: Database.Database, destPath: string): Promise<void> {
  const destDb = new Database(destPath);

  try {
    await backupDatabase(sourceDb, destPath);
    console.log(`Restored to ${destPath}`);
  } finally {
    destDb.close();
  }
}
```

### Verification

```typescript
export function verifyDatabase(db: Database.Database): boolean {
  const result = db.pragma('integrity_check', { simple: true });
  return result === 'ok';
}
```

---

## Related Documents

### Architecture
- [Global Context Network](../architecture/architecture-global-context-network-2025-01-16.md)
- [Database Schema Architecture](../architecture/architecture-database-schema-2025-01-16.md)

### Reference
- [Testing Strategy](./reference-testing-strategy-2025-01-16.md)
- [Subagent Types](./reference-subagent-types-2025-01-16.md)

### Guides
- [Database Setup Guide](../guides/guide-database-setup-2025-01-16.md)

================
File: reference/reference-subagent-types-2025-01-16.md
================
# Subagent Types Reference

> Complete catalog of all subagent types with configurations, prompts, and usage patterns

---
title: Subagent Types Reference
category: reference
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [subagents, claude-agent-sdk, development, testing]
applies_to: Claude Agent SDK 1.x, Sonnet 4.5, Haiku 3.5
---

## Overview

This document provides a complete catalog of all subagent types used in the Global Context Network development. Each subagent is specialized for a specific task with defined inputs, outputs, tools, and success criteria.

**Total Subagents**: 22
- **Implementation**: 14 subagents
- **Test Generation**: 3 subagents
- **Test Validation**: 3 subagents
- **Quality Gates**: 3 subagents

## Subagent Contract Template

Each subagent follows this contract:

```typescript
interface SubagentContract {
  name: string;
  description: string;
  phase: number;
  category: 'implementation' | 'test-generation' | 'test-validation' | 'quality-gate';
  model: 'sonnet' | 'haiku';
  tools: string[];
  input_schema: object;
  output_schema: object;
  prompt_template: string;
  success_criteria: string[];
  timeout_ms: number;
  retry_policy: RetryPolicy;
  cost_sensitivity: 'low' | 'medium' | 'high';
  idempotent: boolean;
  concurrency: 'sequential' | 'parallel';
}
```

---

## Phase 0: Foundation

### foundation-setup-agent

**Purpose**: Initialize TypeScript project with Vitest testing infrastructure

**Configuration**:
```typescript
{
  name: "foundation-setup-agent",
  description: "Sets up TypeScript project with strict mode, Vitest, and project structure",
  phase: 0,
  category: "implementation",
  model: "sonnet",
  tools: ["Write", "Bash", "Read"],
  timeout_ms: 120000,
  cost_sensitivity: "low",
  idempotent: true,
  concurrency: "sequential"
}
```

**Input Schema**:
```typescript
{
  project_name: string;
  node_version: string; // e.g., "20"
  package_manager: "npm" | "pnpm" | "yarn";
}
```

**Output Schema**:
```typescript
{
  files_created: string[];
  dependencies_installed: boolean;
  typescript_version: string;
  vitest_version: string;
}
```

**Prompt Template**:
```
You are a TypeScript project setup expert. Initialize a new TypeScript project with:

1. package.json with dependencies:
   - typescript (latest)
   - vitest (latest)
   - @types/node
   - @typescript-eslint/parser
   - @typescript-eslint/eslint-plugin

2. tsconfig.json with strict mode:
   - "strict": true
   - "esModuleInterop": true
   - "skipLibCheck": true
   - "target": "ES2022"
   - "module": "ESNext"
   - "moduleResolution": "bundler"

3. vitest.config.ts following reference-testing-strategy

4. Project structure:
   - src/
   - tests/
   - .gitignore

5. Install dependencies using {package_manager}

IMPORTANT:
- Use strict TypeScript settings
- Never use "any" types
- All configs must be valid JSON/TypeScript
```

**Success Criteria**:
- ✅ All files created
- ✅ Dependencies installed successfully
- ✅ `pnpm run type-check` passes
- ✅ `pnpm test` can run (even with no tests)

**Common Pitfalls**:
- Forgetting to enable strict mode
- Incorrect module resolution settings
- Missing test setup files

---

### database-schema-agent

**Purpose**: Create SQLite database schema with migrations

**Configuration**:
```typescript
{
  name: "database-schema-agent",
  description: "Designs and implements SQLite database schema with migration system",
  phase: 0,
  category: "implementation",
  model: "sonnet",
  tools: ["Write", "Bash", "Read"],
  timeout_ms: 90000,
  cost_sensitivity: "medium",
  idempotent: true,
  concurrency: "parallel" // Can run with test-infrastructure
}
```

**Input Schema**:
```typescript
{
  tables: Array<{
    name: string;
    columns: Array<{ name: string; type: string; constraints?: string[] }>;
    indexes?: Array<{ columns: string[]; unique?: boolean }>;
  }>;
  enable_fts: boolean; // Full-text search for learnings
}
```

**Output Schema**:
```typescript
{
  migration_files: string[];
  schema_version: string;
  tables_created: string[];
  indexes_created: string[];
}
```

**Prompt Template**:
```
You are a SQLite database expert. Create a production-ready database schema with:

1. Migration system (migrations/001_initial.sql, 002_add_fts.sql, etc.)

2. All tables from input schema with:
   - Primary keys (id TEXT PRIMARY KEY)
   - Foreign keys (with ON DELETE CASCADE where appropriate)
   - Timestamps (created_at, updated_at with triggers)
   - CHECK constraints for data validation

3. Indexes for all foreign keys and frequently queried columns

4. FTS5 virtual table for learnings.content if enable_fts=true

5. Migration runner in TypeScript (src/database/migrations/runner.ts)

CRITICAL REQUIREMENTS:
- Enable foreign keys: PRAGMA foreign_keys = ON
- Use WAL mode: PRAGMA journal_mode = WAL
- All timestamps as ISO 8601 strings
- Add CHECK constraints for confidence (0.0 to 1.0)
- Ensure ACID compliance

NEVER:
- Store unsanitized data (no "raw_content" columns)
- Use INTEGER for IDs (use TEXT for UUIDs/ULIDs)
- Forget indexes on foreign keys
```

**Success Criteria**:
- ✅ Migration runner executes without errors
- ✅ All tables created with proper constraints
- ✅ Foreign keys enforced
- ✅ Indexes created for performance
- ✅ FTS5 table if requested

**Common Pitfalls**:
- Forgetting PRAGMA foreign_keys = ON
- Not using WAL mode
- Missing indexes on foreign keys
- Incorrect timestamp handling

---

### test-infrastructure-agent

**Purpose**: Set up test utilities, helpers, and fixtures

**Configuration**:
```typescript
{
  name: "test-infrastructure-agent",
  description: "Creates test helpers, fixture factories, and test database utilities",
  phase: 0,
  category: "implementation",
  model: "sonnet",
  tools: ["Write", "Read"],
  timeout_ms: 60000,
  cost_sensitivity: "low",
  idempotent: true,
  concurrency: "parallel"
}
```

**Input Schema**:
```typescript
{
  test_types: Array<"unit" | "integration" | "e2e">;
  fixture_types: Array<"conversation" | "message" | "learning">;
}
```

**Output Schema**:
```typescript
{
  helper_files: string[];
  fixture_files: string[];
  test_setup_complete: boolean;
}
```

**Prompt Template**:
```
You are a test infrastructure expert. Create comprehensive test utilities:

1. Test setup (tests/setup.ts):
   - In-memory SQLite database
   - beforeEach/afterEach hooks
   - Test database cleanup

2. Fixture factories (tests/helpers/fixture-factory.ts):
   - createConversation()
   - createMessage()
   - createLearning()
   - Use @faker-js/faker for realistic data

3. Test helpers (tests/helpers/):
   - db-helpers.ts (query helpers, assertions)
   - mock-helpers.ts (LLM, MCP, IPFS mocks)

4. Sample fixtures (tests/fixtures/):
   - conversations/with-pii.json
   - sanitization/pii-corpus.json

REQUIREMENTS:
- All factories return valid, type-safe objects
- Fixtures should be realistic but synthetic
- Mock helpers should be deterministic
- Follow reference-testing-strategy guidelines
```

**Success Criteria**:
- ✅ Test setup file creates in-memory database
- ✅ Fixture factories generate valid data
- ✅ Mock helpers provide deterministic results
- ✅ Sample fixtures load successfully

---

## Phase 1: Event Capture

### hook-developer-agent

**Purpose**: Implement Claude Code hooks for event capture

**Configuration**:
```typescript
{
  name: "hook-developer-agent",
  description: "Creates UserPromptSubmit and Stop hooks with <100ms execution",
  phase: 1,
  category: "implementation",
  model: "sonnet",
  tools: ["Write", "Read", "Bash"],
  timeout_ms: 120000,
  cost_sensitivity: "high", // Critical path
  idempotent: true,
  concurrency: "sequential"
}
```

**Input Schema**:
```typescript
{
  hook_types: Array<"UserPromptSubmit" | "Stop">;
  output_path: string; // Where to write events
  max_execution_ms: number; // Default 100
}
```

**Output Schema**:
```typescript
{
  hook_scripts: string[];
  performance_p95: number; // Measured in tests
  error_handling: "silent" | "logged";
}
```

**Prompt Template**:
```
You are a Claude Code hooks expert. Implement event capture hooks with STRICT performance requirements:

1. UserPromptSubmit hook (.claude/hooks/userPromptSubmit.ts):
   - Captures user input
   - Writes to event queue
   - MUST execute in <100ms P95
   - NEVER block user interaction

2. Stop hook (.claude/hooks/stop.ts):
   - Captures agent response
   - Includes thinking if available
   - MUST execute in <100ms P95
   - Silent error handling (log but don't throw)

3. Event serialization:
   - Correlation ID for conversation tracking
   - Timestamp (ISO 8601)
   - Event type
   - Payload

CRITICAL REQUIREMENTS:
- P95 latency < 100ms (measured in tests)
- Fail silently with logging
- Never throw errors that block user
- Atomic writes to queue
- Handle process crashes gracefully

FORBIDDEN:
- Synchronous I/O in hooks
- Network calls
- Complex processing
- Throwing errors to user
```

**Success Criteria**:
- ✅ Hooks execute in <100ms P95
- ✅ Events persisted atomically
- ✅ Silent error handling
- ✅ No user-blocking behavior
- ✅ Performance tests pass

**Common Pitfalls**:
- Synchronous file I/O
- Complex sanitization in hooks (do async)
- Not handling errors gracefully
- Missing correlation IDs

---

### event-collector-agent

**Purpose**: Aggregate events into conversations

**Configuration**:
```typescript
{
  name: "event-collector-agent",
  description: "Groups events by conversation with session tracking",
  phase: 1,
  category: "implementation",
  model: "sonnet",
  tools: ["Write", "Read"],
  timeout_ms: 90000,
  cost_sensitivity: "medium",
  idempotent: true,
  concurrency: "parallel"
}
```

**Input Schema**:
```typescript
{
  session_timeout_ms: number; // Default 30 minutes
  correlation_strategy: "session_id" | "time_window" | "hybrid";
}
```

**Output Schema**:
```typescript
{
  collector_module: string;
  conversations_created: number;
  events_processed: number;
}
```

**Prompt Template**:
```
You are an event aggregation expert. Implement conversation collector:

1. Event aggregation (src/events/collector.ts):
   - Group events by correlation_id
   - Detect conversation boundaries
   - Handle session timeouts
   - Support multiple concurrent conversations

2. Conversation assembly:
   - Pair UserPromptSubmit with Stop events
   - Preserve message order
   - Track conversation state (active/complete)

3. Persistence:
   - Write complete conversations to queue
   - Handle partial conversations (session timeout)

REQUIREMENTS:
- Conversations must be ordered correctly
- Handle concurrent sessions
- Graceful session timeout handling
- Idempotent processing (replay-safe)
```

**Success Criteria**:
- ✅ Events correctly grouped by conversation
- ✅ Message order preserved
- ✅ Session timeouts handled
- ✅ Concurrent conversations supported

---

### queue-system-agent

**Purpose**: Implement persistent job queue

**Configuration**:
```typescript
{
  name: "queue-system-agent",
  description: "Creates SQLite-based job queue with priority and retry logic",
  phase: 1,
  category: "implementation",
  model: "sonnet",
  tools: ["Write", "Read", "Bash"],
  timeout_ms: 90000,
  cost_sensitivity: "high",
  idempotent: true,
  concurrency: "sequential"
}
```

**Input Schema**:
```typescript
{
  job_types: string[]; // e.g., ["sanitize", "extract_learning", "upload"]
  priority_levels: number; // Default 3 (high, medium, low)
  max_retries: number; // Default 3
}
```

**Output Schema**:
```typescript
{
  queue_module: string;
  tables_created: string[];
  worker_ready: boolean;
}
```

**Prompt Template**:
```
You are a job queue expert. Implement a robust, persistent queue system:

1. Queue table (job_queue):
   - id, type, status, priority, run_at, locked_at, locked_by
   - payload (JSON), attempts, max_retries, last_error
   - Indexes for (status, priority, run_at)

2. Queue operations (src/queue/queue.ts):
   - enqueue(type, payload, options)
   - dequeue() with priority + run_at ordering
   - markComplete(id)
   - markFailed(id, error)
   - requeueWithBackoff(id)

3. Concurrency control:
   - Optimistic locking (UPDATE ... WHERE locked_at IS NULL)
   - Worker heartbeats
   - Dead letter queue for max retries exceeded

4. Retry logic:
   - Exponential backoff: 2^attempt * 1000ms
   - Max 3 retries by default
   - Quarantine after max retries

CRITICAL:
- ACID compliance for job claiming
- No duplicate processing
- Handle worker crashes (stale locks)
- Observable metrics (queue depth, latency)
```

**Success Criteria**:
- ✅ Jobs persist across restarts
- ✅ No duplicate processing
- ✅ Priority ordering respected
- ✅ Retry logic with backoff
- ✅ Dead letter queue for failures

---

## Phase 2: Sanitization

### rule-sanitizer-agent

**Purpose**: Regex-based PII detection

**Configuration**:
```typescript
{
  name: "rule-sanitizer-agent",
  description: "Fast regex-based PII detection with <1% false positive rate",
  phase: 2,
  category: "implementation",
  model: "sonnet",
  tools: ["Write", "Read"],
  timeout_ms: 90000,
  cost_sensitivity: "high",
  idempotent: true,
  concurrency: "parallel"
}
```

**Prompt Template**:
```
You are a PII detection expert. Implement rule-based sanitization:

1. Detection patterns (src/sanitization/patterns.ts):
   - API keys (AWS, OpenAI, GitHub, etc.)
   - File paths (absolute with usernames)
   - Email addresses
   - IP addresses
   - Phone numbers
   - Credit cards

2. Rule detector (src/sanitization/rule-detector.ts):
   - detectPII(content) → Detection[]
   - Fast execution (<10ms per message)
   - <1% false positive rate on test corpus

3. Replacement strategy:
   - [API_KEY], [FILE_PATH], [EMAIL], etc.
   - Preserve structure for code examples
   - Audit log all detections

REQUIREMENTS:
- All patterns tested against corpus
- Performance: <10ms per 1KB content
- False positive rate <1%
- False negative rate <5%
```

**Success Criteria**:
- ✅ Detects all PII types from corpus
- ✅ Execution time <10ms per message
- ✅ False positive rate <1%
- ✅ Audit log complete

---

### ai-sanitizer-agent

**Purpose**: LLM-powered context-aware sanitization

**Configuration**:
```typescript
{
  name: "ai-sanitizer-agent",
  description: "Context-aware PII detection using LLM with <5% false negative rate",
  phase: 2,
  category: "implementation",
  model: "sonnet",
  tools: ["Write", "Read"],
  timeout_ms: 120000,
  cost_sensitivity: "high",
  idempotent: false, // LLM calls not deterministic
  concurrency: "parallel"
}
```

**Prompt Template**:
```
You are an AI-powered sanitization expert. Implement LLM-based PII detection:

1. AI Sanitizer (src/sanitization/ai-sanitizer.ts):
   - Use Claude API for context-aware detection
   - Distinguish person names from variable names
   - Handle company-specific terminology
   - Provide confidence scores

2. Prompt engineering:
   - "Identify PII in this developer conversation..."
   - Return structured JSON with detections
   - Include confidence (0-1)
   - Explain each detection

3. Error handling:
   - Timeout protection (5s max)
   - Fallback to rule-based if API fails
   - Rate limiting
   - Cost tracking

REQUIREMENTS:
- False negative rate <5%
- Execution time <2s per message
- Graceful degradation on API errors
- Cost awareness (token usage)
```

**Success Criteria**:
- ✅ Detects contextual PII (names vs variables)
- ✅ False negative rate <5%
- ✅ API failures handled gracefully
- ✅ Cost tracking implemented

---

### sanitization-pipeline-agent

**Purpose**: Orchestrate hybrid sanitization

**Configuration**:
```typescript
{
  name: "sanitization-pipeline-agent",
  description: "Combines rule-based and AI sanitization with validation",
  phase: 2,
  category: "implementation",
  model: "sonnet",
  tools: ["Write", "Read"],
  timeout_ms: 90000,
  cost_sensitivity: "high",
  idempotent: true,
  concurrency: "sequential"
}
```

**Prompt Template**:
```
You are a sanitization pipeline expert. Combine rule-based and AI sanitization:

1. Pipeline orchestration (src/sanitization/pipeline.ts):
   - Run rule-based detector first (fast)
   - Run AI sanitizer for validation
   - Merge results with deduplication
   - Apply replacements
   - Generate audit log

2. Hybrid validation:
   - Rules catch obvious cases
   - AI validates and enhances
   - Confidence scoring
   - Human review queue for low confidence

3. Output:
   - Sanitized content
   - Detection list
   - Audit log
   - Confidence score

CRITICAL:
- NEVER store unsanitized content
- All detections logged
- Replacements deterministic
- Preserve code structure
```

**Success Criteria**:
- ✅ Zero PII leaks in test corpus
- ✅ Combined FP <1%, FN <3%
- ✅ Complete audit trail
- ✅ Execution time <2s per conversation

---

## Phase 3: Database & Storage

### repository-agent

**Purpose**: Implement repository pattern for database access

**Configuration**:
```typescript
{
  name: "repository-agent",
  description: "Creates type-safe repository interfaces with transaction support",
  phase: 3,
  category: "implementation",
  model: "sonnet",
  tools: ["Write", "Read"],
  timeout_ms: 90000,
  cost_sensitivity: "medium",
  idempotent: true,
  concurrency: "parallel"
}
```

**Prompt Template**:
```
You are a database repository expert. Implement the repository pattern:

1. Base repository (src/database/repositories/base-repository.ts):
   - Transaction support
   - Error handling
   - Type safety
   - Query builders

2. Specific repositories:
   - ConversationRepository
   - MessageRepository
   - LearningRepository
   - JobQueueRepository

3. Repository methods:
   - create(data) → Promise<T>
   - findById(id) → Promise<T | null>
   - update(id, data) → Promise<T>
   - delete(id) → Promise<void>
   - Custom queries (findByConversationId, etc.)

REQUIREMENTS:
- All methods type-safe
- Parameterized queries (no SQL injection)
- Transaction support
- Error wrapping
- NEVER accept unsanitized content
```

**Success Criteria**:
- ✅ All repositories implemented
- ✅ Type safety enforced
- ✅ Transactions working
- ✅ No SQL injection vulnerabilities

---

## Test Generation Subagents

### unit-test-generator

**Configuration**:
```typescript
{
  name: "unit-test-generator",
  description: "Generates comprehensive unit tests with >85% coverage",
  category: "test-generation",
  model: "sonnet",
  tools: ["Write", "Read", "mcp__test-runner__run_unit_tests"],
  timeout_ms: 120000,
  cost_sensitivity: "medium",
  idempotent: false,
  concurrency: "parallel"
}
```

**Prompt Template**:
```
You are a unit test expert. Generate comprehensive unit tests:

1. Test structure:
   - Arrange-Act-Assert pattern
   - Clear test names (should/when/given)
   - One assertion per test
   - Proper mocking of dependencies

2. Coverage:
   - All functions tested
   - Edge cases (empty, null, undefined, boundary values)
   - Error conditions
   - Happy path and sad path

3. Test quality:
   - Fast (<10ms per test)
   - Isolated (no side effects)
   - Deterministic (no flaky tests)
   - Maintainable (clear, DRY)

TARGET: >85% coverage with high-quality tests
```

**Success Criteria**:
- ✅ Coverage ≥85%
- ✅ All tests pass
- ✅ No flaky tests
- ✅ Test quality score ≥0.8

---

### integration-test-generator

**Configuration**:
```typescript
{
  name: "integration-test-generator",
  description: "Creates integration tests for component interactions",
  category: "test-generation",
  model: "sonnet",
  tools: ["Write", "Read", "Bash"],
  timeout_ms: 120000,
  cost_sensitivity: "medium",
  idempotent: false,
  concurrency: "parallel"
}
```

**Prompt Template**:
```
You are an integration test expert. Generate integration tests:

1. Component interactions:
   - Hook → Queue
   - Sanitization → Database
   - Learning extraction → Upload
   - MCP server → Database

2. Test scenarios:
   - Multi-step workflows
   - Error propagation
   - Transaction rollback
   - Concurrent operations

3. Test data:
   - Use fixture factories
   - Test database per test
   - Cleanup after each test

TARGET: Cover all component boundaries
```

**Success Criteria**:
- ✅ All component interactions tested
- ✅ Error scenarios covered
- ✅ Transactions validated
- ✅ No test pollution

---

### e2e-test-generator

**Configuration**:
```typescript
{
  name: "e2e-test-generator",
  description: "Creates end-to-end workflow tests",
  category: "test-generation",
  model: "sonnet",
  tools: ["Write", "Read", "Bash"],
  timeout_ms: 180000,
  cost_sensitivity: "low",
  idempotent: false,
  concurrency: "sequential"
}
```

**Prompt Template**:
```
You are an E2E test expert. Generate end-to-end tests:

1. Complete workflows:
   - User prompt → Sanitization → Database → MCP query
   - Conversation → Learning extraction → Network upload
   - Hook capture → Processing → Availability

2. System verification:
   - Real database (ephemeral)
   - Real MCP server (test instance)
   - Mocked external services (IPFS, blockchain)

3. Failure scenarios:
   - Service unavailable
   - Timeout handling
   - Retry logic
   - Recovery procedures

TARGET: Validate complete system behavior
```

**Success Criteria**:
- ✅ Happy path works end-to-end
- ✅ Failure scenarios handled
- ✅ Recovery tested
- ✅ Performance acceptable

---

## Test Validation Subagents

### test-quality-validator

**Configuration**:
```typescript
{
  name: "test-quality-validator",
  description: "Reviews test code quality and completeness",
  category: "test-validation",
  model: "sonnet",
  tools: ["Read", "Grep"],
  timeout_ms: 60000,
  cost_sensitivity: "low",
  idempotent: true,
  concurrency: "parallel"
}
```

**Prompt Template**:
```
You are a test quality reviewer. Validate test quality:

1. Structure:
   - Proper describe/it nesting
   - Clear test names
   - AAA pattern
   - One assertion per test

2. Coverage:
   - Edge cases covered
   - Error conditions tested
   - Assertions not just truthy

3. Quality:
   - No test.skip without issue reference
   - No disabled assertions
   - Proper cleanup
   - No magic numbers

SCORE: 0-1, require >0.8 to pass
```

**Success Criteria**:
- ✅ Quality score ≥0.8
- ✅ All issues documented
- ✅ Recommendations provided

---

### coverage-validator

**Configuration**:
```typescript
{
  name: "coverage-validator",
  description: "Ensures adequate test coverage",
  category: "test-validation",
  model: "haiku",
  tools: ["Bash", "Read"],
  timeout_ms: 30000,
  cost_sensitivity: "low",
  idempotent: true,
  concurrency: "parallel"
}
```

**Prompt Template**:
```
You are a coverage validator. Analyze test coverage:

1. Coverage metrics:
   - Lines, statements, functions, branches
   - Per-file coverage
   - Critical path 100% coverage

2. Gaps:
   - Uncovered lines
   - Uncovered branches
   - Missing error handlers

3. Report:
   - Coverage percentage
   - Critical gaps
   - Recommendations

REQUIRE: >85% coverage, critical paths 100%
```

**Success Criteria**:
- ✅ Coverage ≥85%
- ✅ Critical paths 100%
- ✅ Gaps identified

---

### implementation-validator

**Configuration**:
```typescript
{
  name: "implementation-validator",
  description: "Validates implementation against tests",
  category: "test-validation",
  model: "sonnet",
  tools: ["Read", "Bash"],
  timeout_ms: 90000,
  cost_sensitivity: "medium",
  idempotent: true,
  concurrency: "sequential"
}
```

**Prompt Template**:
```
You are an implementation validator. Verify implementation:

1. Test alignment:
   - All tests pass
   - Implementation matches specs
   - No untested edge cases

2. Code quality:
   - TypeScript strict mode
   - No "any" types
   - Proper error handling

3. Security:
   - No SQL injection
   - No command injection
   - No hardcoded secrets

4. Performance:
   - Meets SLAs
   - No obvious bottlenecks

REQUIRE: All tests pass, no security issues
```

**Success Criteria**:
- ✅ All tests pass
- ✅ Security scan clean
- ✅ Performance acceptable
- ✅ Code quality high

---

## Quality Gate Subagents

### code-quality-validator

**Configuration**:
```typescript
{
  name: "code-quality-validator",
  description: "Reviews code quality and standards",
  category: "quality-gate",
  model: "sonnet",
  tools: ["Read", "Bash"],
  timeout_ms: 60000,
  cost_sensitivity: "low",
  idempotent: true,
  concurrency: "parallel"
}
```

**Prompt Template**:
```
You are a code quality reviewer. Enforce standards:

1. TypeScript:
   - Strict mode compliance
   - No "any" types
   - Proper type annotations

2. Code style:
   - ESLint passes
   - Prettier formatted
   - Consistent naming

3. Best practices:
   - DRY (Don't Repeat Yourself)
   - SOLID principles
   - Clear function names
   - Proper error handling

BLOCK: If any critical issues found
```

**Success Criteria**:
- ✅ ESLint passes
- ✅ TypeScript strict mode
- ✅ No "any" types
- ✅ Formatted correctly

---

### security-validator

**Configuration**:
```typescript
{
  name: "security-validator",
  description: "Scans for security vulnerabilities",
  category: "quality-gate",
  model: "sonnet",
  tools: ["Read", "Bash"],
  timeout_ms: 90000,
  cost_sensitivity: "medium",
  idempotent: true,
  concurrency: "parallel"
}
```

**Prompt Template**:
```
You are a security auditor. Scan for vulnerabilities:

1. Code analysis:
   - SQL injection (use parameterized queries)
   - Command injection (no shell=true)
   - Path traversal (validate paths)
   - XSS vectors (sanitize output)

2. Dependencies:
   - Known vulnerabilities
   - Outdated packages
   - License issues

3. Secrets:
   - No hardcoded API keys
   - No passwords in code
   - Proper env var usage

BLOCK: If any critical vulnerabilities found
```

**Success Criteria**:
- ✅ No SQL injection
- ✅ No command injection
- ✅ No hardcoded secrets
- ✅ Dependencies clean

---

### performance-validator

**Configuration**:
```typescript
{
  name: "performance-validator",
  description: "Analyzes performance characteristics",
  category: "quality-gate",
  model: "sonnet",
  tools: ["Read", "Bash"],
  timeout_ms: 60000,
  cost_sensitivity: "low",
  idempotent: true,
  concurrency: "parallel"
}
```

**Prompt Template**:
```
You are a performance analyst. Check performance:

1. Algorithm complexity:
   - O(n) acceptable, O(n²) flag
   - No unnecessary loops
   - Proper data structures

2. Database:
   - Indexes on foreign keys
   - No N+1 queries
   - Batch operations where possible

3. Resource usage:
   - No memory leaks
   - Proper stream handling
   - Connection pooling

FLAG: Performance regressions or obvious bottlenecks
```

**Success Criteria**:
- ✅ Algorithm complexity acceptable
- ✅ No N+1 queries
- ✅ No obvious bottlenecks
- ✅ Resource usage reasonable

---

## Orchestration Patterns

### Parallel Execution

```typescript
import { query } from '@anthropic-ai/claude-agent-sdk';

// Phase 0: All can run in parallel
const response = query({
  prompt: 'Implement Phase 0 Foundation',
  options: {
    model: 'claude-sonnet-4-5',
    agents: {
      'foundation-setup-agent': foundationSetupConfig,
      'database-schema-agent': databaseSchemaConfig,
      'test-infrastructure-agent': testInfraConfig
    }
  }
});

for await (const message of response) {
  if (message.type === 'system' && message.subtype === 'subagent_end') {
    console.log(`Completed: ${message.agent_name}`);
  }
}
```

### Sequential with Dependencies

```typescript
// Phase 1: Sequential dependencies
// 1. Setup hooks first
const hooksResult = await query({
  prompt: 'Implement hooks',
  options: {
    agents: { 'hook-developer-agent': hookConfig }
  }
});

// 2. Then event collector (needs hooks to test)
const collectorResult = await query({
  prompt: 'Implement event collector',
  options: {
    agents: { 'event-collector-agent': collectorConfig }
  }
});

// 3. Finally queue system
const queueResult = await query({
  prompt: 'Implement queue system',
  options: {
    agents: { 'queue-system-agent': queueConfig }
  }
});
```

## Related Documents

### Architecture
- [Subagent System Architecture](../architecture/architecture-subagent-system-2025-01-16.md)
- [Global Context Network](../architecture/architecture-global-context-network-2025-01-16.md)

### Reference
- [Claude Agent SDK API](./reference-claude-agent-sdk-api-2025-01-16.md)
- [Testing Strategy](./reference-testing-strategy-2025-01-16.md)
- [Database Schema](./reference-database-schema-2025-01-16.md)

### Guides
- [Using Subagents](../guides/guide-using-subagents-2025-01-16.md)
- [TDD Workflow](../guides/guide-tdd-workflow-2025-01-16.md)

================
File: reference/reference-testing-strategy-2025-01-16.md
================
# Testing Strategy Reference

> Comprehensive testing strategy, coverage requirements, and test organization for Global Context Network

---
title: Testing Strategy Reference
category: reference
date: 2025-01-16
status: active
authors: Claude + Dennison
tags: [testing, tdd, vitest, coverage, quality]
applies_to: Vitest 1.x, Node.js 20+
---

## Overview

This document defines the complete testing strategy for the Global Context Network MVP. Every component MUST follow TDD (Test-Driven Development) with strict coverage requirements and quality gates.

**Core Principle**: Write failing tests first, then minimal implementation, then refactor.

## Test Pyramid

### Distribution

```
        10%  E2E Tests (Full workflows)
       ────────────────────
      /                    \
     /    20% Integration   \
    /      (Component         \
   /       interactions)        \
  /                              \
 /      70% Unit Tests            \
/    (Isolated functions)          \
────────────────────────────────────
```

### Rationale

- **70% Unit Tests**: Fast feedback, easy debugging, isolated testing
- **20% Integration Tests**: Verify component interactions, database transactions
- **10% E2E Tests**: Validate complete workflows, catch integration issues

### Coverage by Type

| Test Type | Speed | Isolation | Setup Complexity | Debugging |
|-----------|-------|-----------|------------------|-----------|
| Unit | <10ms | High | Low | Easy |
| Integration | <100ms | Medium | Medium | Medium |
| E2E | <5s | Low | High | Hard |

## Coverage Requirements

### Global Thresholds

```json
{
  "coverage": {
    "lines": 85,
    "statements": 85,
    "branches": 70,
    "functions": 85
  }
}
```

### Per-Scope Requirements

**Critical Path Files** (sanitization, hooks, database):
- Lines: ≥ 100%
- Statements: ≥ 100%
- Branches: ≥ 90%
- Functions: ≥ 100%

**Standard Files** (utilities, helpers):
- Lines: ≥ 85%
- Statements: ≥ 85%
- Branches: ≥ 70%
- Functions: ≥ 85%

**Infrastructure Files** (config, types):
- Lines: ≥ 50%
- Statements: ≥ 50%
- Branches: ≥ 30%
- Functions: ≥ 50%

### Critical Path Definition

Files matching these patterns require 100% coverage:

```typescript
// vitest.config.ts
export default defineConfig({
  test: {
    coverage: {
      thresholds: {
        perFile: true,
        'src/sanitization/**/*.ts': {
          lines: 100,
          statements: 100,
          branches: 90,
          functions: 100
        },
        'src/hooks/**/*.ts': {
          lines: 100,
          statements: 100,
          branches: 90,
          functions: 100
        },
        'src/database/repositories/**/*.ts': {
          lines: 100,
          statements: 100,
          branches: 90,
          functions: 100
        }
      }
    }
  }
});
```

### Exclusions Policy

**Excluded from coverage**:
- `**/*.d.ts` - Type definitions
- `**/generated/**` - Generated code
- `**/migrations/**/*.sql` - SQL migrations
- `**/config/**/*.ts` - Configuration files (but test loading logic)
- `**/__mocks__/**` - Test mocks
- `**/test-helpers/**` - Test utilities

**Must be tested**:
- Configuration loading and validation
- Migration application logic
- Generated code usage (integration tests)

## Testing Framework Configuration

### Canonical Vitest Config

```typescript
// vitest.config.ts
import { defineConfig } from 'vitest/config';

export default defineConfig({
  test: {
    // Isolation
    isolate: true,
    pool: 'threads',
    poolOptions: {
      threads: {
        singleThread: false,
        isolate: true
      }
    },

    // Test matching
    include: ['**/*.test.ts', '**/*.spec.ts'],
    exclude: [
      '**/node_modules/**',
      '**/dist/**',
      '**/.{git,cache,output,temp}/**'
    ],

    // Environment
    environment: 'node',
    environmentOptions: {},

    // Setup files
    setupFiles: ['./tests/setup.ts'],
    globalSetup: ['./tests/global-setup.ts'],

    // Timeouts
    testTimeout: 5000,
    hookTimeout: 10000,

    // Retry flaky tests once
    retry: 1,

    // Coverage
    coverage: {
      provider: 'v8',
      reporter: ['text', 'json', 'html', 'lcov'],
      exclude: [
        '**/*.d.ts',
        '**/generated/**',
        '**/migrations/**',
        '**/config/**',
        '**/__mocks__/**',
        '**/test-helpers/**'
      ],
      thresholds: {
        lines: 85,
        statements: 85,
        branches: 70,
        functions: 85
      }
    },

    // Fake timers
    fakeTimers: {
      toFake: ['setTimeout', 'clearTimeout', 'setInterval', 'clearInterval', 'Date']
    },

    // Inline snapshots
    resolveSnapshotPath: (testPath, snapExtension) => {
      return testPath.replace(/\.test\.([tj]sx?)/, `.test${snapExtension}.$1`);
    }
  }
});
```

### SQLite Test Database Setup

```typescript
// tests/setup.ts
import { beforeEach, afterEach } from 'vitest';
import Database from 'better-sqlite3';
import { runMigrations } from '../src/database/migrations';

let testDb: Database.Database | null = null;

export function getTestDb(): Database.Database {
  if (!testDb) {
    // In-memory database for fast tests
    testDb = new Database(':memory:');

    // Enable WAL mode (even for in-memory)
    testDb.pragma('journal_mode = WAL');
    testDb.pragma('synchronous = FULL');
    testDb.pragma('foreign_keys = ON');

    // Run all migrations
    runMigrations(testDb);
  }
  return testDb;
}

// Reset database between tests
beforeEach(() => {
  const db = getTestDb();

  // Clear all tables
  db.exec(`
    DELETE FROM sanitization_log;
    DELETE FROM uploads;
    DELETE FROM learnings;
    DELETE FROM messages;
    DELETE FROM conversations;
    DELETE FROM job_queue;
  `);
});

afterEach(() => {
  // Verify no locks
  if (testDb) {
    const locks = testDb.pragma('database_list', { simple: true });
    // Assert no active transactions
  }
});

// Cleanup after all tests
process.on('beforeExit', () => {
  if (testDb) {
    testDb.close();
    testDb = null;
  }
});
```

### CI/CD Configuration

```yaml
# .github/workflows/test.yml
name: Test Suite

on: [push, pull_request]

jobs:
  test:
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        node: [20, 22]

    runs-on: ${{ matrix.os }}

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node }}
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Lint
        run: pnpm run lint

      - name: Type check
        run: pnpm run type-check

      - name: Unit tests
        run: pnpm run test:unit

      - name: Integration tests
        run: pnpm run test:integration

      - name: E2E tests
        run: pnpm run test:e2e

      - name: Coverage check
        run: pnpm run test:coverage

      - name: Security audit
        run: pnpm audit --audit-level=moderate

      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info
```

## Test Organization

### Directory Structure

```
tests/
├── unit/                     # Unit tests (70%)
│   ├── sanitization/
│   │   ├── rule-detector.test.ts
│   │   ├── ai-sanitizer.test.ts
│   │   └── hybrid-validator.test.ts
│   ├── hooks/
│   │   ├── user-prompt-submit.test.ts
│   │   └── stop-hook.test.ts
│   ├── database/
│   │   ├── repositories/
│   │   │   ├── conversation-repository.test.ts
│   │   │   └── learning-repository.test.ts
│   │   └── migrations/
│   │       └── migration-runner.test.ts
│   └── utils/
│       └── validators.test.ts
│
├── integration/              # Integration tests (20%)
│   ├── event-capture.int.test.ts
│   ├── sanitization-pipeline.int.test.ts
│   ├── learning-extraction.int.test.ts
│   └── mcp-server.int.test.ts
│
├── e2e/                      # End-to-end tests (10%)
│   ├── conversation-to-learning.e2e.test.ts
│   ├── hook-to-database.e2e.test.ts
│   └── query-via-mcp.e2e.test.ts
│
├── fixtures/                 # Test data
│   ├── conversations/
│   │   ├── with-pii.json
│   │   └── sanitized.json
│   ├── learnings/
│   │   └── examples.json
│   └── sanitization/
│       ├── api-keys.txt
│       ├── file-paths.txt
│       └── pii-corpus.json
│
├── helpers/                  # Test utilities
│   ├── db-helpers.ts
│   ├── fixture-factory.ts
│   └── mock-helpers.ts
│
├── setup.ts                  # Test setup
└── global-setup.ts           # Global setup
```

### Naming Conventions

**Files**:
- Unit tests: `*.test.ts`
- Integration tests: `*.int.test.ts`
- E2E tests: `*.e2e.test.ts`

**Test cases**:
```typescript
describe('RuleBasedDetector', () => {
  describe('detectAPIKeys', () => {
    it('should detect AWS access keys', () => {
      // Test implementation
    });

    it('should detect OpenAI API keys', () => {
      // Test implementation
    });

    it('should return empty array for clean content', () => {
      // Test implementation
    });
  });
});
```

## TDD Workflow

### Red-Green-Refactor with Subagents

```
┌─────────────────────────────────────────────────────────────┐
│ 🔴 RED PHASE (Test Generator Subagent)                      │
├─────────────────────────────────────────────────────────────┤
│ 1. Generate failing test                                    │
│ 2. Validate test quality (Test Quality Validator)           │
│ 3. Run test → confirm proper failure                        │
│ 4. Commit test                                               │
└─────────────────────────────────────────────────────────────┘
                           ↓
┌─────────────────────────────────────────────────────────────┐
│ 🟢 GREEN PHASE (Implementation Subagent)                    │
├─────────────────────────────────────────────────────────────┤
│ 1. Write minimal code to pass test                          │
│ 2. Run tests continuously                                    │
│ 3. Validate implementation (Implementation Validator)       │
│ 4. All tests pass → proceed                                 │
└─────────────────────────────────────────────────────────────┘
                           ↓
┌─────────────────────────────────────────────────────────────┐
│ 🔵 REFACTOR PHASE (Code Quality Validator)                  │
├─────────────────────────────────────────────────────────────┤
│ 1. Improve code quality                                     │
│ 2. Maintain passing tests                                   │
│ 3. Re-validate quality                                      │
│ 4. Commit refactoring                                        │
└─────────────────────────────────────────────────────────────┘
                           ↓
┌─────────────────────────────────────────────────────────────┐
│ ✅ QUALITY GATE (All Validators in Parallel)                │
├─────────────────────────────────────────────────────────────┤
│ • Coverage ≥ 85%                                             │
│ • Security scan passes                                       │
│ • Performance acceptable                                     │
│ • Lint + TypeScript strict mode                             │
└─────────────────────────────────────────────────────────────┘
```

### Example TDD Cycle

```typescript
// 🔴 RED: Write failing test first
describe('detectAPIKeys', () => {
  it('should detect AWS access keys', () => {
    const content = 'AKIAIOSFODNN7EXAMPLE';
    const result = detectAPIKeys(content);

    expect(result).toHaveLength(1);
    expect(result[0]).toMatchObject({
      type: 'aws_access_key',
      start: 0,
      end: 20,
      confidence: 1.0
    });
  });
});

// Run: pnpm test
// ❌ FAIL: ReferenceError: detectAPIKeys is not defined

// 🟢 GREEN: Minimal implementation
export function detectAPIKeys(content: string): Detection[] {
  const AWS_KEY_REGEX = /AKIA[0-9A-Z]{16}/g;
  const matches: Detection[] = [];

  let match;
  while ((match = AWS_KEY_REGEX.exec(content)) !== null) {
    matches.push({
      type: 'aws_access_key',
      start: match.index,
      end: match.index + match[0].length,
      confidence: 1.0
    });
  }

  return matches;
}

// Run: pnpm test
// ✅ PASS

// 🔵 REFACTOR: Extract regex patterns
const API_KEY_PATTERNS = {
  aws_access_key: /AKIA[0-9A-Z]{16}/g,
  openai: /sk-[a-zA-Z0-9]{48}/g,
  github: /ghp_[a-zA-Z0-9]{36}/g
};

export function detectAPIKeys(content: string): Detection[] {
  const matches: Detection[] = [];

  for (const [type, pattern] of Object.entries(API_KEY_PATTERNS)) {
    let match;
    while ((match = pattern.exec(content)) !== null) {
      matches.push({
        type,
        start: match.index,
        end: match.index + match[0].length,
        confidence: 1.0
      });
    }
  }

  return matches;
}

// Run: pnpm test
// ✅ PASS (all tests still pass after refactor)
```

## Mocking Strategy

### When to Mock vs Stub vs Fake

| Dependency | Strategy | Rationale |
|------------|----------|-----------|
| Database | Fake (in-memory SQLite) | Fast, realistic behavior |
| LLM API | Stub (recorded fixtures) | Deterministic, no API costs |
| MCP Server | Fake (local test server) | Contract testing |
| IPFS | Stub (deterministic CIDs) | No external dependency |
| Blockchain | Stub (fake tx hashes) | No real transactions |
| File System | Real (temp directory) | OS compatibility testing |
| Time | Fake (vitest fake timers) | Deterministic timing |
| Random | Seeded RNG | Reproducible tests |

### LLM Call Mocking

```typescript
// tests/helpers/mock-llm.ts
import { vi } from 'vitest';

interface MockCompletion {
  input: string;
  output: string;
  model?: string;
}

export function mockLLMWithFixtures(fixtures: MockCompletion[]) {
  return vi.fn(async (input: string) => {
    const fixture = fixtures.find(f => f.input === input);
    if (!fixture) {
      throw new Error(`No fixture for input: ${input}`);
    }
    return fixture.output;
  });
}

// Usage in tests
import { sanitizeWithAI } from '../src/sanitization/ai-sanitizer';

it('should sanitize PII using AI', async () => {
  const mockLLM = mockLLMWithFixtures([
    {
      input: 'My email is john@example.com',
      output: 'My email is [EMAIL]'
    }
  ]);

  const result = await sanitizeWithAI('My email is john@example.com', mockLLM);
  expect(result).toBe('My email is [EMAIL]');
});
```

### MCP Server Mocking

```typescript
// tests/helpers/mock-mcp-server.ts
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';

export function createMockMCPServer() {
  const server = new Server({
    name: 'test-context-server',
    version: '1.0.0'
  }, {
    capabilities: {
      tools: {},
      resources: {}
    }
  });

  // Mock search_learnings tool
  server.setRequestHandler('tools/call', async (request) => {
    if (request.params.name === 'search_learnings') {
      return {
        content: [
          {
            type: 'text',
            text: JSON.stringify([
              { id: '1', content: 'Test learning', confidence: 0.9 }
            ])
          }
        ]
      };
    }
    throw new Error(`Unknown tool: ${request.params.name}`);
  });

  return server;
}
```

### Deterministic Time and Randomness

```typescript
// Use fake timers
import { vi } from 'vitest';

beforeEach(() => {
  vi.useFakeTimers();
  vi.setSystemTime(new Date('2025-01-16T00:00:00Z'));
});

afterEach(() => {
  vi.useRealTimers();
});

it('should retry after 1 second', async () => {
  const fn = vi.fn()
    .mockRejectedValueOnce(new Error('Fail'))
    .mockResolvedValueOnce('Success');

  const promise = retryWithBackoff(fn, { initialDelay: 1000 });

  await vi.advanceTimersByTimeAsync(1000);

  const result = await promise;
  expect(result).toBe('Success');
  expect(fn).toHaveBeenCalledTimes(2);
});

// Seeded random for reproducibility
import seedrandom from 'seedrandom';

const rng = seedrandom('test-seed-123');

it('should randomly sample with seed', () => {
  const samples = Array.from({ length: 10 }, () => rng());
  // Always produces same sequence
  expect(samples[0]).toBeCloseTo(0.9282578795792454);
});
```

## Performance Testing

### Component SLAs

| Component | P50 | P95 | P99 | Max |
|-----------|-----|-----|-----|-----|
| Hook execution | <50ms | <100ms | <150ms | 200ms |
| Event queueing | <10ms | <50ms | <100ms | 200ms |
| Sanitization | <1s | <2s | <3s | 5s |
| Database queries | <50ms | <100ms | <200ms | 500ms |
| MCP queries | <100ms | <200ms | <500ms | 1s |
| Learning extraction | <2s | <5s | <10s | 30s |

### Measurement Strategy

```typescript
// tests/performance/hook-performance.test.ts
import { performance } from 'perf_hooks';

describe('Hook Performance', () => {
  it('should execute UserPromptSubmit hook under 100ms P95', async () => {
    const samples: number[] = [];

    for (let i = 0; i < 100; i++) {
      const start = performance.now();
      await userPromptSubmitHook({ prompt: 'Test prompt' });
      const duration = performance.now() - start;
      samples.push(duration);
    }

    samples.sort((a, b) => a - b);
    const p95 = samples[Math.floor(samples.length * 0.95)];

    expect(p95).toBeLessThan(100);
  });
});
```

### Load Testing

```javascript
// tests/load/k6-load-test.js
import http from 'k6/http';
import { check, sleep } from 'k6';

export const options = {
  stages: [
    { duration: '30s', target: 10 },  // Ramp up to 10 users
    { duration: '1m', target: 10 },   // Stay at 10 users
    { duration: '30s', target: 0 },   // Ramp down
  ],
  thresholds: {
    http_req_duration: ['p(95)<200'], // 95% under 200ms
  },
};

export default function () {
  const res = http.get('http://localhost:3000/api/learnings/search?q=test');

  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 200ms': (r) => r.timings.duration < 200,
  });

  sleep(1);
}
```

## Security Testing

### Static Analysis

```json
// .eslintrc.json
{
  "extends": [
    "eslint:recommended",
    "plugin:@typescript-eslint/recommended",
    "plugin:security/recommended"
  ],
  "plugins": ["security"],
  "rules": {
    "security/detect-object-injection": "error",
    "security/detect-non-literal-regexp": "warn",
    "security/detect-unsafe-regex": "error",
    "security/detect-buffer-noassert": "error",
    "security/detect-child-process": "error",
    "security/detect-disable-mustache-escape": "error",
    "security/detect-eval-with-expression": "error",
    "security/detect-no-csrf-before-method-override": "error",
    "security/detect-non-literal-fs-filename": "warn",
    "security/detect-non-literal-require": "error",
    "security/detect-possible-timing-attacks": "warn",
    "security/detect-pseudoRandomBytes": "error"
  }
}
```

### Dependency Scanning

```bash
# Run in CI
pnpm audit --audit-level=moderate
pnpm outdated

# Use npm-check-updates
npx ncu -u
```

### Secret Scanning

```yaml
# .github/workflows/security.yml
- name: Gitleaks
  uses: gitleaks/gitleaks-action@v2
  env:
    GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

### Sanitization Red-Team Tests

```typescript
// tests/security/sanitization-redteam.test.ts
import { sanitizationPipeline } from '../src/sanitization/pipeline';
import { piiCorpus } from '../fixtures/sanitization/pii-corpus';

describe('Sanitization Red Team Tests', () => {
  // Test against curated corpus of PII
  it.each(piiCorpus.api_keys)('should detect API key: %s', async (apiKey) => {
    const content = `Here is my key: ${apiKey}`;
    const result = await sanitizationPipeline(content);

    expect(result.content).not.toContain(apiKey);
    expect(result.detections).toHaveLength(1);
    expect(result.detections[0].type).toBe('api_key');
  });

  // Adversarial prompts
  it('should handle obfuscated API keys', async () => {
    const content = 'My key is: A K I A I O S F O D N N 7 E X A M P L E';
    const result = await sanitizationPipeline(content);

    // Should still detect when spaces are normalized
    expect(result.content).not.toContain('AKIAIOSFODNN7EXAMPLE');
  });

  // False positive checks
  it('should not flag variable names as API keys', async () => {
    const content = 'const apiKey = getEnvVar("API_KEY");';
    const result = await sanitizationPipeline(content);

    expect(result.detections).toHaveLength(0);
  });
});
```

### PII Corpus Structure

```json
// fixtures/sanitization/pii-corpus.json
{
  "api_keys": {
    "aws": ["AKIAIOSFODNN7EXAMPLE", "AKIAI44QH8DHBEXAMPLE"],
    "openai": ["sk-proj-abc123..."],
    "github": ["ghp_1234567890abcdef..."]
  },
  "file_paths": {
    "absolute_with_username": [
      "/Users/john/projects/app",
      "C:\\Users\\jane\\Documents"
    ],
    "relative_safe": [
      "./src/index.ts",
      "../utils/helpers.ts"
    ]
  },
  "emails": [
    "john.doe@example.com",
    "test+filter@domain.co.uk"
  ],
  "ip_addresses": [
    "192.168.1.1",
    "10.0.0.1",
    "2001:0db8:85a3::8a2e:0370:7334"
  ],
  "person_names": [
    "John Doe",
    "Jane Smith"
  ],
  "phone_numbers": [
    "+1-555-123-4567",
    "(555) 987-6543"
  ]
}
```

## Test Data Management

### Fixture Factories

```typescript
// tests/helpers/fixture-factory.ts
import { faker } from '@faker-js/faker';

export function createConversation(overrides?: Partial<Conversation>): Conversation {
  return {
    id: faker.string.uuid(),
    created_at: new Date().toISOString(),
    updated_at: new Date().toISOString(),
    session_id: faker.string.alphanumeric(32),
    correlation_id: faker.string.uuid(),
    sanitized: true,
    ...overrides
  };
}

export function createMessage(overrides?: Partial<Message>): Message {
  return {
    id: faker.string.uuid(),
    conversation_id: faker.string.uuid(),
    role: faker.helpers.arrayElement(['user', 'assistant']),
    content: faker.lorem.paragraph(),
    created_at: new Date().toISOString(),
    sequence: faker.number.int({ min: 0, max: 100 }),
    ...overrides
  };
}

export function createLearning(overrides?: Partial<Learning>): Learning {
  return {
    id: faker.string.uuid(),
    conversation_id: faker.string.uuid(),
    category: faker.helpers.arrayElement(['pattern', 'best_practice', 'bug_fix']),
    content: faker.lorem.sentences(3),
    confidence: faker.number.float({ min: 0.6, max: 1.0 }),
    tags: faker.helpers.arrayElements(['typescript', 'testing', 'database'], { min: 1, max: 3 }),
    created_at: new Date().toISOString(),
    dedupe_hash: faker.string.alphanumeric(64),
    ...overrides
  };
}
```

### Synthetic vs Real Data

**Unit Tests**: 100% synthetic data via faker
**Integration Tests**: Synthetic data + realistic fixtures
**E2E Tests**: Sanitized real-world examples

### Data Versioning

```typescript
// fixtures/conversations/v1/with-pii.json
{
  "version": "1.0.0",
  "schema": "conversation-with-messages",
  "data": {
    // ...
  }
}
```

## Canonical Commands

```json
// package.json
{
  "scripts": {
    "test": "vitest",
    "test:unit": "vitest run tests/unit",
    "test:integration": "vitest run tests/integration",
    "test:e2e": "vitest run tests/e2e",
    "test:watch": "vitest watch",
    "test:coverage": "vitest run --coverage",
    "test:perf": "k6 run tests/load/k6-load-test.js",
    "test:mutation": "stryker run",
    "test:ci": "pnpm run lint && pnpm run type-check && pnpm run test:coverage && pnpm run test:perf"
  }
}
```

## Flaky Test Policy

### Rules

1. **No disabled tests in main branch**
2. **Quarantine flaky tests** to separate file
3. **Fix within 7 days** or remove
4. **Track flakiness** in test metadata

### Quarantine Process

```typescript
// tests/quarantine/flaky-tests.test.ts
import { describe, it, skip } from 'vitest';

describe.skip('Quarantined Tests', () => {
  it.skip('flaky test - issue #123', () => {
    // Test that needs fixing
  });
});
```

## Mutation Testing

```javascript
// stryker.config.mjs
export default {
  packageManager: 'pnpm',
  reporters: ['html', 'clear-text', 'progress'],
  testRunner: 'vitest',
  coverageAnalysis: 'perTest',
  mutate: [
    'src/sanitization/**/*.ts',
    'src/hooks/**/*.ts',
    'src/database/repositories/**/*.ts'
  ],
  thresholds: { high: 80, low: 60, break: 50 }
};
```

## Related Documents

### Architecture
- [Global Context Network Architecture](../architecture/architecture-global-context-network-2025-01-16.md)
- [Subagent System](../architecture/architecture-subagent-system-2025-01-16.md)

### Guides
- [TDD Workflow Guide](../guides/guide-tdd-workflow-2025-01-16.md)
- [Testing Harness Usage](../guides/guide-testing-harness-usage-2025-01-16.md)

### Reference
- [Subagent Types](./reference-subagent-types-2025-01-16.md)
- [Database Schema](./reference-database-schema-2025-01-16.md)

================
File: INDEX.md
================
# Documentation Index

> Last updated: 2025-01-16

## Overview

This directory contains all project documentation for the Global Context Network MVP - a system that captures Claude Code conversations, sanitizes them for PII, stores learnings, and shares them globally via blockchain/IPFS with token rewards.

**Core Philosophy**: Subagent-driven development with Claude-powered testing harness.

## Quick Links

- [Architecture](./architecture/INDEX.md) - System design, components, and data flow
- [Decisions](./decisions/INDEX.md) - Architecture Decision Records (ADRs)
- [Plans](./plans/INDEX.md) - Implementation plans, roadmaps, and task breakdowns
- [Guides](./guides/INDEX.md) - How-to guides for development and testing
- [Reference](./reference/INDEX.md) - Technical reference materials and APIs
- [Learnings](./learnings/INDEX.md) - Insights, retrospectives, and discoveries

## Project Goals

1. **Capture**: Hook into Claude Code to capture conversations
2. **Sanitize**: Remove ALL PII before storage (privacy-first)
3. **Extract**: Generate valuable, reusable learnings
4. **Share**: Upload to global network (IPFS + blockchain)
5. **Query**: MCP server for agents to access learnings
6. **Reward**: Token rewards for quality contributions

## Recent Documents

| Date | Category | Document | Description |
|------|----------|----------|-------------|
| 2025-01-16 | decision | [ADR-001: Use Claude Hooks](./decisions/decision-use-claude-hooks-2025-01-16.md) | Event capture via Claude Code hooks |
| 2025-01-16 | decision | [ADR-002: Subagent-Driven Development](./decisions/decision-subagent-driven-development-2025-01-16.md) | All implementation via specialized subagents |
| 2025-01-16 | decision | [ADR-003: Claude Testing Harness](./decisions/decision-claude-testing-harness-2025-01-16.md) | AI-powered test generation and validation |
| 2025-01-16 | decision | [ADR-004: Sanitize Before Storage](./decisions/decision-sanitize-before-storage-2025-01-16.md) | Privacy-first architecture decision |
| 2025-01-16 | decision | [ADR-005: Use SQLite](./decisions/decision-use-sqlite-2025-01-16.md) | SQLite for MVP storage |
| 2025-01-16 | decision | [ADR-006: Async Processing Model](./decisions/decision-async-processing-model-2025-01-16.md) | SQLite-based job queue |
| 2025-01-16 | plans | [Global Context Network MVP](./plans/plan-global-context-network-mvp-2025-01-16.md) | Complete MVP implementation plan |
| 2025-01-16 | plans | [Implementation Roadmap](./plans/plan-implementation-roadmap-2025-01-16.md) | 7-phase roadmap with timeline |
| 2025-01-16 | plans | [Original User Vision](./plans/plan-original-user-vision-2025-01-16.md) | User's original concept and requirements |
| 2025-01-16 | architecture | [Global Context Network](./architecture/architecture-global-context-network-2025-01-16.md) | System architecture overview |
| 2025-01-16 | architecture | [Subagent System](./architecture/architecture-subagent-system-2025-01-16.md) | Subagent-driven development architecture |

## Document Count by Category

- **Architecture**: 2 documents (system design, components, data flow)
- **Decisions**: 6 ADRs (major architectural decisions) ✓ **NEW**
- **Plans**: 1 plan (original user vision)
- **Guides**: 0 guides (to be created during implementation)
- **Reference**: 0 references (to be created during implementation)
- **Learnings**: 0 (will be populated during implementation)

**Total**: 9 documents

## Key Architectural Decisions

1. **Hooks-Based Capture** - Use Claude Code hooks (UserPromptSubmit, Stop)
2. **Privacy-First** - Sanitize BEFORE database storage, never store raw PII
3. **Subagent-Driven** - ALL implementation via specialized subagents
4. **Claude Testing** - Self-validating system using Claude Agent SDK
5. **Async Processing** - Job queue for sanitization and learning extraction
6. **SQLite Storage** - Local persistence with migration system
7. **MCP Interface** - Standard protocol for agent queries
8. **IPFS + Blockchain** - Decentralized global storage with rewards

## Development Phases

| Phase | Focus | Duration | Status | Plan |
|-------|-------|----------|--------|------|
| 0 | Foundation (TypeScript, DB, Tests) | 2-3 days | Planned | [Phase 0 Tasks](./plans/plan-phase-0-tasks-2025-01-16.md) |
| 1 | Event Capture (Hooks, Queue) | 3-4 days | Planned | [Phase 1 Tasks](./plans/plan-phase-1-tasks-2025-01-16.md) |
| 2 | Sanitization (PII Removal) | 7-10 days | Planned | [Phase 2 Tasks](./plans/plan-phase-2-tasks-2025-01-16.md) |
| 3 | Database & Storage | 2-3 days | Planned | [Phase 3 Tasks](./plans/plan-phase-3-tasks-2025-01-16.md) |
| 4 | Async Processing (Job Queue) | 5-7 days | Planned | [Phase 4 Tasks](./plans/plan-phase-4-tasks-2025-01-16.md) |
| 5 | Learning Extraction | 6-8 days | Planned | [Phase 5 Tasks](./plans/plan-phase-5-tasks-2025-01-16.md) |
| 6 | MCP Server | 3-4 days | Planned | [Phase 6 Tasks](./plans/plan-phase-6-tasks-2025-01-16.md) |
| 7 | Mining & Upload (IPFS/Blockchain) | 4-10 days | MVP+ | [Phase 7 Tasks](./plans/plan-phase-7-tasks-2025-01-16.md) |

## How to Use This Documentation

### For Implementation
1. Start with [Implementation Roadmap](./plans/plan-implementation-roadmap-2025-01-16.md)
2. Review [Subagent Workflow](./plans/plan-subagent-workflow-2025-01-16.md)
3. Follow phase-specific guides in `guides/`
4. Reference architecture docs as needed

### For Understanding the System
1. Read [Global Context Network Architecture](./architecture/architecture-global-context-network-2025-01-16.md)
2. Review [Architectural Decisions](./decisions/) for rationale
3. Explore component-specific architecture docs

### For Testing
1. Follow [TDD Workflow Guide](./guides/guide-tdd-workflow-2025-01-16.md)
2. Use [Testing Harness Usage](./guides/guide-testing-harness-usage-2025-01-16.md)
3. Reference [Testing Strategy](./reference/reference-testing-strategy-2025-01-16.md)

## Contributing

When adding documentation:

1. **Choose Category**: architecture, decisions, plans, guides, reference, or learnings
2. **Name Properly**: `category-topic-2025-01-16.md` format
3. **Use Template**: Follow markdown-organizer templates
4. **Add Frontmatter**: Include all required metadata
5. **Update Category INDEX**: Add entry to category's INDEX.md
6. **Update This File**: Add to "Recent Documents" and update counts
7. **Cross-Link**: Add "Related Documents" section with links

## Templates

All documentation follows standardized templates:
- **Architecture**: System design with diagrams, components, trade-offs
- **ADR**: Context, decision, consequences, alternatives
- **Plan**: Goals, tasks, risks, success criteria
- **Guide**: Step-by-step instructions with examples
- **Reference**: Technical specifications and API docs
- **Learning**: Insights with context and application

## Navigation Tips

- Use category INDEX.md files for complete listings
- Search by topic using your editor's find function
- Follow cross-links in "Related Documents" sections
- Check this master index for recent additions
- All paths are relative for easy navigation

## Project Links

- **GitHub**: [Repository URL when created]
- **Documentation**: This directory
- **Tests**: `/tests/` directory
- **Source**: `/src/` directory

## Status Legend

- 📝 **Planned**: Not yet started
- 🚧 **In Progress**: Currently being implemented
- ✅ **Complete**: Finished and validated
- 📦 **Archived**: Superseded or no longer active

---

*This documentation follows the markdown-organizer skill guidelines for consistent, discoverable, well-organized documentation.*



================================================================
End of Codebase
================================================================
